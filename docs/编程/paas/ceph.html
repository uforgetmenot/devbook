<!DOCTYPE HTML>
<html lang="zh" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Ceph åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿå­¦ä¹ ç¬”è®° - å¼€å‘</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../theme/pagetoc.css">
        <link rel="stylesheet" href="../../theme/help-overlay.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>â†</kbd> or <kbd>â†’</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">å¼€å‘</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="æœç´¢æœ¬ä¹¦å†…å®¹..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="ceph-åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿå­¦ä¹ ç¬”è®°"><a class="header" href="#ceph-åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿå­¦ä¹ ç¬”è®°">Ceph åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿå­¦ä¹ ç¬”è®°</a></h1>
<h2 id="-å­¦ä¹ ç›®æ ‡"><a class="header" href="#-å­¦ä¹ ç›®æ ‡">ğŸ“‹ å­¦ä¹ ç›®æ ‡</a></h2>
<p>é€šè¿‡æœ¬ç¬”è®°çš„å­¦ä¹ ï¼Œä½ å°†èƒ½å¤Ÿï¼š</p>
<ol>
<li>æ·±å…¥ç†è§£ Ceph çš„æ¶æ„è®¾è®¡åŸç†å’Œæ ¸å¿ƒç»„ä»¶</li>
<li>æŒæ¡ RADOSã€CRUSH ç­‰æ ¸å¿ƒæŠ€æœ¯çš„å·¥ä½œæœºåˆ¶</li>
<li>ç†Ÿç»ƒéƒ¨ç½²å’Œç®¡ç† Ceph é›†ç¾¤</li>
<li>ç†è§£å¹¶ä½¿ç”¨ Ceph çš„ä¸‰ç§å­˜å‚¨æ¥å£ï¼ˆå—ã€æ–‡ä»¶ã€å¯¹è±¡ï¼‰</li>
<li>å…·å¤‡ Ceph æ€§èƒ½ä¼˜åŒ–å’Œæ•…éšœæ’æŸ¥èƒ½åŠ›</li>
</ol>
<hr />
<h2 id="ç¬¬ä¸€ç« ceph-æ¦‚è¿°ä¸æ ¸å¿ƒæ¶æ„"><a class="header" href="#ç¬¬ä¸€ç« ceph-æ¦‚è¿°ä¸æ ¸å¿ƒæ¶æ„">ç¬¬ä¸€ç« ï¼šCeph æ¦‚è¿°ä¸æ ¸å¿ƒæ¶æ„</a></h2>
<h3 id="11-ä»€ä¹ˆæ˜¯-ceph"><a class="header" href="#11-ä»€ä¹ˆæ˜¯-ceph">1.1 ä»€ä¹ˆæ˜¯ Ceph</a></h3>
<p>Ceph æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿï¼Œæä¾›äº†ç»Ÿä¸€çš„è½¯ä»¶å®šä¹‰å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚å®ƒçš„è®¾è®¡ç›®æ ‡æ˜¯å®ç°<strong>æ— å•ç‚¹æ•…éšœ</strong>ã€<strong>çº¿æ€§æ‰©å±•</strong>å’Œ<strong>ç»Ÿä¸€å­˜å‚¨æ¥å£</strong>ã€‚</p>
<h4 id="æ ¸å¿ƒç‰¹æ€§"><a class="header" href="#æ ¸å¿ƒç‰¹æ€§">æ ¸å¿ƒç‰¹æ€§</a></h4>
<ol>
<li>
<p><strong>ç»Ÿä¸€å­˜å‚¨å¹³å°</strong></p>
<ul>
<li>å—å­˜å‚¨ï¼ˆRBD - RADOS Block Deviceï¼‰</li>
<li>æ–‡ä»¶å­˜å‚¨ï¼ˆCephFS - Ceph File Systemï¼‰</li>
<li>å¯¹è±¡å­˜å‚¨ï¼ˆRGW - RADOS Gatewayï¼‰</li>
</ul>
</li>
<li>
<p><strong>é«˜å¯ç”¨æ€§</strong></p>
<ul>
<li>æ— å•ç‚¹æ•…éšœè®¾è®¡</li>
<li>æ•°æ®è‡ªåŠ¨å¤åˆ¶</li>
<li>æ•…éšœåŸŸéš”ç¦»</li>
</ul>
</li>
<li>
<p><strong>å¯æ‰©å±•æ€§</strong></p>
<ul>
<li>æ”¯æŒ PB çº§åˆ«å­˜å‚¨</li>
<li>çº¿æ€§æ€§èƒ½æ‰©å±•</li>
<li>æ”¯æŒæ•°åƒä¸ªå­˜å‚¨èŠ‚ç‚¹</li>
</ul>
</li>
<li>
<p><strong>è‡ªæˆ‘ç®¡ç†</strong></p>
<ul>
<li>è‡ªåŠ¨æ•°æ®å¹³è¡¡</li>
<li>è‡ªæˆ‘ä¿®å¤</li>
<li>è‡ªåŠ¨æ•…éšœæ£€æµ‹</li>
</ul>
</li>
</ol>
<h4 id="ceph-çš„å‘å±•å†ç¨‹"><a class="header" href="#ceph-çš„å‘å±•å†ç¨‹">Ceph çš„å‘å±•å†ç¨‹</a></h4>
<pre><code>2004: Sage Weil åœ¨ UCSC å¼€å§‹ Ceph é¡¹ç›®
2006: å‘å¸ƒç¬¬ä¸€ä¸ªç‰ˆæœ¬
2012: Ceph è¿›å…¥ç”Ÿäº§ç¯å¢ƒ
2014: Red Hat æ”¶è´­ Inktank
2017: Luminous ç‰ˆæœ¬ï¼ˆç¬¬ä¸€ä¸ª LTS ç‰ˆæœ¬ï¼‰
2020: Octopus ç‰ˆæœ¬
2022: Quincy ç‰ˆæœ¬
2023: Reef ç‰ˆæœ¬ï¼ˆå½“å‰ç¨³å®šç‰ˆï¼‰
</code></pre>
<h3 id="12-ceph-æ ¸å¿ƒæ¶æ„"><a class="header" href="#12-ceph-æ ¸å¿ƒæ¶æ„">1.2 Ceph æ ¸å¿ƒæ¶æ„</a></h3>
<h4 id="121-æ•´ä½“æ¶æ„å›¾"><a class="header" href="#121-æ•´ä½“æ¶æ„å›¾">1.2.1 æ•´ä½“æ¶æ„å›¾</a></h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨å±‚ï¼ˆApplicationsï¼‰                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   RBD    â”‚  â”‚ CephFS   â”‚  â”‚   RGW    â”‚              â”‚
â”‚  â”‚(å—å­˜å‚¨)   â”‚  â”‚(æ–‡ä»¶ç³»ç»Ÿ) â”‚  â”‚(å¯¹è±¡å­˜å‚¨) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    LIBRADOS (ç»Ÿä¸€æ¥å£)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           RADOS æ ¸å¿ƒå±‚                      â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ Monitor  â”‚  â”‚ Manager  â”‚  â”‚   OSD   â”‚ â”‚
        â”‚  â”‚  (MON)   â”‚  â”‚  (MGR)   â”‚  â”‚ (å¯¹è±¡)  â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
        â”‚           â”‚   MDS    â”‚  (å¯é€‰ï¼ŒCephFS)    â”‚
        â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      ç‰©ç†å­˜å‚¨å±‚            â”‚
        â”‚  HDD / SSD / NVMe         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="122-æ ¸å¿ƒç»„ä»¶è¯¦è§£"><a class="header" href="#122-æ ¸å¿ƒç»„ä»¶è¯¦è§£">1.2.2 æ ¸å¿ƒç»„ä»¶è¯¦è§£</a></h4>
<p><strong>1. Monitor (MON)</strong></p>
<p>Monitor æ˜¯ Ceph é›†ç¾¤çš„"å¤§è„‘"ï¼Œç»´æŠ¤é›†ç¾¤çŠ¶æ€ä¿¡æ¯ã€‚</p>
<ul>
<li>
<p><strong>èŒè´£</strong>ï¼š</p>
<ul>
<li>ç»´æŠ¤é›†ç¾¤ Mapï¼ˆCluster Mapï¼‰</li>
<li>æä¾›ä¸€è‡´æ€§æœåŠ¡</li>
<li>ç®¡ç†è®¤è¯</li>
</ul>
</li>
<li>
<p><strong>å…³é”®ç‰¹æ€§</strong>ï¼š</p>
<ul>
<li>ä½¿ç”¨ Paxos ç®—æ³•ä¿è¯ä¸€è‡´æ€§</li>
<li>æ¨èéƒ¨ç½²å¥‡æ•°ä¸ªï¼ˆ3/5/7ï¼‰</li>
<li>ä¸ç›´æ¥å¤„ç†æ•°æ® I/O</li>
</ul>
</li>
<li>
<p><strong>ç»´æŠ¤çš„ Map ç±»å‹</strong>ï¼š</p>
<pre><code>1. Monitor Map: Monitor èŠ‚ç‚¹ä¿¡æ¯
2. OSD Map: OSD çŠ¶æ€å’Œä½ç½®ä¿¡æ¯
3. PG Map: PG çŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯
4. CRUSH Map: æ•°æ®åˆ†å¸ƒè§„åˆ™
5. MDS Map: å…ƒæ•°æ®æœåŠ¡å™¨ä¿¡æ¯ï¼ˆCephFSï¼‰
</code></pre>
</li>
</ul>
<p><strong>2. OSD (Object Storage Daemon)</strong></p>
<p>OSD æ˜¯å®é™…å­˜å‚¨æ•°æ®çš„å®ˆæŠ¤è¿›ç¨‹ï¼Œä¸€èˆ¬ä¸€ä¸ªç£ç›˜å¯¹åº”ä¸€ä¸ª OSDã€‚</p>
<ul>
<li>
<p><strong>èŒè´£</strong>ï¼š</p>
<ul>
<li>å­˜å‚¨å®é™…æ•°æ®</li>
<li>å¤„ç†æ•°æ®å¤åˆ¶</li>
<li>æ‰§è¡Œæ•°æ®æ¢å¤</li>
<li>å‘ Monitor æŠ¥å‘ŠçŠ¶æ€</li>
<li>æ‰§è¡Œæ•°æ®æ¸…æ´—</li>
</ul>
</li>
<li>
<p><strong>å·¥ä½œåŸç†</strong>ï¼š</p>
<pre><code>æ•°æ®å†™å…¥æµç¨‹ï¼š
1. æ¥æ”¶å®¢æˆ·ç«¯å†™è¯·æ±‚
2. ç¡®å®š Primary OSD
3. Primary OSD æ‰§è¡Œå†™å…¥å¹¶å¤åˆ¶åˆ°å‰¯æœ¬ OSD
4. æ‰€æœ‰ OSD ç¡®è®¤åè¿”å›æˆåŠŸ
</code></pre>
</li>
<li>
<p><strong>OSD çŠ¶æ€</strong>ï¼š</p>
<ul>
<li><code>up</code>: OSD è¿›ç¨‹è¿è¡Œä¸­</li>
<li><code>down</code>: OSD è¿›ç¨‹åœæ­¢</li>
<li><code>in</code>: OSD åœ¨é›†ç¾¤æ•°æ®åˆ†å¸ƒä¸­</li>
<li><code>out</code>: OSD ä¸åœ¨é›†ç¾¤æ•°æ®åˆ†å¸ƒä¸­</li>
</ul>
</li>
</ul>
<p><strong>3. Manager (MGR)</strong></p>
<p>Manager æ˜¯é›†ç¾¤ç®¡ç†å’Œç›‘æ§çš„ä¸­å¿ƒã€‚</p>
<ul>
<li>
<p><strong>èŒè´£</strong>ï¼š</p>
<ul>
<li>æ”¶é›†é›†ç¾¤æ€§èƒ½æŒ‡æ ‡</li>
<li>æä¾› Dashboard ç•Œé¢</li>
<li>ç®¡ç†æ’ä»¶æ¨¡å—</li>
<li>REST API æ¥å£</li>
</ul>
</li>
<li>
<p><strong>å¸¸ç”¨æ¨¡å—</strong>ï¼š</p>
<pre><code class="language-bash"># Dashboard - Web ç®¡ç†ç•Œé¢
# Prometheus - ç›‘æ§é›†æˆ
# Balancer - æ•°æ®å¹³è¡¡
# Telemetry - é¥æµ‹æ•°æ®
# Orchestrator - é›†ç¾¤ç¼–æ’
</code></pre>
</li>
</ul>
<p><strong>4. MDS (Metadata Server)</strong> - CephFS ä¸“ç”¨</p>
<p>MDS ä¸º CephFS ç®¡ç†å…ƒæ•°æ®ã€‚</p>
<ul>
<li>
<p><strong>èŒè´£</strong>ï¼š</p>
<ul>
<li>ç®¡ç†æ–‡ä»¶ç³»ç»Ÿå…ƒæ•°æ®</li>
<li>ç›®å½•æ ‘ç®¡ç†</li>
<li>æ–‡ä»¶æƒé™å’Œå±æ€§</li>
</ul>
</li>
<li>
<p><strong>ç‰¹æ€§</strong>ï¼š</p>
<ul>
<li>æ”¯æŒå¤šæ´»ï¼ˆActive-Activeï¼‰</li>
<li>å…ƒæ•°æ®ç¼“å­˜</li>
<li>åŠ¨æ€å­æ ‘åˆ†åŒº</li>
</ul>
</li>
</ul>
<h3 id="13-radosceph-çš„åŸºçŸ³"><a class="header" href="#13-radosceph-çš„åŸºçŸ³">1.3 RADOSï¼šCeph çš„åŸºçŸ³</a></h3>
<h4 id="131-rados-æ¦‚è¿°"><a class="header" href="#131-rados-æ¦‚è¿°">1.3.1 RADOS æ¦‚è¿°</a></h4>
<p>RADOS (Reliable Autonomic Distributed Object Store) æ˜¯ Ceph çš„æ ¸å¿ƒï¼Œæä¾›äº†ä¸€ä¸ªå¯é çš„ã€è‡ªæ²»çš„åˆ†å¸ƒå¼å¯¹è±¡å­˜å‚¨ã€‚</p>
<p><strong>RADOS è®¾è®¡åŸåˆ™</strong>ï¼š</p>
<ol>
<li><strong>å»ä¸­å¿ƒåŒ–</strong>ï¼šæ²¡æœ‰ä¸­å¿ƒåŒ–çš„å…ƒæ•°æ®æœåŠ¡å™¨</li>
<li><strong>è‡ªæ²»æ€§</strong>ï¼šOSD ä¹‹é—´è‡ªä¸»åä½œ</li>
<li><strong>å¯æ‰©å±•</strong>ï¼šæ”¯æŒæ•°åƒèŠ‚ç‚¹çš„é›†ç¾¤</li>
<li><strong>ä¸€è‡´æ€§</strong>ï¼šå¼ºä¸€è‡´æ€§ä¿è¯</li>
</ol>
<h4 id="132-å¯¹è±¡pg-å’Œ-pool"><a class="header" href="#132-å¯¹è±¡pg-å’Œ-pool">1.3.2 å¯¹è±¡ã€PG å’Œ Pool</a></h4>
<p><strong>å¯¹è±¡ï¼ˆObjectï¼‰</strong></p>
<p>Ceph å°†æ‰€æœ‰æ•°æ®å­˜å‚¨ä¸ºå¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š</p>
<ul>
<li>å¯¹è±¡ IDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰</li>
<li>äºŒè¿›åˆ¶æ•°æ®</li>
<li>å…ƒæ•°æ®ï¼ˆé”®å€¼å¯¹ï¼‰</li>
</ul>
<pre><code>å¯¹è±¡å¤§å°ï¼šé»˜è®¤ 4MBï¼ˆå¯é…ç½®ï¼‰
å‘½åè§„åˆ™ï¼š&lt;pool_id&gt;.&lt;object_id&gt;
</code></pre>
<p><strong>Poolï¼ˆå­˜å‚¨æ± ï¼‰</strong></p>
<p>Pool æ˜¯å¯¹è±¡çš„é€»è¾‘åˆ†åŒºï¼Œå®šä¹‰äº†æ•°æ®çš„å­˜å‚¨ç­–ç•¥ã€‚</p>
<pre><code class="language-bash"># Pool é…ç½®å‚æ•°
- pg_num: PG æ•°é‡
- pgp_num: PG ç”¨äºæ”¾ç½®çš„æ•°é‡
- size: å‰¯æœ¬æ•°é‡
- min_size: æœ€å°å‰¯æœ¬æ•°
- crush_rule: CRUSH è§„åˆ™
- type: replicatedï¼ˆå‰¯æœ¬ï¼‰æˆ– erasureï¼ˆçº åˆ ç ï¼‰
</code></pre>
<p><strong>å®æˆ˜ç¤ºä¾‹ï¼šåˆ›å»º Pool</strong></p>
<pre><code class="language-bash"># åˆ›å»ºå‰¯æœ¬æ± ï¼ˆ3 å‰¯æœ¬ï¼‰
ceph osd pool create mypool 128 128 replicated

# åˆ›å»ºçº åˆ ç æ± ï¼ˆ4+2ï¼‰
ceph osd pool create ec-pool 128 128 erasure

# æŸ¥çœ‹ Pool ä¿¡æ¯
ceph osd pool ls detail

# è®¾ç½® Pool é…ç½®
ceph osd pool set mypool size 3
ceph osd pool set mypool min_size 2
ceph osd pool set mypool pg_num 256
</code></pre>
<p><strong>PGï¼ˆPlacement Groupï¼‰</strong></p>
<p>PG æ˜¯å¯¹è±¡åˆ° OSD çš„ä¸­é—´æ˜ å°„å±‚ï¼Œæ˜¯ Ceph æ•°æ®åˆ†å¸ƒçš„å…³é”®ã€‚</p>
<pre><code>æ•°æ®æ˜ å°„æµç¨‹ï¼š
Object â†’ Hash â†’ PG â†’ CRUSH â†’ OSD Set

ç¤ºä¾‹ï¼š
Object "foo" â†’ Hash(foo) = 0x12345678
            â†’ PG 1.78 (å‡è®¾ pool 1 æœ‰ 256 ä¸ª PG)
            â†’ CRUSH(1.78) = [OSD.5, OSD.12, OSD.23]
</code></pre>
<p><strong>PG æ•°é‡è®¡ç®—</strong>ï¼š</p>
<pre><code class="language-bash"># æ¨èå…¬å¼
PG_NUM = (Target PGs per OSD Ã— OSDæ•°é‡ Ã— å‰¯æœ¬æ•°) / Poolæ•°é‡

# ç¤ºä¾‹ï¼š10 ä¸ª OSDï¼Œ3 å‰¯æœ¬ï¼Œ1 ä¸ª Pool
PG_NUM = (100 Ã— 10 Ã— 3) / 1 = 3000
# é€‰æ‹©æœ€æ¥è¿‘çš„ 2 çš„å¹‚æ¬¡ï¼š2048
</code></pre>
<p><strong>ä¸ºä»€ä¹ˆéœ€è¦ PGï¼Ÿ</strong></p>
<ol>
<li><strong>ç®€åŒ–æ•°æ®ç®¡ç†</strong>ï¼šå°†æ•°ç™¾ä¸‡å¯¹è±¡æ˜ å°„åˆ°æ•°åƒä¸ª PG</li>
<li><strong>æé«˜æ€§èƒ½</strong>ï¼šæ‰¹é‡æ“ä½œï¼Œå‡å°‘å…ƒæ•°æ®</li>
<li><strong>æ•…éšœæ¢å¤</strong>ï¼šä»¥ PG ä¸ºå•ä½è¿›è¡Œæ¢å¤</li>
<li><strong>è´Ÿè½½å‡è¡¡</strong>ï¼šPG çº§åˆ«çš„æ•°æ®åˆ†å¸ƒ</li>
</ol>
<hr />
<h2 id="ç¬¬äºŒç« crush-ç®—æ³•æ·±åº¦è§£æ"><a class="header" href="#ç¬¬äºŒç« crush-ç®—æ³•æ·±åº¦è§£æ">ç¬¬äºŒç« ï¼šCRUSH ç®—æ³•æ·±åº¦è§£æ</a></h2>
<h3 id="21-crush-ç®—æ³•æ¦‚è¿°"><a class="header" href="#21-crush-ç®—æ³•æ¦‚è¿°">2.1 CRUSH ç®—æ³•æ¦‚è¿°</a></h3>
<p>CRUSH (Controlled Replication Under Scalable Hashing) æ˜¯ Ceph çš„æ•°æ®åˆ†å¸ƒç®—æ³•ï¼Œè§£å†³äº†"å¦‚ä½•ç¡®å®šæ•°æ®åº”è¯¥å­˜å‚¨åœ¨å“ªäº› OSD ä¸Š"çš„é—®é¢˜ã€‚</p>
<h4 id="211-ä¼ ç»Ÿæ–¹æ¡ˆ-vs-crush"><a class="header" href="#211-ä¼ ç»Ÿæ–¹æ¡ˆ-vs-crush">2.1.1 ä¼ ç»Ÿæ–¹æ¡ˆ vs CRUSH</a></h4>
<p><strong>ä¼ ç»Ÿæ–¹æ¡ˆï¼ˆä¸­å¿ƒåŒ–å…ƒæ•°æ®ï¼‰</strong>ï¼š</p>
<pre><code>ä¼˜ç‚¹ï¼šå®ç°ç®€å•
ç¼ºç‚¹ï¼š
- å…ƒæ•°æ®æœåŠ¡å™¨æˆä¸ºç“¶é¢ˆ
- å•ç‚¹æ•…éšœé£é™©
- æ‰©å±•æ€§å—é™
</code></pre>
<p><strong>CRUSH æ–¹æ¡ˆï¼ˆå»ä¸­å¿ƒåŒ–ï¼‰</strong>ï¼š</p>
<pre><code>ä¼˜ç‚¹ï¼š
- æ— éœ€æŸ¥è¯¢å…ƒæ•°æ®æœåŠ¡å™¨
- å®¢æˆ·ç«¯å’Œ OSD éƒ½èƒ½è®¡ç®—æ•°æ®ä½ç½®
- çº¿æ€§æ‰©å±•
- æ”¯æŒå¤æ‚çš„æ•…éšœåŸŸ
ç¼ºç‚¹ï¼š
- ç®—æ³•å¤æ‚åº¦è¾ƒé«˜
</code></pre>
<h3 id="22-crush-map-ç»“æ„"><a class="header" href="#22-crush-map-ç»“æ„">2.2 CRUSH Map ç»“æ„</a></h3>
<p>CRUSH Map å®šä¹‰äº†é›†ç¾¤çš„ç‰©ç†æ‹“æ‰‘å’Œæ•°æ®æ”¾ç½®è§„åˆ™ã€‚</p>
<h4 id="221-å±‚æ¬¡ç»“æ„"><a class="header" href="#221-å±‚æ¬¡ç»“æ„">2.2.1 å±‚æ¬¡ç»“æ„</a></h4>
<pre><code>root (é›†ç¾¤æ ¹)
  â”œâ”€ datacenter (æ•°æ®ä¸­å¿ƒ)
  â”‚   â”œâ”€ room (æœºæˆ¿)
  â”‚   â”‚   â”œâ”€ rack (æœºæ¶)
  â”‚   â”‚   â”‚   â”œâ”€ host (ä¸»æœº)
  â”‚   â”‚   â”‚   â”‚   â”œâ”€ osd.0
  â”‚   â”‚   â”‚   â”‚   â”œâ”€ osd.1
  â”‚   â”‚   â”‚   â”‚   â””â”€ osd.2
  â”‚   â”‚   â”‚   â””â”€ host (ä¸»æœº)
  â”‚   â”‚   â”‚       â”œâ”€ osd.3
  â”‚   â”‚   â”‚       â””â”€ osd.4
  â”‚   â”‚   â””â”€ rack
  â”‚   â””â”€ room
  â””â”€ datacenter
</code></pre>
<h4 id="222-crush-map-ç»„æˆ"><a class="header" href="#222-crush-map-ç»„æˆ">2.2.2 CRUSH Map ç»„æˆ</a></h4>
<ol>
<li><strong>Devicesï¼ˆè®¾å¤‡ï¼‰</strong>ï¼šç‰©ç† OSD åˆ—è¡¨</li>
<li><strong>Bucketsï¼ˆæ¡¶ï¼‰</strong>ï¼šå±‚æ¬¡ç»“æ„ä¸­çš„å®¹å™¨</li>
<li><strong>Rulesï¼ˆè§„åˆ™ï¼‰</strong>ï¼šæ•°æ®æ”¾ç½®ç­–ç•¥</li>
</ol>
<p><strong>æŸ¥çœ‹ CRUSH Map</strong>ï¼š</p>
<pre><code class="language-bash"># å¯¼å‡º CRUSH Mapï¼ˆäºŒè¿›åˆ¶ï¼‰
ceph osd getcrushmap -o crushmap.bin

# åç¼–è¯‘ä¸ºæ–‡æœ¬
crushtool -d crushmap.bin -o crushmap.txt

# æŸ¥çœ‹å†…å®¹
cat crushmap.txt
</code></pre>
<p><strong>CRUSH Map ç¤ºä¾‹</strong>ï¼š</p>
<pre><code># devices
device 0 osd.0 class hdd
device 1 osd.1 class ssd
device 2 osd.2 class hdd

# types
type 0 osd
type 1 host
type 2 rack
type 3 datacenter
type 4 root

# buckets
host node1 {
    id -2
    alg straw2
    hash 0  # rjenkins1
    item osd.0 weight 1.000
    item osd.1 weight 1.000
}

host node2 {
    id -3
    alg straw2
    hash 0
    item osd.2 weight 1.000
}

rack rack1 {
    id -4
    alg straw2
    hash 0
    item node1 weight 2.000
    item node2 weight 1.000
}

root default {
    id -1
    alg straw2
    hash 0
    item rack1 weight 3.000
}

# rules
rule replicated_rule {
    id 0
    type replicated
    min_size 1
    max_size 10
    step take default
    step chooseleaf firstn 0 type host
    step emit
}
</code></pre>
<h3 id="23-crush-ç®—æ³•å·¥ä½œåŸç†"><a class="header" href="#23-crush-ç®—æ³•å·¥ä½œåŸç†">2.3 CRUSH ç®—æ³•å·¥ä½œåŸç†</a></h3>
<h4 id="231-æ•°æ®æ”¾ç½®æµç¨‹"><a class="header" href="#231-æ•°æ®æ”¾ç½®æµç¨‹">2.3.1 æ•°æ®æ”¾ç½®æµç¨‹</a></h4>
<pre><code>è¾“å…¥ï¼šPG ID (å¦‚ 1.7a)
è¾“å‡ºï¼šOSD åˆ—è¡¨ (å¦‚ [osd.5, osd.12, osd.23])

æ­¥éª¤ï¼š
1. æ ¹æ® PG ID ç”Ÿæˆä¼ªéšæœºæ•°
2. ä» root å¼€å§‹éå† CRUSH Map
3. æ ¹æ®è§„åˆ™é€‰æ‹©å­èŠ‚ç‚¹
4. è€ƒè™‘æƒé‡è¿›è¡Œéšæœºé€‰æ‹©
5. è€ƒè™‘æ•…éšœåŸŸéš”ç¦»
6. è¿”å› OSD åˆ—è¡¨
</code></pre>
<h4 id="232-é€‰æ‹©ç®—æ³•"><a class="header" href="#232-é€‰æ‹©ç®—æ³•">2.3.2 é€‰æ‹©ç®—æ³•</a></h4>
<p>CRUSH æ”¯æŒå¤šç§æ¡¶é€‰æ‹©ç®—æ³•ï¼š</p>
<p><strong>1. Uniform</strong></p>
<ul>
<li>é€‚ç”¨åœºæ™¯ï¼šæ‰€æœ‰è®¾å¤‡æƒé‡ç›¸åŒ</li>
<li>ç‰¹ç‚¹ï¼šæœ€å¿«ï¼Œä½†ä¸çµæ´»</li>
</ul>
<p><strong>2. List</strong></p>
<ul>
<li>é€‚ç”¨åœºæ™¯ï¼šæ‰©å±•åœºæ™¯ï¼Œæ–°å¢è®¾å¤‡</li>
<li>ç‰¹ç‚¹ï¼šçº¿æ€§æŸ¥æ‰¾</li>
</ul>
<p><strong>3. Tree</strong></p>
<ul>
<li>é€‚ç”¨åœºæ™¯ï¼šå¤§é‡è®¾å¤‡</li>
<li>ç‰¹ç‚¹ï¼šO(log n) å¤æ‚åº¦</li>
</ul>
<p><strong>4. Straw</strong></p>
<ul>
<li>é€‚ç”¨åœºæ™¯ï¼šé€šç”¨åœºæ™¯</li>
<li>ç‰¹ç‚¹ï¼šå‡åŒ€åˆ†å¸ƒï¼Œä½†æ·»åŠ è®¾å¤‡æ—¶é‡åˆ†å¸ƒè¾ƒå¤š</li>
</ul>
<p><strong>5. Straw2ï¼ˆæ¨èï¼‰</strong></p>
<ul>
<li>é€‚ç”¨åœºæ™¯ï¼šå½“å‰é»˜è®¤ç®—æ³•</li>
<li>ç‰¹ç‚¹ï¼šæ”¹è¿›çš„ Strawï¼Œå‡å°‘ä¸å¿…è¦çš„æ•°æ®è¿ç§»</li>
</ul>
<h4 id="233-æƒé‡è®¡ç®—"><a class="header" href="#233-æƒé‡è®¡ç®—">2.3.3 æƒé‡è®¡ç®—</a></h4>
<p>OSD æƒé‡é€šå¸¸åŸºäºå®¹é‡ï¼š</p>
<pre><code class="language-bash"># 1TB ç£ç›˜ = 1.0 æƒé‡
# 2TB ç£ç›˜ = 2.0 æƒé‡
# 500GB SSD = 0.5 æƒé‡

# æŸ¥çœ‹ OSD æƒé‡
ceph osd tree

# è°ƒæ•´æƒé‡
ceph osd crush reweight osd.0 0.5

# ä¸´æ—¶è°ƒæ•´æƒé‡ï¼ˆä¸ä¿®æ”¹ CRUSH Mapï¼‰
ceph osd reweight osd.0 0.8
</code></pre>
<h3 id="24-crush-è§„åˆ™è¯¦è§£"><a class="header" href="#24-crush-è§„åˆ™è¯¦è§£">2.4 CRUSH è§„åˆ™è¯¦è§£</a></h3>
<h4 id="241-è§„åˆ™è¯­æ³•"><a class="header" href="#241-è§„åˆ™è¯­æ³•">2.4.1 è§„åˆ™è¯­æ³•</a></h4>
<pre><code>rule &lt;rule_name&gt; {
    id &lt;rule_id&gt;
    type [replicated|erasure]
    min_size &lt;min_size&gt;
    max_size &lt;max_size&gt;
    step take &lt;root&gt;
    step [choose|chooseleaf] [firstn|indep] &lt;N&gt; type &lt;type&gt;
    step emit
}
</code></pre>
<p><strong>å‚æ•°è¯´æ˜</strong>ï¼š</p>
<ul>
<li><code>take</code>: é€‰æ‹©èµ·å§‹èŠ‚ç‚¹</li>
<li><code>choose</code>: é€‰æ‹© N ä¸ªæŒ‡å®šç±»å‹çš„é¡¹</li>
<li><code>chooseleaf</code>: é€‰æ‹© N ä¸ªæŒ‡å®šç±»å‹é¡¹ä¸‹çš„æ‰€æœ‰å¶å­èŠ‚ç‚¹</li>
<li><code>firstn</code>: å‰¯æœ¬æ¨¡å¼ï¼ˆæœ‰åºï¼‰</li>
<li><code>indep</code>: çº åˆ ç æ¨¡å¼ï¼ˆç‹¬ç«‹ï¼‰</li>
<li><code>N=0</code>: è¡¨ç¤º pool çš„ size æ•°é‡</li>
</ul>
<h4 id="242-å®æˆ˜ç¤ºä¾‹è‡ªå®šä¹‰è§„åˆ™"><a class="header" href="#242-å®æˆ˜ç¤ºä¾‹è‡ªå®šä¹‰è§„åˆ™">2.4.2 å®æˆ˜ç¤ºä¾‹ï¼šè‡ªå®šä¹‰è§„åˆ™</a></h4>
<p><strong>åœºæ™¯ 1ï¼šSSD å’Œ HDD åˆ†ç¦»</strong></p>
<pre><code class="language-bash"># åˆ›å»º SSD è§„åˆ™
rule ssd_rule {
    id 1
    type replicated
    min_size 1
    max_size 10
    step take default class ssd
    step chooseleaf firstn 0 type host
    step emit
}

# åˆ›å»º HDD è§„åˆ™
rule hdd_rule {
    id 2
    type replicated
    min_size 1
    max_size 10
    step take default class hdd
    step chooseleaf firstn 0 type host
    step emit
}

# åº”ç”¨è§„åˆ™åˆ° Pool
ceph osd pool set mypool crush_rule ssd_rule
</code></pre>
<p><strong>åœºæ™¯ 2ï¼šè·¨æœºæˆ¿å†—ä½™</strong></p>
<pre><code class="language-bash">rule cross_datacenter {
    id 3
    type replicated
    min_size 1
    max_size 10
    step take default
    step choose firstn 2 type datacenter
    step chooseleaf firstn 2 type host
    step emit
}
</code></pre>
<p><strong>åœºæ™¯ 3ï¼šæ··åˆéƒ¨ç½²ç­–ç•¥</strong></p>
<pre><code class="language-bash"># ä¸»å‰¯æœ¬åœ¨ SSDï¼Œå…¶ä»–å‰¯æœ¬åœ¨ HDD
rule hybrid_rule {
    id 4
    type replicated
    min_size 1
    max_size 10
    step take default class ssd
    step chooseleaf firstn 1 type host
    step emit
    step take default class hdd
    step chooseleaf firstn -1 type host
    step emit
}
</code></pre>
<h3 id="25-æ•…éšœåŸŸä¸æ•°æ®å¯é æ€§"><a class="header" href="#25-æ•…éšœåŸŸä¸æ•°æ®å¯é æ€§">2.5 æ•…éšœåŸŸä¸æ•°æ®å¯é æ€§</a></h3>
<h4 id="251-æ•…éšœåŸŸé…ç½®"><a class="header" href="#251-æ•…éšœåŸŸé…ç½®">2.5.1 æ•…éšœåŸŸé…ç½®</a></h4>
<pre><code class="language-bash"># é…ç½®ä¸»æœºçº§åˆ«æ•…éšœåŸŸï¼ˆé»˜è®¤ï¼‰
# ç¡®ä¿å‰¯æœ¬åˆ†å¸ƒåœ¨ä¸åŒä¸»æœº

# é…ç½®æœºæ¶çº§åˆ«æ•…éšœåŸŸ
rule rack_failure_domain {
    step chooseleaf firstn 0 type rack
}

# é…ç½®æ•°æ®ä¸­å¿ƒçº§åˆ«æ•…éšœåŸŸ
rule datacenter_failure_domain {
    step chooseleaf firstn 0 type datacenter
}
</code></pre>
<h4 id="252-å¯é æ€§åˆ†æ"><a class="header" href="#252-å¯é æ€§åˆ†æ">2.5.2 å¯é æ€§åˆ†æ</a></h4>
<p><strong>3 å‰¯æœ¬ + ä¸»æœºçº§æ•…éšœåŸŸ</strong>ï¼š</p>
<pre><code>å¯é æ€§ï¼šå¯å®¹å¿ä»»æ„ 2 å°ä¸»æœºæ•…éšœ
æ•°æ®å¯ç”¨æ€§ï¼š99.999%
å­˜å‚¨å¼€é”€ï¼š3x
</code></pre>
<p><strong>çº åˆ ç  8+3 + æœºæ¶çº§æ•…éšœåŸŸ</strong>ï¼š</p>
<pre><code>å¯é æ€§ï¼šå¯å®¹å¿ä»»æ„ 3 ä¸ªæœºæ¶æ•…éšœ
æ•°æ®å¯ç”¨æ€§ï¼š99.9999%
å­˜å‚¨å¼€é”€ï¼š1.375x
</code></pre>
<hr />
<h2 id="ç¬¬ä¸‰ç« ceph-å­˜å‚¨æ¥å£è¯¦è§£"><a class="header" href="#ç¬¬ä¸‰ç« ceph-å­˜å‚¨æ¥å£è¯¦è§£">ç¬¬ä¸‰ç« ï¼šCeph å­˜å‚¨æ¥å£è¯¦è§£</a></h2>
<h3 id="31-rbdå—å­˜å‚¨æ¥å£"><a class="header" href="#31-rbdå—å­˜å‚¨æ¥å£">3.1 RBDï¼šå—å­˜å‚¨æ¥å£</a></h3>
<h4 id="311-rbd-æ¦‚è¿°"><a class="header" href="#311-rbd-æ¦‚è¿°">3.1.1 RBD æ¦‚è¿°</a></h4>
<p>RBD (RADOS Block Device) æä¾›ç±»ä¼¼ä¼ ç»Ÿ SAN çš„å—å­˜å‚¨æœåŠ¡ã€‚</p>
<p><strong>ç‰¹æ€§</strong>ï¼š</p>
<ul>
<li>ç²¾ç®€é…ç½®ï¼ˆThin Provisioningï¼‰</li>
<li>å¿«ç…§å’Œå…‹éš†</li>
<li>åŸç”Ÿæ”¯æŒ Linux å†…æ ¸</li>
<li>æ”¯æŒåˆ†å±‚å­˜å‚¨ï¼ˆLayeringï¼‰</li>
<li>æ”¯æŒ QoS é™åˆ¶</li>
</ul>
<h4 id="312-rbd-æ¶æ„"><a class="header" href="#312-rbd-æ¶æ„">3.1.2 RBD æ¶æ„</a></h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VM / Container â”‚
â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ /dev/rbd0 â”‚  â”‚ â† è™šæ‹Ÿå—è®¾å¤‡
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ librbd  â”‚ â† RBD å®¢æˆ·ç«¯åº“
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ librados â”‚ â† RADOS æ¥å£
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ RADOS å¯¹è±¡å­˜å‚¨       â”‚
    â”‚ [obj1][obj2][obj3]  â”‚ â† 4MB å¯¹è±¡
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="313-rbd-å®æˆ˜æ“ä½œ"><a class="header" href="#313-rbd-å®æˆ˜æ“ä½œ">3.1.3 RBD å®æˆ˜æ“ä½œ</a></h4>
<p><strong>åˆ›å»ºå’Œä½¿ç”¨ RBD é•œåƒ</strong>ï¼š</p>
<pre><code class="language-bash"># 1. åˆ›å»º Pool
ceph osd pool create rbd_pool 128 128

# 2. åˆå§‹åŒ– Pool ä¸º RBD ä½¿ç”¨
rbd pool init rbd_pool

# 3. åˆ›å»º RBD é•œåƒï¼ˆ10GBï¼‰
rbd create --size 10240 rbd_pool/image1

# 4. æŸ¥çœ‹é•œåƒä¿¡æ¯
rbd info rbd_pool/image1
rbd image 'image1':
    size 10 GiB in 2560 objects
    order 22 (4 MiB objects)
    snapshot_count: 0
    id: 106b6b8b4567
    block_name_prefix: rbd_data.106b6b8b4567
    format: 2
    features: layering, exclusive-lock, object-map, fast-diff, deep-flatten
    op_features:
    flags:
    create_timestamp: Wed Dec 13 10:30:00 2023

# 5. æ˜ å°„åˆ°å†…æ ¸ï¼ˆéœ€è¦ root æƒé™ï¼‰
sudo rbd map rbd_pool/image1
/dev/rbd0

# 6. æ ¼å¼åŒ–å’ŒæŒ‚è½½
sudo mkfs.ext4 /dev/rbd0
sudo mkdir /mnt/ceph-disk
sudo mount /dev/rbd0 /mnt/ceph-disk

# 7. ä½¿ç”¨
echo "Hello Ceph" &gt; /mnt/ceph-disk/test.txt

# 8. å¸è½½
sudo umount /mnt/ceph-disk
sudo rbd unmap /dev/rbd0

# 9. æŸ¥çœ‹æ˜ å°„
rbd showmapped
</code></pre>
<p><strong>RBD å¿«ç…§å’Œå…‹éš†</strong>ï¼š</p>
<pre><code class="language-bash"># åˆ›å»ºå¿«ç…§
rbd snap create rbd_pool/image1@snap1

# åˆ—å‡ºå¿«ç…§
rbd snap ls rbd_pool/image1

# å›æ»šå¿«ç…§
rbd snap rollback rbd_pool/image1@snap1

# ä¿æŠ¤å¿«ç…§ï¼ˆç”¨äºå…‹éš†ï¼‰
rbd snap protect rbd_pool/image1@snap1

# å…‹éš†é•œåƒï¼ˆå¿«é€Ÿåˆ›å»ºå‰¯æœ¬ï¼‰
rbd clone rbd_pool/image1@snap1 rbd_pool/image1_clone

# æŸ¥çœ‹å…‹éš†å…³ç³»
rbd children rbd_pool/image1@snap1

# æ‰å¹³åŒ–å…‹éš†ï¼ˆè§£é™¤ä¾èµ–ï¼‰
rbd flatten rbd_pool/image1_clone

# å–æ¶ˆä¿æŠ¤
rbd snap unprotect rbd_pool/image1@snap1

# åˆ é™¤å¿«ç…§
rbd snap rm rbd_pool/image1@snap1

# æ¸…é™¤æ‰€æœ‰å¿«ç…§
rbd snap purge rbd_pool/image1
</code></pre>
<p><strong>RBD é•œåƒç‰¹æ€§</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹æ”¯æŒçš„ç‰¹æ€§
rbd feature list

# åˆ›å»ºæ—¶æŒ‡å®šç‰¹æ€§
rbd create --size 10G --image-feature layering,exclusive-lock rbd_pool/image2

# ç¦ç”¨æŸäº›ç‰¹æ€§ï¼ˆæé«˜å…¼å®¹æ€§ï¼‰
rbd feature disable rbd_pool/image1 object-map fast-diff deep-flatten

# å¯ç”¨ç‰¹æ€§
rbd feature enable rbd_pool/image1 exclusive-lock
</code></pre>
<p><strong>RBD æ€§èƒ½é…ç½®</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹ I/O ç»Ÿè®¡
rbd perf image iostat

# é…ç½® QoSï¼ˆIOPS é™åˆ¶ï¼‰
rbd config image set rbd_pool/image1 rbd_qos_iops_limit 1000

# é…ç½® QoSï¼ˆå¸¦å®½é™åˆ¶ï¼ŒMB/sï¼‰
rbd config image set rbd_pool/image1 rbd_qos_bw_limit 100

# æŸ¥çœ‹é…ç½®
rbd config image get rbd_pool/image1
</code></pre>
<h4 id="314-rbd-é«˜çº§ç‰¹æ€§"><a class="header" href="#314-rbd-é«˜çº§ç‰¹æ€§">3.1.4 RBD é«˜çº§ç‰¹æ€§</a></h4>
<p><strong>åˆ†å±‚å­˜å‚¨ï¼ˆLayeringï¼‰</strong>ï¼š</p>
<pre><code class="language-bash"># åˆ›å»ºçˆ¶é•œåƒï¼ˆé»„é‡‘é•œåƒï¼‰
rbd create --size 10G rbd_pool/golden_image
# ... å®‰è£…æ“ä½œç³»ç»Ÿå’Œè½¯ä»¶ ...

# åˆ›å»ºå¿«ç…§
rbd snap create rbd_pool/golden_image@v1.0
rbd snap protect rbd_pool/golden_image@v1.0

# å¿«é€Ÿå…‹éš†å‡ºå¤šä¸ªå®ä¾‹
for i in {1..10}; do
    rbd clone rbd_pool/golden_image@v1.0 rbd_pool/vm_$i
done

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨ï¼ˆç²¾ç®€é…ç½®ï¼‰
rbd du rbd_pool
</code></pre>
<p><strong>RBD é•œåƒå¯¼å…¥å¯¼å‡º</strong>ï¼š</p>
<pre><code class="language-bash"># å¯¼å‡ºé•œåƒ
rbd export rbd_pool/image1 /backup/image1.img

# å¯¼å‡ºå·®å¼‚ï¼ˆå¢é‡å¤‡ä»½ï¼‰
rbd export-diff rbd_pool/image1@snap1 /backup/image1-snap1.diff
rbd export-diff rbd_pool/image1@snap2 --from-snap snap1 /backup/image1-snap2.diff

# å¯¼å…¥é•œåƒ
rbd import /backup/image1.img rbd_pool/image1_restore

# å¯¼å…¥å·®å¼‚
rbd import-diff /backup/image1-snap1.diff rbd_pool/image1_restore
</code></pre>
<h3 id="32-cephfsæ–‡ä»¶ç³»ç»Ÿæ¥å£"><a class="header" href="#32-cephfsæ–‡ä»¶ç³»ç»Ÿæ¥å£">3.2 CephFSï¼šæ–‡ä»¶ç³»ç»Ÿæ¥å£</a></h3>
<h4 id="321-cephfs-æ¦‚è¿°"><a class="header" href="#321-cephfs-æ¦‚è¿°">3.2.1 CephFS æ¦‚è¿°</a></h4>
<p>CephFS æ˜¯ Ceph çš„ POSIX å…¼å®¹åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿã€‚</p>
<p><strong>ç‰¹æ€§</strong>ï¼š</p>
<ul>
<li>å®Œå…¨ POSIX å…¼å®¹</li>
<li>æ”¯æŒå¤šä¸ªæ–‡ä»¶ç³»ç»Ÿ</li>
<li>åŠ¨æ€å…ƒæ•°æ®åˆ†åŒº</li>
<li>å¤šæ´» MDSï¼ˆActive-Activeï¼‰</li>
<li>å¿«ç…§æ”¯æŒ</li>
</ul>
<h4 id="322-cephfs-æ¶æ„"><a class="header" href="#322-cephfs-æ¶æ„">3.2.2 CephFS æ¶æ„</a></h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        å®¢æˆ·ç«¯åº”ç”¨                   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ kernel â”‚              â”‚  FUSE   â”‚
â”‚ client â”‚              â”‚ client  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   MDS Cluster   â”‚ â† å…ƒæ•°æ®ç®¡ç†
    â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”    â”‚
    â”‚  â”‚MDSâ”‚ â”‚MDSâ”‚    â”‚
    â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RADOS Cluster  â”‚
    â”‚                 â”‚
    â”‚ [metadata pool] â”‚ â† å…ƒæ•°æ®å­˜å‚¨
    â”‚   [data pool]   â”‚ â† æ–‡ä»¶æ•°æ®å­˜å‚¨
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="323-éƒ¨ç½²-cephfs"><a class="header" href="#323-éƒ¨ç½²-cephfs">3.2.3 éƒ¨ç½² CephFS</a></h4>
<p><strong>æ­¥éª¤ 1ï¼šåˆ›å»ºå­˜å‚¨æ± </strong></p>
<pre><code class="language-bash"># åˆ›å»ºå…ƒæ•°æ®æ± ï¼ˆä½¿ç”¨ SSDï¼Œè¾ƒå°ï¼‰
ceph osd pool create cephfs_metadata 64 64

# åˆ›å»ºæ•°æ®æ± ï¼ˆä½¿ç”¨ HDDï¼Œå¤§å®¹é‡ï¼‰
ceph osd pool create cephfs_data 128 128

# ä¸ºå…ƒæ•°æ®æ± å¯ç”¨åº”ç”¨æ ‡ç­¾
ceph osd pool application enable cephfs_metadata cephfs
ceph osd pool application enable cephfs_data cephfs
</code></pre>
<p><strong>æ­¥éª¤ 2ï¼šåˆ›å»ºæ–‡ä»¶ç³»ç»Ÿ</strong></p>
<pre><code class="language-bash"># åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿ
ceph fs new mycephfs cephfs_metadata cephfs_data

# æŸ¥çœ‹æ–‡ä»¶ç³»ç»ŸçŠ¶æ€
ceph fs ls
ceph fs status mycephfs
</code></pre>
<p><strong>æ­¥éª¤ 3ï¼šéƒ¨ç½² MDS</strong></p>
<pre><code class="language-bash"># ä½¿ç”¨ cephadm éƒ¨ç½² MDS
ceph orch apply mds mycephfs --placement="3 node1 node2 node3"

# æ‰‹åŠ¨éƒ¨ç½²ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
# åœ¨ node1 ä¸Š
mkdir -p /var/lib/ceph/mds/ceph-node1
ceph-authtool --create-keyring /var/lib/ceph/mds/ceph-node1/keyring --gen-key -n mds.node1
ceph auth add mds.node1 osd "allow rwx" mds "allow" mon "allow profile mds" -i /var/lib/ceph/mds/ceph-node1/keyring
systemctl start ceph-mds@node1

# æŸ¥çœ‹ MDS çŠ¶æ€
ceph mds stat
ceph fs dump
</code></pre>
<p><strong>æ­¥éª¤ 4ï¼šå®¢æˆ·ç«¯æŒ‚è½½</strong></p>
<p><strong>æ–¹æ³• 1ï¼šå†…æ ¸å®¢æˆ·ç«¯ï¼ˆæ¨èï¼‰</strong></p>
<pre><code class="language-bash"># è·å– admin å¯†é’¥
ceph auth get-key client.admin &gt; /etc/ceph/admin.secret

# æŒ‚è½½
mount -t ceph mon1:6789,mon2:6789,mon3:6789:/ /mnt/cephfs -o name=admin,secretfile=/etc/ceph/admin.secret

# æˆ–ä½¿ç”¨ mount.ceph
mount -t ceph :/ /mnt/cephfs -o name=admin,secret=AQBxxxx...

# è‡ªåŠ¨æŒ‚è½½ï¼ˆ/etc/fstabï¼‰
mon1:6789,mon2:6789,mon3:6789:/ /mnt/cephfs ceph name=admin,secretfile=/etc/ceph/admin.secret,_netdev 0 2
</code></pre>
<p><strong>æ–¹æ³• 2ï¼šFUSE å®¢æˆ·ç«¯</strong></p>
<pre><code class="language-bash"># å®‰è£… ceph-fuse
apt install ceph-fuse  # Ubuntu/Debian
yum install ceph-fuse  # CentOS/RHEL

# æŒ‚è½½
ceph-fuse -m mon1:6789,mon2:6789 /mnt/cephfs

# å¸è½½
fusermount -u /mnt/cephfs
</code></pre>
<h4 id="324-cephfs-é«˜çº§ç‰¹æ€§"><a class="header" href="#324-cephfs-é«˜çº§ç‰¹æ€§">3.2.4 CephFS é«˜çº§ç‰¹æ€§</a></h4>
<p><strong>å¤šæ´» MDS é…ç½®</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹å½“å‰ MDS é…ç½®
ceph fs get mycephfs

# è®¾ç½®æœ€å¤§æ´»è·ƒ MDS æ•°é‡ï¼ˆæé«˜å…ƒæ•°æ®æ€§èƒ½ï¼‰
ceph fs set mycephfs max_mds 2

# è®¾ç½® standby-replayï¼ˆå¿«é€Ÿæ•…éšœåˆ‡æ¢ï¼‰
ceph fs set mycephfs allow_standby_replay true

# å›ºå®š MDS rank
ceph mds pin mds.node1 1
</code></pre>
<p><strong>ç›®å½•å¸ƒå±€ï¼ˆLayoutï¼‰</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹ç›®å½•å¸ƒå±€
getfattr -n ceph.dir.layout /mnt/cephfs/mydir

# è®¾ç½®å¯¹è±¡å¤§å°ï¼ˆ4MBï¼‰
setfattr -n ceph.dir.layout.object_size -v 4194304 /mnt/cephfs/mydir

# è®¾ç½®æ¡å¸¦å¤§å°
setfattr -n ceph.dir.layout.stripe_unit -v 4194304 /mnt/cephfs/mydir

# è®¾ç½®æ¡å¸¦æ•°é‡
setfattr -n ceph.dir.layout.stripe_count -v 2 /mnt/cephfs/mydir

# æŒ‡å®šæ•°æ®æ± 
setfattr -n ceph.dir.layout.pool -v cephfs_data_ssd /mnt/cephfs/hot_data
</code></pre>
<p><strong>é…é¢ç®¡ç†</strong>ï¼š</p>
<pre><code class="language-bash"># è®¾ç½®ç›®å½•æœ€å¤§å­—èŠ‚æ•°ï¼ˆ10GBï¼‰
setfattr -n ceph.quota.max_bytes -v 10737418240 /mnt/cephfs/project1

# è®¾ç½®ç›®å½•æœ€å¤§æ–‡ä»¶æ•°
setfattr -n ceph.quota.max_files -v 100000 /mnt/cephfs/project1

# æŸ¥çœ‹é…é¢
getfattr -n ceph.quota.max_bytes /mnt/cephfs/project1
</code></pre>
<p><strong>å¿«ç…§åŠŸèƒ½</strong>ï¼š</p>
<pre><code class="language-bash"># å¯ç”¨å¿«ç…§ï¼ˆé»˜è®¤å·²å¯ç”¨ï¼‰
ceph fs set mycephfs allow_new_snaps true

# åˆ›å»ºå¿«ç…§
mkdir /mnt/cephfs/mydir/.snap/snapshot1

# æŸ¥çœ‹å¿«ç…§
ls /mnt/cephfs/mydir/.snap/

# è®¿é—®å¿«ç…§æ•°æ®
ls /mnt/cephfs/mydir/.snap/snapshot1/

# åˆ é™¤å¿«ç…§
rmdir /mnt/cephfs/mydir/.snap/snapshot1
</code></pre>
<p><strong>å­ç›®å½•æŒ‚è½½</strong>ï¼š</p>
<pre><code class="language-bash"># æŒ‚è½½å­ç›®å½•
mount -t ceph mon1:6789:/subdir /mnt/mysubdir -o name=admin,secret=xxx

# é™åˆ¶å®¢æˆ·ç«¯è®¿é—®æƒé™
ceph fs authorize mycephfs client.user1 /project1 rw
ceph auth get client.user1
</code></pre>
<h3 id="33-rgwå¯¹è±¡å­˜å‚¨æ¥å£"><a class="header" href="#33-rgwå¯¹è±¡å­˜å‚¨æ¥å£">3.3 RGWï¼šå¯¹è±¡å­˜å‚¨æ¥å£</a></h3>
<h4 id="331-rgw-æ¦‚è¿°"><a class="header" href="#331-rgw-æ¦‚è¿°">3.3.1 RGW æ¦‚è¿°</a></h4>
<p>RGW (RADOS Gateway) æä¾› S3 å’Œ Swift å…¼å®¹çš„å¯¹è±¡å­˜å‚¨æ¥å£ã€‚</p>
<p><strong>ç‰¹æ€§</strong>ï¼š</p>
<ul>
<li>S3 API å…¼å®¹</li>
<li>Swift API å…¼å®¹</li>
<li>å¤šç§Ÿæˆ·æ”¯æŒ</li>
<li>å¤šç«™ç‚¹å¤åˆ¶</li>
<li>ç‰ˆæœ¬æ§åˆ¶</li>
<li>ç”Ÿå‘½å‘¨æœŸç®¡ç†</li>
</ul>
<h4 id="332-rgw-æ¶æ„"><a class="header" href="#332-rgw-æ¶æ„">3.3.2 RGW æ¶æ„</a></h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      åº”ç”¨ç¨‹åº                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚S3 SDK  â”‚      â”‚Swift SDKâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ HTTP/HTTPS
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ RGW (radosgw)  â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚   â”‚ Beast  â”‚   â”‚ â† HTTP æœåŠ¡å™¨
        â”‚   â”‚ / Civetwebâ”‚  â”‚
        â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜   â”‚
        â”‚        â”‚       â”‚
        â”‚   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”‚
        â”‚   â”‚ librgw  â”‚  â”‚ â† RGW é€»è¾‘
        â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   RADOS Cluster     â”‚
        â”‚                     â”‚
        â”‚  [.rgw.root]        â”‚ â† é…ç½®ä¿¡æ¯
        â”‚  [.rgw.control]     â”‚ â† æ§åˆ¶ä¿¡æ¯
        â”‚  [.rgw.meta]        â”‚ â† å…ƒæ•°æ®
        â”‚  [.rgw.log]         â”‚ â† æ—¥å¿—
        â”‚  [.rgw.buckets.*]   â”‚ â† å¯¹è±¡æ•°æ®
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="333-éƒ¨ç½²-rgw"><a class="header" href="#333-éƒ¨ç½²-rgw">3.3.3 éƒ¨ç½² RGW</a></h4>
<p><strong>æ–¹æ³• 1ï¼šä½¿ç”¨ cephadmï¼ˆæ¨èï¼‰</strong></p>
<pre><code class="language-bash"># éƒ¨ç½² RGW
ceph orch apply rgw myrgw --placement="2 node1 node2" --port=8080

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
ceph orch ls rgw
ceph orch ps --daemon_type rgw

# æŸ¥çœ‹ RGW ä¿¡æ¯
radosgw-admin realm list
radosgw-admin zonegroup list
radosgw-admin zone list
</code></pre>
<p><strong>æ–¹æ³• 2ï¼šæ‰‹åŠ¨éƒ¨ç½²</strong></p>
<pre><code class="language-bash"># 1. åˆ›å»º RGW å¯†é’¥
ceph auth get-or-create client.rgw.node1 mon 'allow rw' osd 'allow rwx' -o /etc/ceph/ceph.client.rgw.node1.keyring

# 2. é…ç½®æ–‡ä»¶ï¼ˆ/etc/ceph/ceph.confï¼‰
cat &gt;&gt; /etc/ceph/ceph.conf &lt;&lt; EOF
[client.rgw.node1]
host = node1
rgw_frontends = "beast port=8080"
rgw_thread_pool_size = 512
EOF

# 3. å¯åŠ¨æœåŠ¡
systemctl start ceph-radosgw@rgw.node1
systemctl enable ceph-radosgw@rgw.node1

# 4. éªŒè¯
curl http://node1:8080
</code></pre>
<h4 id="334-rgw-ç”¨æˆ·å’Œæƒé™ç®¡ç†"><a class="header" href="#334-rgw-ç”¨æˆ·å’Œæƒé™ç®¡ç†">3.3.4 RGW ç”¨æˆ·å’Œæƒé™ç®¡ç†</a></h4>
<pre><code class="language-bash"># åˆ›å»ºç”¨æˆ·
radosgw-admin user create --uid=testuser --display-name="Test User" --email=test@example.com

# è¾“å‡ºç¤ºä¾‹ï¼š
{
    "user_id": "testuser",
    "display_name": "Test User",
    "email": "test@example.com",
    "keys": [
        {
            "access_key": "ABCDEFGHIJKLMNOP",
            "secret_key": "1234567890abcdefghijklmnop"
        }
    ]
}

# æŸ¥çœ‹ç”¨æˆ·ä¿¡æ¯
radosgw-admin user info --uid=testuser

# åˆ›å»ºå­ç”¨æˆ·ï¼ˆSwiftï¼‰
radosgw-admin subuser create --uid=testuser --subuser=testuser:swift --access=full

# ç”Ÿæˆæ–°çš„è®¿é—®å¯†é’¥
radosgw-admin key create --uid=testuser --key-type=s3 --gen-access-key --gen-secret

# ä¿®æ”¹ç”¨æˆ·é…é¢
radosgw-admin quota set --quota-scope=user --uid=testuser --max-objects=10000 --max-size=10737418240
radosgw-admin quota enable --quota-scope=user --uid=testuser

# åˆ é™¤ç”¨æˆ·
radosgw-admin user rm --uid=testuser
</code></pre>
<h4 id="335-ä½¿ç”¨-s3-api"><a class="header" href="#335-ä½¿ç”¨-s3-api">3.3.5 ä½¿ç”¨ S3 API</a></h4>
<p><strong>ä½¿ç”¨ AWS CLI</strong>ï¼š</p>
<pre><code class="language-bash"># å®‰è£… AWS CLI
pip install awscli

# é…ç½®
aws configure
AWS Access Key ID: ABCDEFGHIJKLMNOP
AWS Secret Access Key: 1234567890abcdefghijklmnop
Default region name: us-east-1
Default output format: json

# é…ç½® endpointï¼ˆ~/.aws/configï¼‰
[default]
s3 =
    endpoint_url = http://node1:8080
    signature_version = s3v4

# åˆ›å»º bucket
aws s3 mb s3://mybucket

# ä¸Šä¼ æ–‡ä»¶
aws s3 cp /path/to/file s3://mybucket/

# åˆ—å‡ºå¯¹è±¡
aws s3 ls s3://mybucket/

# ä¸‹è½½æ–‡ä»¶
aws s3 cp s3://mybucket/file /path/to/local

# åˆ é™¤å¯¹è±¡
aws s3 rm s3://mybucket/file

# åˆ é™¤ bucket
aws s3 rb s3://mybucket --force
</code></pre>
<p><strong>ä½¿ç”¨ Python boto3</strong>ï¼š</p>
<pre><code class="language-python">import boto3

# åˆ›å»º S3 å®¢æˆ·ç«¯
s3 = boto3.client('s3',
    endpoint_url='http://node1:8080',
    aws_access_key_id='ABCDEFGHIJKLMNOP',
    aws_secret_access_key='1234567890abcdefghijklmnop'
)

# åˆ›å»º bucket
s3.create_bucket(Bucket='mybucket')

# ä¸Šä¼ æ–‡ä»¶
with open('/path/to/file', 'rb') as f:
    s3.put_object(Bucket='mybucket', Key='myfile', Body=f)

# åˆ—å‡ºå¯¹è±¡
response = s3.list_objects_v2(Bucket='mybucket')
for obj in response.get('Contents', []):
    print(obj['Key'])

# ä¸‹è½½æ–‡ä»¶
s3.download_file('mybucket', 'myfile', '/path/to/local/file')

# åˆ é™¤å¯¹è±¡
s3.delete_object(Bucket='mybucket', Key='myfile')
</code></pre>
<h4 id="336-rgw-é«˜çº§ç‰¹æ€§"><a class="header" href="#336-rgw-é«˜çº§ç‰¹æ€§">3.3.6 RGW é«˜çº§ç‰¹æ€§</a></h4>
<p><strong>Bucket ç”Ÿå‘½å‘¨æœŸç®¡ç†</strong>ï¼š</p>
<pre><code class="language-json">// lifecycle.json
{
    "Rules": [
        {
            "Id": "DeleteOldObjects",
            "Status": "Enabled",
            "Expiration": {
                "Days": 90
            },
            "Filter": {
                "Prefix": "logs/"
            }
        },
        {
            "Id": "TransitionToArchive",
            "Status": "Enabled",
            "Transitions": [
                {
                    "Days": 30,
                    "StorageClass": "GLACIER"
                }
            ]
        }
    ]
}
</code></pre>
<pre><code class="language-bash"># è®¾ç½®ç”Ÿå‘½å‘¨æœŸ
aws s3api put-bucket-lifecycle-configuration --bucket mybucket --lifecycle-configuration file://lifecycle.json

# æŸ¥çœ‹ç”Ÿå‘½å‘¨æœŸ
aws s3api get-bucket-lifecycle-configuration --bucket mybucket
</code></pre>
<p><strong>ç‰ˆæœ¬æ§åˆ¶</strong>ï¼š</p>
<pre><code class="language-bash"># å¯ç”¨ç‰ˆæœ¬æ§åˆ¶
aws s3api put-bucket-versioning --bucket mybucket --versioning-configuration Status=Enabled

# åˆ—å‡ºå¯¹è±¡ç‰ˆæœ¬
aws s3api list-object-versions --bucket mybucket

# åˆ é™¤ç‰¹å®šç‰ˆæœ¬
aws s3api delete-object --bucket mybucket --key myfile --version-id xxxxx
</code></pre>
<p><strong>é™æ€ç½‘ç«™æ‰˜ç®¡</strong>ï¼š</p>
<pre><code class="language-bash"># é…ç½®é™æ€ç½‘ç«™
aws s3 website s3://mybucket/ --index-document index.html --error-document error.html

# ä¸Šä¼ ç½‘ç«™æ–‡ä»¶
aws s3 cp index.html s3://mybucket/ --acl public-read
</code></pre>
<hr />
<h2 id="ç¬¬å››ç« æ•°æ®å¯é æ€§ä¸æ¢å¤æœºåˆ¶"><a class="header" href="#ç¬¬å››ç« æ•°æ®å¯é æ€§ä¸æ¢å¤æœºåˆ¶">ç¬¬å››ç« ï¼šæ•°æ®å¯é æ€§ä¸æ¢å¤æœºåˆ¶</a></h2>
<h3 id="41-å‰¯æœ¬æœºåˆ¶"><a class="header" href="#41-å‰¯æœ¬æœºåˆ¶">4.1 å‰¯æœ¬æœºåˆ¶</a></h3>
<h4 id="411-å‰¯æœ¬å·¥ä½œåŸç†"><a class="header" href="#411-å‰¯æœ¬å·¥ä½œåŸç†">4.1.1 å‰¯æœ¬å·¥ä½œåŸç†</a></h4>
<p>Ceph é»˜è®¤ä½¿ç”¨å‰¯æœ¬æœºåˆ¶ä¿è¯æ•°æ®å¯é æ€§ã€‚</p>
<p><strong>å†™å…¥æµç¨‹</strong>ï¼š</p>
<pre><code>1. å®¢æˆ·ç«¯è®¡ç®—å¯¹è±¡åº”å­˜å‚¨çš„ PG
2. é€šè¿‡ CRUSH è®¡ç®— PG å¯¹åº”çš„ OSD åˆ—è¡¨ [primary, replica1, replica2]
3. å®¢æˆ·ç«¯è¿æ¥ Primary OSD
4. Primary OSD æ¥æ”¶æ•°æ®å¹¶åŒæ­¥å†™å…¥ replica1 å’Œ replica2
5. æ‰€æœ‰å‰¯æœ¬ç¡®è®¤åï¼ŒPrimary OSD å‘å®¢æˆ·ç«¯è¿”å›æˆåŠŸ
</code></pre>
<p><strong>è¯»å–æµç¨‹</strong>ï¼š</p>
<pre><code>1. å®¢æˆ·ç«¯è®¡ç®—å¯¹è±¡æ‰€åœ¨ PG
2. é€šè¿‡ CRUSH è®¡ç®— OSD åˆ—è¡¨
3. å®¢æˆ·ç«¯ä» Primary OSD è¯»å–æ•°æ®
4. å¦‚æœ Primary æ•…éšœï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° replica
</code></pre>
<h4 id="412-å‰¯æœ¬é…ç½®"><a class="header" href="#412-å‰¯æœ¬é…ç½®">4.1.2 å‰¯æœ¬é…ç½®</a></h4>
<pre><code class="language-bash"># æŸ¥çœ‹ Pool å‰¯æœ¬é…ç½®
ceph osd pool get mypool size
ceph osd pool get mypool min_size

# è®¾ç½®å‰¯æœ¬æ•°
ceph osd pool set mypool size 3    # 3 å‰¯æœ¬
ceph osd pool set mypool min_size 2  # æœ€å°‘ 2 å‰¯æœ¬å¯å†™

# size=3, min_size=2 çš„å«ä¹‰ï¼š
# - æ­£å¸¸æƒ…å†µï¼š3 ä¸ªå‰¯æœ¬éƒ½å†™å…¥
# - 1 ä¸ª OSD æ•…éšœï¼šä»å¯è¯»å†™ï¼ˆ2 ä¸ªå‰¯æœ¬ï¼‰
# - 2 ä¸ª OSD æ•…éšœï¼šåªè¯»ï¼ˆ1 ä¸ªå‰¯æœ¬ï¼‰
# - 3 ä¸ª OSD æ•…éšœï¼šä¸å¯ç”¨
</code></pre>
<h3 id="42-çº åˆ ç erasure-code"><a class="header" href="#42-çº åˆ ç erasure-code">4.2 çº åˆ ç ï¼ˆErasure Codeï¼‰</a></h3>
<h4 id="421-çº åˆ ç åŸç†"><a class="header" href="#421-çº åˆ ç åŸç†">4.2.1 çº åˆ ç åŸç†</a></h4>
<p>çº åˆ ç é€šè¿‡æ•°å­¦ç®—æ³•å°†æ•°æ®åˆ†ä¸º K ä¸ªæ•°æ®å—å’Œ M ä¸ªæ ¡éªŒå—ï¼Œå¯å®¹å¿ M ä¸ªå—ä¸¢å¤±ã€‚</p>
<p><strong>å¸¸è§é…ç½®</strong>ï¼š</p>
<div class="table-wrapper"><table><thead><tr><th>é…ç½®</th><th>æ•°æ®å—(K)</th><th>æ ¡éªŒå—(M)</th><th>æ€»å—æ•°</th><th>å­˜å‚¨å¼€é”€</th><th>å®¹é”™èƒ½åŠ›</th></tr></thead><tbody>
<tr><td>4+2</td><td>4</td><td>2</td><td>6</td><td>1.5x</td><td>2 å—æ•…éšœ</td></tr>
<tr><td>8+3</td><td>8</td><td>3</td><td>11</td><td>1.375x</td><td>3 å—æ•…éšœ</td></tr>
<tr><td>8+4</td><td>8</td><td>4</td><td>12</td><td>1.5x</td><td>4 å—æ•…éšœ</td></tr>
</tbody></table>
</div>
<p><strong>å¯¹æ¯”å‰¯æœ¬</strong>ï¼š</p>
<pre><code>3 å‰¯æœ¬ï¼š
- å­˜å‚¨å¼€é”€ï¼š3x
- å®¹é”™ï¼š2 ä¸ªå‰¯æœ¬ä¸¢å¤±

8+3 çº åˆ ç ï¼š
- å­˜å‚¨å¼€é”€ï¼š1.375x
- å®¹é”™ï¼š3 ä¸ªå—ä¸¢å¤±
- èŠ‚çœç©ºé—´ï¼š(3 - 1.375) / 3 = 54%
</code></pre>
<h4 id="422-çº åˆ ç é…ç½®"><a class="header" href="#422-çº åˆ ç é…ç½®">4.2.2 çº åˆ ç é…ç½®</a></h4>
<p><strong>åˆ›å»ºçº åˆ ç  Profile</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹é»˜è®¤ profile
ceph osd erasure-code-profile ls
ceph osd erasure-code-profile get default

# åˆ›å»ºè‡ªå®šä¹‰ profile (8+3)
ceph osd erasure-code-profile set my_ec_profile \
    k=8 \
    m=3 \
    crush-failure-domain=host \
    plugin=jerasure \
    technique=reed_sol_van

# å‚æ•°è¯´æ˜ï¼š
# k: æ•°æ®å—æ•°é‡
# m: æ ¡éªŒå—æ•°é‡
# crush-failure-domain: æ•…éšœåŸŸï¼ˆhost/rack/datacenterï¼‰
# plugin: çº åˆ ç ç®—æ³•ï¼ˆjerasure/isa/lrc/shec/clayï¼‰
# technique: å…·ä½“æŠ€æœ¯ï¼ˆä»… jerasureï¼‰
</code></pre>
<p><strong>åˆ›å»ºçº åˆ ç  Pool</strong>ï¼š</p>
<pre><code class="language-bash"># åˆ›å»ºçº åˆ ç æ± 
ceph osd pool create ec_pool 128 128 erasure my_ec_profile

# çº åˆ ç æ± ä¸èƒ½ç›´æ¥ç”¨äº RBDï¼Œéœ€è¦é…åˆå‰¯æœ¬æ± 
# åˆ›å»ºå‰¯æœ¬æ± ä½œä¸ºå…ƒæ•°æ®æ± 
ceph osd pool create ec_pool_meta 32 32 replicated

# é…ç½® RBD ä½¿ç”¨çº åˆ ç æ± 
rbd create --size 10G --data-pool ec_pool ec_pool_meta/image1
</code></pre>
<h4 id="423-çº åˆ ç ç®—æ³•å¯¹æ¯”"><a class="header" href="#423-çº åˆ ç ç®—æ³•å¯¹æ¯”">4.2.3 çº åˆ ç ç®—æ³•å¯¹æ¯”</a></h4>
<p><strong>Jerasure</strong>ï¼ˆé»˜è®¤ï¼‰ï¼š</p>
<ul>
<li>æˆç†Ÿç¨³å®š</li>
<li>CPU å¼€é”€è¾ƒé«˜</li>
<li>æ”¯æŒå¤šç§æŠ€æœ¯ï¼ˆReed-Solomon, Cauchyï¼‰</li>
</ul>
<p><strong>ISA</strong>ï¼ˆIntel ISA-Lï¼‰ï¼š</p>
<ul>
<li>Intel ä¼˜åŒ–</li>
<li>æ€§èƒ½æœ€å¥½ï¼ˆåˆ©ç”¨ CPU æŒ‡ä»¤é›†ï¼‰</li>
<li>ä»…æ”¯æŒ Intel/AMD CPU</li>
</ul>
<p><strong>LRC</strong>ï¼ˆLocally Repairable Codeï¼‰ï¼š</p>
<ul>
<li>å‡å°‘æ¢å¤æ—¶çš„ç½‘ç»œä¼ è¾“</li>
<li>é€‚åˆå¤§è§„æ¨¡é›†ç¾¤</li>
<li>é…ç½®ç¤ºä¾‹ï¼š
<pre><code class="language-bash">ceph osd erasure-code-profile set lrc_profile \
    plugin=lrc \
    k=8 m=4 l=4
</code></pre>
</li>
</ul>
<p><strong>SHEC</strong>ï¼ˆShingled Erasure Codeï¼‰ï¼š</p>
<ul>
<li>æ›´çµæ´»çš„é…ç½®</li>
<li>å¯ç‹¬ç«‹æ¢å¤</li>
</ul>
<p><strong>Clay</strong>ï¼š</p>
<ul>
<li>æœ€æ–°ç®—æ³•</li>
<li>æœ€å°åŒ–æ¢å¤å¸¦å®½</li>
<li>é€‚åˆè·¨æ•°æ®ä¸­å¿ƒ</li>
</ul>
<h3 id="43-æ•°æ®æ¢å¤æœºåˆ¶"><a class="header" href="#43-æ•°æ®æ¢å¤æœºåˆ¶">4.3 æ•°æ®æ¢å¤æœºåˆ¶</a></h3>
<h4 id="431-osd-æ•…éšœå¤„ç†"><a class="header" href="#431-osd-æ•…éšœå¤„ç†">4.3.1 OSD æ•…éšœå¤„ç†</a></h4>
<p><strong>æ•…éšœæ£€æµ‹</strong>ï¼š</p>
<pre><code>1. OSD å¿ƒè·³æ£€æµ‹ï¼ˆæ¯ 6 ç§’ï¼‰
2. OSD å‘ Monitor æŠ¥å‘Šå…¶ä»– OSD çŠ¶æ€
3. Monitor æ ‡è®° down/out çŠ¶æ€
4. è§¦å‘æ•°æ®æ¢å¤æµç¨‹
</code></pre>
<p><strong>æ¢å¤æµç¨‹</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹ OSD çŠ¶æ€
ceph osd tree
ceph osd stat

# æ ‡è®° OSD downï¼ˆæ‰‹åŠ¨ï¼‰
ceph osd down osd.5

# æ ‡è®° OSD outï¼ˆè§¦å‘æ•°æ®è¿ç§»ï¼‰
ceph osd out osd.5

# æŸ¥çœ‹æ¢å¤è¿›åº¦
ceph -s
ceph -w  # å®æ—¶ç›‘æ§

# æ¢å¤å®Œæˆåï¼ŒOSD é‡æ–°ä¸Šçº¿
ceph osd in osd.5
</code></pre>
<h4 id="432-pg-çŠ¶æ€è¯¦è§£"><a class="header" href="#432-pg-çŠ¶æ€è¯¦è§£">4.3.2 PG çŠ¶æ€è¯¦è§£</a></h4>
<p><strong>å¸¸è§ PG çŠ¶æ€</strong>ï¼š</p>
<div class="table-wrapper"><table><thead><tr><th>çŠ¶æ€</th><th>å«ä¹‰</th><th>å¤„ç†</th></tr></thead><tbody>
<tr><td>active+clean</td><td>æ­£å¸¸ï¼Œå¯è¯»å†™</td><td>æ— éœ€å¤„ç†</td></tr>
<tr><td>active+degraded</td><td>å‰¯æœ¬ä¸è¶³ï¼Œä½†å¯è¯»å†™</td><td>ç­‰å¾…æ¢å¤</td></tr>
<tr><td>active+recovering</td><td>æ­£åœ¨æ¢å¤æ•°æ®</td><td>ç­‰å¾…å®Œæˆ</td></tr>
<tr><td>active+backfilling</td><td>æ­£åœ¨å›å¡«æ•°æ®</td><td>ç­‰å¾…å®Œæˆ</td></tr>
<tr><td>peering</td><td>æ­£åœ¨åŒæ­¥çŠ¶æ€</td><td>é€šå¸¸å¾ˆå¿«å®Œæˆ</td></tr>
<tr><td>remapped</td><td>PG æ˜ å°„å·²æ”¹å˜</td><td>ç­‰å¾…è¿ç§»</td></tr>
<tr><td>undersized</td><td>å‰¯æœ¬æ•°å°äºé…ç½®</td><td>æ£€æŸ¥ OSD çŠ¶æ€</td></tr>
<tr><td>incomplete</td><td>PG æ•°æ®ä¸å®Œæ•´</td><td>ä¸¥é‡é—®é¢˜ï¼Œéœ€äººå·¥ä»‹å…¥</td></tr>
<tr><td>stale</td><td>PG é•¿æ—¶é—´æ— æ›´æ–°</td><td>æ£€æŸ¥ OSD è¿æ¥</td></tr>
</tbody></table>
</div>
<p><strong>æŸ¥çœ‹ PG çŠ¶æ€</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹ PG ç»Ÿè®¡
ceph pg stat

# æŸ¥çœ‹å¼‚å¸¸ PG
ceph pg dump_stuck
ceph pg dump_stuck undersized
ceph pg dump_stuck degraded

# æŸ¥çœ‹ç‰¹å®š PG è¯¦æƒ…
ceph pg 1.7a query

# ä¿®å¤ PG
ceph pg repair 1.7a

# å¼ºåˆ¶æ¸…æ´—
ceph pg scrub 1.7a
ceph pg deep-scrub 1.7a
</code></pre>
<h4 id="433-æ•°æ®æ¸…æ´—scrubbing"><a class="header" href="#433-æ•°æ®æ¸…æ´—scrubbing">4.3.3 æ•°æ®æ¸…æ´—ï¼ˆScrubbingï¼‰</a></h4>
<p>Ceph å®šæœŸæ¸…æ´—æ•°æ®ä»¥æ£€æµ‹æ•°æ®ä¸ä¸€è‡´ã€‚</p>
<p><strong>æ¸…æ´—ç±»å‹</strong>ï¼š</p>
<ol>
<li>
<p><strong>Scrub</strong>ï¼š</p>
<ul>
<li>æ£€æŸ¥å¯¹è±¡å…ƒæ•°æ®</li>
<li>è½»é‡çº§ï¼Œå¿«é€Ÿ</li>
<li>é»˜è®¤æ¯å¤©ä¸€æ¬¡</li>
</ul>
</li>
<li>
<p><strong>Deep Scrub</strong>ï¼š</p>
<ul>
<li>æ£€æŸ¥å¯¹è±¡æ•°æ®å†…å®¹ï¼ˆCRCï¼‰</li>
<li>é‡é‡çº§ï¼Œè€—æ—¶</li>
<li>é»˜è®¤æ¯å‘¨ä¸€æ¬¡</li>
</ul>
</li>
</ol>
<p><strong>é…ç½®æ¸…æ´—</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹æ¸…æ´—é…ç½®
ceph config get osd osd_scrub_begin_hour
ceph config get osd osd_scrub_end_hour

# è®¾ç½®æ¸…æ´—æ—¶é—´çª—å£ï¼ˆä»…åœ¨ 0-6 ç‚¹æ¸…æ´—ï¼‰
ceph config set osd osd_scrub_begin_hour 0
ceph config set osd osd_scrub_end_hour 6

# ç¦ç”¨è‡ªåŠ¨æ¸…æ´—ï¼ˆç»´æŠ¤æœŸé—´ï¼‰
ceph osd set noscrub
ceph osd set nodeep-scrub

# æ¢å¤è‡ªåŠ¨æ¸…æ´—
ceph osd unset noscrub
ceph osd unset nodeep-scrub

# æ‰‹åŠ¨è§¦å‘æ¸…æ´—
ceph pg scrub 1.7a
ceph pg deep-scrub 1.7a

# ä¿®å¤ä¸ä¸€è‡´
ceph pg repair 1.7a
</code></pre>
<h3 id="44-æ•°æ®å¹³è¡¡"><a class="header" href="#44-æ•°æ®å¹³è¡¡">4.4 æ•°æ®å¹³è¡¡</a></h3>
<h4 id="441-è‡ªåŠ¨å¹³è¡¡"><a class="header" href="#441-è‡ªåŠ¨å¹³è¡¡">4.4.1 è‡ªåŠ¨å¹³è¡¡</a></h4>
<p>Ceph ä¼šè‡ªåŠ¨å¹³è¡¡æ•°æ®åˆ†å¸ƒã€‚</p>
<p><strong>è§¦å‘åœºæ™¯</strong>ï¼š</p>
<ul>
<li>æ·»åŠ æ–° OSD</li>
<li>OSD ä¸‹çº¿</li>
<li>OSD æƒé‡å˜åŒ–</li>
<li>CRUSH Map ä¿®æ”¹</li>
</ul>
<p><strong>å¹³è¡¡æµç¨‹</strong>ï¼š</p>
<pre><code>1. Monitor æ£€æµ‹åˆ°é›†ç¾¤å˜åŒ–
2. é‡æ–°è®¡ç®— PG åˆ†å¸ƒ
3. ç”Ÿæˆæ•°æ®è¿ç§»è®¡åˆ’
4. OSD æ‰§è¡Œæ•°æ®è¿ç§»ï¼ˆbackfillï¼‰
5. å®Œæˆå¹³è¡¡
</code></pre>
<p><strong>æŸ¥çœ‹å¹³è¡¡çŠ¶æ€</strong>ï¼š</p>
<pre><code class="language-bash"># æŸ¥çœ‹æ•°æ®åˆ†å¸ƒ
ceph osd df

# æŸ¥çœ‹ PG åˆ†å¸ƒ
ceph pg dump | grep active

# æŸ¥çœ‹è¿ç§»è¿›åº¦
ceph -s
ceph progress

# æŸ¥çœ‹å›å¡«æ“ä½œ
ceph osd pool get mypool backfill_full_ratio
</code></pre>
<h4 id="442-æ‰‹åŠ¨æ§åˆ¶å¹³è¡¡"><a class="header" href="#442-æ‰‹åŠ¨æ§åˆ¶å¹³è¡¡">4.4.2 æ‰‹åŠ¨æ§åˆ¶å¹³è¡¡</a></h4>
<pre><code class="language-bash"># æš‚åœæ¢å¤å’Œå›å¡«
ceph osd set nobackfill
ceph osd set norecover
ceph osd set norebalance

# æ¢å¤è‡ªåŠ¨å¹³è¡¡
ceph osd unset nobackfill
ceph osd unset norecover
ceph osd unset norebalance

# è°ƒæ•´æ¢å¤ä¼˜å…ˆçº§
ceph tell osd.* injectargs '--osd-recovery-max-active 1'
ceph tell osd.* injectargs '--osd-recovery-max-single-start 1'

# ä½¿ç”¨ Balancer æ¨¡å—
ceph balancer on
ceph balancer mode upmap
ceph balancer eval
ceph balancer status
</code></pre>
<hr />
<h2 id="ç¬¬äº”ç« é›†ç¾¤éƒ¨ç½²ä¸è¿ç»´"><a class="header" href="#ç¬¬äº”ç« é›†ç¾¤éƒ¨ç½²ä¸è¿ç»´">ç¬¬äº”ç« ï¼šé›†ç¾¤éƒ¨ç½²ä¸è¿ç»´</a></h2>
<h3 id="51-éƒ¨ç½²è§„åˆ’"><a class="header" href="#51-éƒ¨ç½²è§„åˆ’">5.1 éƒ¨ç½²è§„åˆ’</a></h3>
<h4 id="511-ç¡¬ä»¶è¦æ±‚"><a class="header" href="#511-ç¡¬ä»¶è¦æ±‚">5.1.1 ç¡¬ä»¶è¦æ±‚</a></h4>
<p><strong>æœ€å°æµ‹è¯•ç¯å¢ƒï¼ˆå•èŠ‚ç‚¹ï¼‰</strong>ï¼š</p>
<pre><code>- CPU: 4 æ ¸
- å†…å­˜: 8GB
- ç£ç›˜: 3 x 10GBï¼ˆOSDï¼‰
- ç½‘ç»œ: 1Gbps
</code></pre>
<p><strong>ç”Ÿäº§ç¯å¢ƒæ¨è</strong>ï¼š</p>
<p><strong>Monitor èŠ‚ç‚¹</strong>ï¼š</p>
<pre><code>- CPU: 4-8 æ ¸
- å†…å­˜: 16-32GB
- ç£ç›˜: 50-100GB SSDï¼ˆç³»ç»Ÿ + Monitor DBï¼‰
- ç½‘ç»œ: 10Gbps
- æ•°é‡: 3/5/7 ä¸ªï¼ˆå¥‡æ•°ï¼‰
</code></pre>
<p><strong>OSD èŠ‚ç‚¹</strong>ï¼š</p>
<pre><code>- CPU: 0.5-1 æ ¸/OSDï¼ˆä¸€èˆ¬ 12-24 æ ¸ï¼‰
- å†…å­˜: 2-4GB/OSDï¼ˆä¸€èˆ¬ 64-128GBï¼‰
- ç£ç›˜:
  - HDD: 4-12TB SATA/SAS 7.2K RPM
  - SSD: 1-4TB NVMe/SATA SSD
  - æ¯èŠ‚ç‚¹ 10-12 å—ç›˜
- ç½‘ç»œ: 10Gbpsï¼ˆåŒç½‘å¡bondï¼‰æˆ– 25Gbps
- æ•°é‡: è‡³å°‘ 3 ä¸ªèŠ‚ç‚¹
</code></pre>
<p><strong>ç®¡ç†èŠ‚ç‚¹</strong>ï¼š</p>
<pre><code>- CPU: 4 æ ¸
- å†…å­˜: 8GB
- ç£ç›˜: 50GB
- ç½‘ç»œ: 1Gbps
</code></pre>
<h4 id="512-ç½‘ç»œè§„åˆ’"><a class="header" href="#512-ç½‘ç»œè§„åˆ’">5.1.2 ç½‘ç»œè§„åˆ’</a></h4>
<p><strong>å•ç½‘ç»œï¼ˆæµ‹è¯•ï¼‰</strong>ï¼š</p>
<pre><code>æ‰€æœ‰æµé‡å…±äº«ä¸€ä¸ªç½‘ç»œ
ç®€å•ä½†æ€§èƒ½æœ‰é™
</code></pre>
<p><strong>åŒç½‘ç»œï¼ˆæ¨èï¼‰</strong>ï¼š</p>
<pre><code>Public Networkï¼ˆå…¬å…±ç½‘ç»œï¼‰ï¼š
- å®¢æˆ·ç«¯è®¿é—®
- Monitor é€šä¿¡
- 10Gbps

Cluster Networkï¼ˆé›†ç¾¤ç½‘ç»œï¼‰ï¼š
- OSD ä¹‹é—´å¤åˆ¶
- æ•°æ®æ¢å¤å’Œå¹³è¡¡
- 10-25Gbps
</code></pre>
<p><strong>é…ç½®ç¤ºä¾‹</strong>ï¼š</p>
<pre><code class="language-ini">[global]
public_network = 192.168.1.0/24
cluster_network = 192.168.100.0/24
</code></pre>
<h4 id="513-ç£ç›˜è§„åˆ’"><a class="header" href="#513-ç£ç›˜è§„åˆ’">5.1.3 ç£ç›˜è§„åˆ’</a></h4>
<p><strong>OSD ç£ç›˜ç±»å‹</strong>ï¼š</p>
<ol>
<li>
<p><strong>FileStoreï¼ˆå·²åºŸå¼ƒï¼‰</strong>ï¼š</p>
<ul>
<li>åŸºäºæ–‡ä»¶ç³»ç»Ÿï¼ˆXFSï¼‰</li>
<li>éœ€è¦ Journalï¼ˆSSDï¼‰</li>
</ul>
</li>
<li>
<p><strong>BlueStoreï¼ˆå½“å‰é»˜è®¤ï¼‰</strong>ï¼š</p>
<ul>
<li>ç›´æ¥ç®¡ç†è£¸è®¾å¤‡</li>
<li>æ€§èƒ½æ›´å¥½</li>
<li>ç»„æˆï¼š
<ul>
<li>Blockï¼šä¸»æ•°æ®ï¼ˆHDD/SSDï¼‰</li>
<li>Block.dbï¼šå…ƒæ•°æ®ï¼ˆSSD/NVMeï¼Œæ¨èï¼‰</li>
<li>Block.walï¼šé¢„å†™æ—¥å¿—ï¼ˆSSD/NVMeï¼Œå¯é€‰ï¼‰</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>é…ç½®ç­–ç•¥</strong>ï¼š</p>
<p><strong>ç­–ç•¥ 1ï¼šå…¨ HDDï¼ˆç»æµå‹ï¼‰</strong>ï¼š</p>
<pre><code>- Block: HDD
- Block.db: HDDï¼ˆå…±äº«ï¼‰
- Block.wal: HDDï¼ˆå…±äº«ï¼‰
- é€‚ç”¨ï¼šå½’æ¡£å­˜å‚¨ï¼Œæˆæœ¬ä¼˜å…ˆ
</code></pre>
<p><strong>ç­–ç•¥ 2ï¼šHDD + SSDï¼ˆæ¨èï¼‰</strong>ï¼š</p>
<pre><code>- Block: HDD
- Block.db: SSDï¼ˆå…±äº«ï¼Œ1:5-10 æ¯”ä¾‹ï¼‰
- Block.wal: SSDï¼ˆå…±äº«ï¼Œå¯é€‰ï¼‰
- é€‚ç”¨ï¼šé€šç”¨åœºæ™¯ï¼Œæ€§èƒ½å’Œæˆæœ¬å¹³è¡¡
</code></pre>
<p><strong>ç­–ç•¥ 3ï¼šå…¨ NVMeï¼ˆé«˜æ€§èƒ½ï¼‰</strong>ï¼š</p>
<pre><code>- Block: NVMe
- Block.db: NVMeï¼ˆç‹¬ç«‹ï¼‰
- Block.wal: NVMeï¼ˆç‹¬ç«‹ï¼‰
- é€‚ç”¨ï¼šé«˜æ€§èƒ½éœ€æ±‚ï¼Œæ•°æ®åº“
</code></pre>
<h3 id="52-ä½¿ç”¨-cephadm-éƒ¨ç½²æ¨è"><a class="header" href="#52-ä½¿ç”¨-cephadm-éƒ¨ç½²æ¨è">5.2 ä½¿ç”¨ Cephadm éƒ¨ç½²ï¼ˆæ¨èï¼‰</a></h3>
<p>Cephadm æ˜¯ Ceph Octopus+ ç‰ˆæœ¬çš„å®˜æ–¹éƒ¨ç½²å·¥å…·ï¼ŒåŸºäºå®¹å™¨ã€‚</p>
<h4 id="521-å‡†å¤‡å·¥ä½œ"><a class="header" href="#521-å‡†å¤‡å·¥ä½œ">5.2.1 å‡†å¤‡å·¥ä½œ</a></h4>
<p><strong>æ‰€æœ‰èŠ‚ç‚¹</strong>ï¼š</p>
<pre><code class="language-bash"># 1. é…ç½®ä¸»æœºå
hostnamectl set-hostname node1

# 2. é…ç½® hosts
cat &gt;&gt; /etc/hosts &lt;&lt; EOF
192.168.1.11 node1
192.168.1.12 node2
192.168.1.13 node3
EOF

# 3. é…ç½®æ—¶é—´åŒæ­¥
apt install chrony -y
systemctl enable --now chronyd

# 4. ç¦ç”¨é˜²ç«å¢™ï¼ˆæˆ–å¼€æ”¾ç«¯å£ï¼‰
systemctl stop firewalld
systemctl disable firewalld

# æˆ–å¼€æ”¾ç«¯å£
firewall-cmd --permanent --add-service=ceph
firewall-cmd --permanent --add-service=ceph-mon
firewall-cmd --reload

# 5. å®‰è£… Docker æˆ– Podman
apt install docker.io -y
systemctl enable --now docker

# 6. é…ç½®æ— å¯†ç  SSHï¼ˆä» admin èŠ‚ç‚¹ï¼‰
ssh-keygen
ssh-copy-id root@node1
ssh-copy-id root@node2
ssh-copy-id root@node3
</code></pre>
<h4 id="522-éƒ¨ç½²é›†ç¾¤"><a class="header" href="#522-éƒ¨ç½²é›†ç¾¤">5.2.2 éƒ¨ç½²é›†ç¾¤</a></h4>
<p><strong>æ­¥éª¤ 1ï¼šå¼•å¯¼é›†ç¾¤</strong></p>
<pre><code class="language-bash"># åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆnode1ï¼‰

# 1. å®‰è£… cephadm
curl --silent --remote-name --location https://download.ceph.com/rpm-reef/el9/noarch/cephadm
chmod +x cephadm
./cephadm add-repo --release reef
./cephadm install

# 2. å¼•å¯¼é›†ç¾¤
cephadm bootstrap --mon-ip 192.168.1.11 \
    --cluster-network 192.168.100.0/24 \
    --initial-dashboard-user admin \
    --initial-dashboard-password StrongPassword123

# è¾“å‡ºåŒ…å«ï¼š
# - Dashboard URL: https://node1:8443
# - admin ç”¨æˆ·å’Œå¯†ç 
# - ceph.conf å’Œ keyring ä½ç½®

# 3. å®‰è£… ceph å‘½ä»¤è¡Œå·¥å…·
cephadm install ceph-common

# 4. éªŒè¯é›†ç¾¤çŠ¶æ€
ceph -s
ceph orch ls
</code></pre>
<p><strong>æ­¥éª¤ 2ï¼šæ·»åŠ ä¸»æœº</strong></p>
<pre><code class="language-bash"># æ·»åŠ ä¸»æœºåˆ°é›†ç¾¤
ceph orch host add node2 192.168.1.12
ceph orch host add node3 192.168.1.13

# ä¸ºä¸»æœºæ‰“æ ‡ç­¾
ceph orch host label add node1 mon
ceph orch host label add node2 mon
ceph orch host label add node3 mon

# æŸ¥çœ‹ä¸»æœº
ceph orch host ls
</code></pre>
<p><strong>æ­¥éª¤ 3ï¼šéƒ¨ç½² Monitor</strong></p>
<pre><code class="language-bash"># éƒ¨ç½² 3 ä¸ª Monitor
ceph orch apply mon --placement="3 node1 node2 node3"

# æˆ–ä½¿ç”¨æ ‡ç­¾
ceph orch apply mon label:mon

# æŸ¥çœ‹ Monitor çŠ¶æ€
ceph mon stat
ceph orch ps --daemon_type mon
</code></pre>
<p><strong>æ­¥éª¤ 4ï¼šéƒ¨ç½² Manager</strong></p>
<pre><code class="language-bash"># éƒ¨ç½² Managerï¼ˆè‡ªåŠ¨ HAï¼‰
ceph orch apply mgr --placement="2 node1 node2"

# æŸ¥çœ‹ Manager çŠ¶æ€
ceph mgr dump
ceph orch ps --daemon_type mgr
</code></pre>
<p><strong>æ­¥éª¤ 5ï¼šéƒ¨ç½² OSD</strong></p>
<pre><code class="language-bash"># æŸ¥çœ‹å¯ç”¨ç£ç›˜
ceph orch device ls

# æ–¹æ³• 1ï¼šè‡ªåŠ¨éƒ¨ç½²æ‰€æœ‰å¯ç”¨ç£ç›˜
ceph orch apply osd --all-available-devices

# æ–¹æ³• 2ï¼šæŒ‡å®šç£ç›˜
ceph orch daemon add osd node1:/dev/sdb
ceph orch daemon add osd node2:/dev/sdb
ceph orch daemon add osd node3:/dev/sdb

# æ–¹æ³• 3ï¼šä½¿ç”¨è§„æ ¼æ–‡ä»¶ï¼ˆæ¨èï¼‰
cat &gt; osd-spec.yml &lt;&lt; EOF
service_type: osd
service_id: default_drive_group
placement:
  host_pattern: '*'
data_devices:
  paths:
    - /dev/sdb
    - /dev/sdc
db_devices:
  paths:
    - /dev/nvme0n1
EOF

ceph orch apply -i osd-spec.yml

# æŸ¥çœ‹ OSD çŠ¶æ€
ceph osd stat
ceph osd tree
ceph orch ps --daemon_type osd
</code></pre>
<p><strong>æ­¥éª¤ 6ï¼šéƒ¨ç½²å…¶ä»–æœåŠ¡</strong></p>
<pre><code class="language-bash"># éƒ¨ç½² MDSï¼ˆç”¨äº CephFSï¼‰
ceph orch apply mds mycephfs --placement="2 node1 node2"

# éƒ¨ç½² RGWï¼ˆç”¨äºå¯¹è±¡å­˜å‚¨ï¼‰
ceph orch apply rgw myrgw --placement="2 node2 node3" --port=8080

# å¯ç”¨ Dashboard æ¨¡å—
ceph mgr module enable dashboard
ceph dashboard create-self-signed-cert
</code></pre>
<h3 id="53-æ—¥å¸¸è¿ç»´æ“ä½œ"><a class="header" href="#53-æ—¥å¸¸è¿ç»´æ“ä½œ">5.3 æ—¥å¸¸è¿ç»´æ“ä½œ</a></h3>
<h4 id="531-é›†ç¾¤çŠ¶æ€ç›‘æ§"><a class="header" href="#531-é›†ç¾¤çŠ¶æ€ç›‘æ§">5.3.1 é›†ç¾¤çŠ¶æ€ç›‘æ§</a></h4>
<pre><code class="language-bash"># æŸ¥çœ‹é›†ç¾¤æ•´ä½“çŠ¶æ€
ceph -s
ceph status

# å®æ—¶ç›‘æ§
ceph -w

# è¯¦ç»†å¥åº·ä¿¡æ¯
ceph health detail

# æŸ¥çœ‹é›†ç¾¤ä½¿ç”¨æƒ…å†µ
ceph df
ceph df detail

# æŸ¥çœ‹ OSD ä½¿ç”¨æƒ…å†µ
ceph osd df

# æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡
ceph osd perf

# æŸ¥çœ‹ Pool ç»Ÿè®¡
ceph osd pool stats
</code></pre>
<h4 id="532-osd-ç®¡ç†"><a class="header" href="#532-osd-ç®¡ç†">5.3.2 OSD ç®¡ç†</a></h4>
<pre><code class="language-bash"># å®‰å…¨ä¸‹çº¿ OSD
ceph osd out osd.5
# ç­‰å¾…æ•°æ®è¿ç§»å®Œæˆ
ceph -w
# åœæ­¢ OSD
systemctl stop ceph-osd@5
# ä» CRUSH ç§»é™¤
ceph osd crush remove osd.5
# åˆ é™¤ OSD
ceph osd rm osd.5
# åˆ é™¤è®¤è¯
ceph auth del osd.5

# æ·»åŠ  OSD
ceph orch daemon add osd node1:/dev/sde

# æ›¿æ¢æ•…éšœç£ç›˜
# 1. æ ‡è®° OSD out
ceph osd out osd.5
# 2. ç­‰å¾…æ•°æ®è¿ç§»
# 3. æ›´æ¢ç£ç›˜
# 4. é”€æ¯æ—§ OSD
ceph orch osd rm osd.5 --replace
# 5. éƒ¨ç½²æ–° OSD
ceph orch daemon add osd node1:/dev/sde

# è°ƒæ•´ OSD æƒé‡
ceph osd crush reweight osd.5 2.0

# æŸ¥çœ‹ OSD è¯¦ç»†ä¿¡æ¯
ceph osd find osd.5
ceph osd metadata osd.5
</code></pre>
<h4 id="533-pool-ç®¡ç†"><a class="header" href="#533-pool-ç®¡ç†">5.3.3 Pool ç®¡ç†</a></h4>
<pre><code class="language-bash"># åˆ›å»º Pool
ceph osd pool create mypool 128

# åˆ é™¤ Poolï¼ˆéœ€è¦ç¡®è®¤ï¼‰
ceph osd pool delete mypool mypool --yes-i-really-really-mean-it

# ä¿®æ”¹ Pool é…ç½®
ceph osd pool set mypool size 3
ceph osd pool set mypool min_size 2
ceph osd pool set mypool pg_num 256
ceph osd pool set mypool pgp_num 256

# é‡å‘½å Pool
ceph osd pool rename oldname newname

# åˆ›å»º Pool å¿«ç…§
ceph osd pool mksnap mypool snap1

# åˆ é™¤ Pool å¿«ç…§
ceph osd pool rmsnap mypool snap1
</code></pre>
<h4 id="534-ç”¨æˆ·å’Œæƒé™ç®¡ç†"><a class="header" href="#534-ç”¨æˆ·å’Œæƒé™ç®¡ç†">5.3.4 ç”¨æˆ·å’Œæƒé™ç®¡ç†</a></h4>
<pre><code class="language-bash"># æŸ¥çœ‹ç”¨æˆ·
ceph auth list
ceph auth get client.admin

# åˆ›å»ºç”¨æˆ·
ceph auth get-or-create client.rbd mon 'allow r' osd 'allow rwx pool=rbd_pool'

# å¯¼å‡ºå¯†é’¥
ceph auth get client.rbd -o /etc/ceph/ceph.client.rbd.keyring

# ä¿®æ”¹æƒé™
ceph auth caps client.rbd mon 'allow r' osd 'allow rwx pool=rbd_pool, allow rx pool=another_pool'

# åˆ é™¤ç”¨æˆ·
ceph auth del client.rbd
</code></pre>
<hr />
<h2 id="ç¬¬å…­ç« æ€§èƒ½ä¼˜åŒ–ä¸æ•…éšœæ’æŸ¥"><a class="header" href="#ç¬¬å…­ç« æ€§èƒ½ä¼˜åŒ–ä¸æ•…éšœæ’æŸ¥">ç¬¬å…­ç« ï¼šæ€§èƒ½ä¼˜åŒ–ä¸æ•…éšœæ’æŸ¥</a></h2>
<h3 id="61-æ€§èƒ½ä¼˜åŒ–"><a class="header" href="#61-æ€§èƒ½ä¼˜åŒ–">6.1 æ€§èƒ½ä¼˜åŒ–</a></h3>
<h4 id="611-osd-æ€§èƒ½ä¼˜åŒ–"><a class="header" href="#611-osd-æ€§èƒ½ä¼˜åŒ–">6.1.1 OSD æ€§èƒ½ä¼˜åŒ–</a></h4>
<p><strong>BlueStore å‚æ•°</strong>ï¼š</p>
<pre><code class="language-bash"># BlueStore ç¼“å­˜å¤§å°ï¼ˆHDDï¼‰
ceph config set osd bluestore_cache_size_hdd 1073741824  # 1GB

# BlueStore ç¼“å­˜å¤§å°ï¼ˆSSDï¼‰
ceph config set osd bluestore_cache_size_ssd 3221225472  # 3GB

# BlueStore æœ€å°åˆ†é…å•å…ƒ
ceph config set osd bluestore_min_alloc_size_hdd 65536  # 64KB
ceph config set osd bluestore_min_alloc_size_ssd 16384  # 16KB

# å‹ç¼©è®¾ç½®
ceph config set osd bluestore_compression_algorithm snappy
ceph config set osd bluestore_compression_mode aggressive
</code></pre>
<p><strong>OSD å¹¶å‘è®¾ç½®</strong>ï¼š</p>
<pre><code class="language-bash"># OSD æ“ä½œçº¿ç¨‹æ± 
ceph config set osd osd_op_num_threads_per_shard 2
ceph config set osd osd_op_num_shards 8

# OSD æœ€å¤§å¹¶å‘æ“ä½œ
ceph config set osd osd_max_backfills 1
ceph config set osd osd_recovery_max_active 3
</code></pre>
<h4 id="612-ç½‘ç»œä¼˜åŒ–"><a class="header" href="#612-ç½‘ç»œä¼˜åŒ–">6.1.2 ç½‘ç»œä¼˜åŒ–</a></h4>
<pre><code class="language-bash"># å¢åŠ æ¶ˆæ¯é˜Ÿåˆ—å¤§å°
ceph config set osd ms_dispatch_throttle_bytes 1048576000

# è°ƒæ•´ç½‘ç»œ MTUï¼ˆé…ç½® Jumbo Frameï¼‰
ip link set eth0 mtu 9000

# éªŒè¯
ping -M do -s 8972 node2
</code></pre>
<h4 id="613-å®¢æˆ·ç«¯ä¼˜åŒ–"><a class="header" href="#613-å®¢æˆ·ç«¯ä¼˜åŒ–">6.1.3 å®¢æˆ·ç«¯ä¼˜åŒ–</a></h4>
<p><strong>RBD ä¼˜åŒ–</strong>ï¼š</p>
<pre><code class="language-bash"># å¢åŠ  RBD ç¼“å­˜
rbd config image set rbd_pool/image1 rbd_cache true
rbd config image set rbd_pool/image1 rbd_cache_size 67108864  # 64MB

# å¯ç”¨ RBD é¢„è¯»
rbd config image set rbd_pool/image1 rbd_readahead_trigger_requests 10

# è°ƒæ•´ queue_depth
echo 128 &gt; /sys/block/rbd0/queue/nr_requests
</code></pre>
<p><strong>CephFS ä¼˜åŒ–</strong>ï¼š</p>
<pre><code class="language-bash"># å®¢æˆ·ç«¯ç¼“å­˜
ceph config set client client_cache_size 16777216  # 16MB

# MDS ç¼“å­˜
ceph config set mds mds_cache_memory_limit 4294967296  # 4GB

# å¯ç”¨ fscache
mount -t ceph mon1:/ /mnt/cephfs -o name=admin,fsc
</code></pre>
<h3 id="62-ç›‘æ§ä¸å‘Šè­¦"><a class="header" href="#62-ç›‘æ§ä¸å‘Šè­¦">6.2 ç›‘æ§ä¸å‘Šè­¦</a></h3>
<h4 id="621-å¯ç”¨ç›‘æ§æ¨¡å—"><a class="header" href="#621-å¯ç”¨ç›‘æ§æ¨¡å—">6.2.1 å¯ç”¨ç›‘æ§æ¨¡å—</a></h4>
<pre><code class="language-bash"># å¯ç”¨ Prometheus æ¨¡å—
ceph mgr module enable prometheus

# æŸ¥çœ‹ Prometheus endpoint
ceph mgr services

# å¯ç”¨ Dashboard æ¨¡å—
ceph mgr module enable dashboard
ceph dashboard create-self-signed-cert
ceph dashboard ac-user-create admin StrongPassword123 administrator

# è®¿é—® Dashboard
https://node1:8443
</code></pre>
<h4 id="622-é›†æˆ-prometheus--grafana"><a class="header" href="#622-é›†æˆ-prometheus--grafana">6.2.2 é›†æˆ Prometheus + Grafana</a></h4>
<p><strong>å®‰è£… Prometheus</strong>ï¼š</p>
<pre><code class="language-bash"># docker-compose.yml
version: '3'
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
</code></pre>
<p><strong>prometheus.yml</strong>ï¼š</p>
<pre><code class="language-yaml">global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'ceph'
    static_configs:
      - targets: ['node1:9283', 'node2:9283', 'node3:9283']
</code></pre>
<p><strong>å®‰è£… Grafana</strong>ï¼š</p>
<pre><code class="language-bash"># docker-compose.yml æ·»åŠ 
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana

volumes:
  grafana-storage:
</code></pre>
<p><strong>é…ç½® Grafana</strong>ï¼š</p>
<ol>
<li>è®¿é—® http://node1:3000ï¼ˆadmin/adminï¼‰</li>
<li>æ·»åŠ  Prometheus æ•°æ®æº</li>
<li>å¯¼å…¥ Ceph å®˜æ–¹ Dashboardï¼ˆID: 2842, 5336, 7056ï¼‰</li>
</ol>
<h4 id="623-å…³é”®ç›‘æ§æŒ‡æ ‡"><a class="header" href="#623-å…³é”®ç›‘æ§æŒ‡æ ‡">6.2.3 å…³é”®ç›‘æ§æŒ‡æ ‡</a></h4>
<p><strong>é›†ç¾¤çº§åˆ«</strong>ï¼š</p>
<ul>
<li>é›†ç¾¤å¥åº·çŠ¶æ€</li>
<li>æ€»å®¹é‡å’Œä½¿ç”¨ç‡</li>
<li>IOPS å’Œååé‡</li>
<li>PG çŠ¶æ€åˆ†å¸ƒ</li>
</ul>
<p><strong>OSD çº§åˆ«</strong>ï¼š</p>
<ul>
<li>OSD çŠ¶æ€ï¼ˆup/down, in/outï¼‰</li>
<li>ç£ç›˜ä½¿ç”¨ç‡</li>
<li>ç£ç›˜å»¶è¿Ÿ</li>
<li>ç½‘ç»œæµé‡</li>
</ul>
<p><strong>Pool çº§åˆ«</strong>ï¼š</p>
<ul>
<li>Pool å®¹é‡ä½¿ç”¨</li>
<li>Pool IOPS</li>
<li>Pool å®¢æˆ·ç«¯è¿æ¥æ•°</li>
</ul>
<h3 id="63-å¸¸è§é—®é¢˜æ’æŸ¥"><a class="header" href="#63-å¸¸è§é—®é¢˜æ’æŸ¥">6.3 å¸¸è§é—®é¢˜æ’æŸ¥</a></h3>
<h4 id="631-é›†ç¾¤çŠ¶æ€å¼‚å¸¸"><a class="header" href="#631-é›†ç¾¤çŠ¶æ€å¼‚å¸¸">6.3.1 é›†ç¾¤çŠ¶æ€å¼‚å¸¸</a></h4>
<p><strong>é—®é¢˜ 1ï¼šHEALTH_WARN - too many PGs per OSD</strong></p>
<pre><code class="language-bash"># åŸå› ï¼šPG æ•°é‡è¿‡å¤š
# æŸ¥çœ‹å½“å‰ PG åˆ†å¸ƒ
ceph osd df

# è§£å†³æ–¹æ¡ˆï¼š
# æ–¹æ¡ˆ 1ï¼šå¢åŠ  OSD æ•°é‡ï¼ˆæ¨èï¼‰
# æ–¹æ¡ˆ 2ï¼šå‡å°‘ PG æ•°é‡ï¼ˆéœ€è°¨æ…ï¼‰
ceph osd pool set mypool pg_num 128
ceph osd pool set mypool pgp_num 128
</code></pre>
<p><strong>é—®é¢˜ 2ï¼šHEALTH_WARN - clock skew detected</strong></p>
<pre><code class="language-bash"># åŸå› ï¼šèŠ‚ç‚¹æ—¶é—´ä¸åŒæ­¥
# æ£€æŸ¥æ—¶é—´
date
chronyc sources

# è§£å†³æ–¹æ¡ˆï¼šåŒæ­¥æ—¶é—´
systemctl restart chronyd
ceph tell mon.* injectargs '--mon-clock-drift-allowed 0.05'
</code></pre>
<p><strong>é—®é¢˜ 3ï¼šHEALTH_ERR - PGs are undersized</strong></p>
<pre><code class="language-bash"># åŸå› ï¼šå‰¯æœ¬æ•°ä¸è¶³
# æŸ¥çœ‹é—®é¢˜ PG
ceph pg dump_stuck undersized

# è§£å†³æ–¹æ¡ˆï¼š
# 1. æ£€æŸ¥ OSD çŠ¶æ€
ceph osd tree

# 2. æ¢å¤æ•…éšœ OSD æˆ–ç­‰å¾…æ•°æ®æ¢å¤
ceph -w
</code></pre>
<h4 id="632-æ€§èƒ½é—®é¢˜"><a class="header" href="#632-æ€§èƒ½é—®é¢˜">6.3.2 æ€§èƒ½é—®é¢˜</a></h4>
<p><strong>é—®é¢˜ 1ï¼šå†™å…¥æ…¢</strong></p>
<pre><code class="language-bash"># è¯Šæ–­æ­¥éª¤ï¼š

# 1. æ£€æŸ¥é›†ç¾¤çŠ¶æ€
ceph -s

# 2. æ£€æŸ¥ PG çŠ¶æ€ï¼ˆæ˜¯å¦åœ¨æ¢å¤ï¼‰
ceph pg stat

# 3. æ£€æŸ¥ OSD å»¶è¿Ÿ
ceph osd perf

# 4. æ£€æŸ¥ç£ç›˜ I/O
iostat -x 1

# 5. æ£€æŸ¥ç½‘ç»œ
iftop
netstat -s | grep retrans

# å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š
# - æ•°æ®æ¢å¤ä¸­ï¼šç­‰å¾…æˆ–é™ä½æ¢å¤ä¼˜å…ˆçº§
# - ç£ç›˜æ…¢ï¼šæ£€æŸ¥ç¡¬ä»¶ï¼Œä¼˜åŒ–å‚æ•°
# - ç½‘ç»œæ‹¥å¡ï¼šæ£€æŸ¥ç½‘ç»œé…ç½®ï¼Œå¯ç”¨ Jumbo Frame
# - OSD è´Ÿè½½ä¸å‡ï¼šä½¿ç”¨ Balancer æ¨¡å—
</code></pre>
<p><strong>é—®é¢˜ 2ï¼šè¯»å–æ…¢</strong></p>
<pre><code class="language-bash"># è¯Šæ–­æ­¥éª¤ï¼š

# 1. æ£€æŸ¥ OSD çŠ¶æ€
ceph osd tree

# 2. æ£€æŸ¥ç£ç›˜ SMART ä¿¡æ¯
smartctl -a /dev/sdb

# 3. æµ‹è¯•ç£ç›˜æ€§èƒ½
fio --name=randread --ioengine=libaio --iodepth=16 --rw=randread --bs=4k --direct=1 --size=1G --numjobs=4 --runtime=60 --group_reporting

# 4. å¯ç”¨ RBD ç¼“å­˜
rbd config image set pool/image rbd_cache true

# 5. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping -c 100 node2
</code></pre>
<h4 id="633-æ•°æ®ä¸ä¸€è‡´"><a class="header" href="#633-æ•°æ®ä¸ä¸€è‡´">6.3.3 æ•°æ®ä¸ä¸€è‡´</a></h4>
<p><strong>é—®é¢˜ï¼šinconsistent PG</strong></p>
<pre><code class="language-bash"># æŸ¥çœ‹ä¸ä¸€è‡´çš„ PG
ceph health detail
ceph pg dump | grep inconsistent

# æŸ¥çœ‹ç‰¹å®š PG çš„è¯¦ç»†ä¿¡æ¯
ceph pg 1.7a query

# è§£å†³æ–¹æ¡ˆï¼šä¿®å¤ PG
ceph pg repair 1.7a

# å¦‚æœä¿®å¤å¤±è´¥ï¼Œæ·±åº¦æ¸…æ´—
ceph pg deep-scrub 1.7a

# æŸ¥çœ‹ä¿®å¤æ—¥å¿—
ceph log last 100 | grep 1.7a
</code></pre>
<h4 id="634-osd-æ— æ³•å¯åŠ¨"><a class="header" href="#634-osd-æ— æ³•å¯åŠ¨">6.3.4 OSD æ— æ³•å¯åŠ¨</a></h4>
<p><strong>è¯Šæ–­æ­¥éª¤</strong>ï¼š</p>
<pre><code class="language-bash"># 1. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
journalctl -u ceph-osd@5 -n 100

# 2. æ£€æŸ¥ç£ç›˜çŠ¶æ€
lsblk
smartctl -H /dev/sdb

# 3. æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿ
ceph-bluestore-tool fsck --path /var/lib/ceph/osd/ceph-5

# 4. å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆï¼š

# é”™è¯¯ï¼šfailed to load OSD map
# è§£å†³ï¼š
ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-5 --op update-mon-db --mon-store-path /tmp/mon-store

# é”™è¯¯ï¼šBlueStore fsck found errors
# è§£å†³ï¼š
ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-5

# é”™è¯¯ï¼šç£ç›˜æ•…éšœ
# è§£å†³ï¼šæ›´æ¢ç£ç›˜ï¼Œé‡æ–°éƒ¨ç½² OSD
</code></pre>
<hr />
<h2 id="å­¦ä¹ éªŒè¯æ ‡å‡†"><a class="header" href="#å­¦ä¹ éªŒè¯æ ‡å‡†">å­¦ä¹ éªŒè¯æ ‡å‡†</a></h2>
<p>å®Œæˆæœ¬ç¬”è®°å­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š</p>
<h3 id="-ç†è®ºçŸ¥è¯†éªŒè¯"><a class="header" href="#-ç†è®ºçŸ¥è¯†éªŒè¯">âœ… ç†è®ºçŸ¥è¯†éªŒè¯</a></h3>
<ol>
<li>
<p><strong>æ¶æ„ç†è§£</strong>ï¼š</p>
<ul>
<li>èƒ½å¤Ÿç»˜åˆ¶ Ceph æ¶æ„å›¾å¹¶è§£é‡Šå„ç»„ä»¶ä½œç”¨</li>
<li>ç†è§£ RADOSã€CRUSH ç®—æ³•çš„å·¥ä½œåŸç†</li>
<li>ç†è§£å¯¹è±¡ã€PGã€Pool çš„å…³ç³»å’Œæ˜ å°„æµç¨‹</li>
</ul>
</li>
<li>
<p><strong>æ•°æ®å¯é æ€§</strong>ï¼š</p>
<ul>
<li>è®¡ç®—ä¸åŒå‰¯æœ¬é…ç½®çš„å­˜å‚¨å¼€é”€å’Œå®¹é”™èƒ½åŠ›</li>
<li>é€‰æ‹©åˆé€‚çš„çº åˆ ç é…ç½®</li>
<li>ç†è§£æ•°æ®æ¢å¤å’Œå¹³è¡¡æµç¨‹</li>
</ul>
</li>
<li>
<p><strong>å­˜å‚¨æ¥å£</strong>ï¼š</p>
<ul>
<li>åŒºåˆ† RBDã€CephFSã€RGW çš„é€‚ç”¨åœºæ™¯</li>
<li>ç†è§£å„æ¥å£çš„ç‰¹æ€§å’Œé™åˆ¶</li>
</ul>
</li>
</ol>
<h3 id="-å®æˆ˜èƒ½åŠ›éªŒè¯"><a class="header" href="#-å®æˆ˜èƒ½åŠ›éªŒè¯">âœ… å®æˆ˜èƒ½åŠ›éªŒè¯</a></h3>
<ol>
<li>
<p><strong>é›†ç¾¤éƒ¨ç½²</strong>ï¼š</p>
<ul>
<li>èƒ½å¤Ÿä»é›¶æ­å»º 3 èŠ‚ç‚¹ Ceph é›†ç¾¤</li>
<li>é…ç½®åŒç½‘ç»œï¼ˆå…¬å…±ç½‘ç»œå’Œé›†ç¾¤ç½‘ç»œï¼‰</li>
<li>éƒ¨ç½² Monã€MGRã€OSDã€MDSã€RGW å„ç»„ä»¶</li>
</ul>
</li>
<li>
<p><strong>å­˜å‚¨é…ç½®</strong>ï¼š</p>
<ul>
<li>åˆ›å»ºå’Œç®¡ç† Poolï¼ˆå‰¯æœ¬æ± ã€çº åˆ ç æ± ï¼‰</li>
<li>åˆ›å»ºå’Œä½¿ç”¨ RBD é•œåƒ</li>
<li>éƒ¨ç½²å’ŒæŒ‚è½½ CephFS</li>
<li>é…ç½®å’Œä½¿ç”¨ RGWï¼ˆS3 æ¥å£ï¼‰</li>
</ul>
</li>
<li>
<p><strong>è¿ç»´æ“ä½œ</strong>ï¼š</p>
<ul>
<li>å®‰å…¨ä¸‹çº¿å’Œæ›¿æ¢ OSD</li>
<li>è°ƒæ•´ PG æ•°é‡å’Œå‰¯æœ¬æ•°</li>
<li>åˆ›å»ºå’Œç®¡ç†å¿«ç…§</li>
<li>é…ç½® CRUSH è§„åˆ™</li>
</ul>
</li>
<li>
<p><strong>æ•…éšœå¤„ç†</strong>ï¼š</p>
<ul>
<li>è¯Šæ–­å’Œä¿®å¤ inconsistent PG</li>
<li>å¤„ç† OSD æ•…éšœ</li>
<li>è§£å†³æ€§èƒ½é—®é¢˜</li>
<li>æ¢å¤è¯¯åˆ é™¤æ•°æ®</li>
</ul>
</li>
</ol>
<h3 id="-å®æˆ˜ç»ƒä¹ å»ºè®®"><a class="header" href="#-å®æˆ˜ç»ƒä¹ å»ºè®®">âœ… å®æˆ˜ç»ƒä¹ å»ºè®®</a></h3>
<p><strong>ç»ƒä¹  1ï¼šåŸºç¡€é›†ç¾¤æ­å»ºï¼ˆ4-6 å°æ—¶ï¼‰</strong></p>
<pre><code>ç›®æ ‡ï¼šæ­å»º 3 èŠ‚ç‚¹ Ceph é›†ç¾¤
æ­¥éª¤ï¼š
1. å‡†å¤‡ 3 å°è™šæ‹Ÿæœºï¼ˆæ¯å° 2 æ ¸ 4GBï¼‰
2. ä½¿ç”¨ cephadm éƒ¨ç½²é›†ç¾¤
3. éªŒè¯é›†ç¾¤å¥åº·çŠ¶æ€
4. åˆ›å»ºæµ‹è¯• Pool å¹¶å†™å…¥æ•°æ®
</code></pre>
<p><strong>ç»ƒä¹  2ï¼šRBD å—å­˜å‚¨å®æˆ˜ï¼ˆ2-3 å°æ—¶ï¼‰</strong></p>
<pre><code>ç›®æ ‡ï¼šæŒæ¡ RBD çš„åˆ›å»ºã€å¿«ç…§ã€å…‹éš†
æ­¥éª¤ï¼š
1. åˆ›å»º 10GB RBD é•œåƒ
2. æ ¼å¼åŒ–å¹¶æŒ‚è½½ä½¿ç”¨
3. åˆ›å»ºå¿«ç…§å¹¶å…‹éš†
4. æµ‹è¯•å¿«ç…§å›æ»šåŠŸèƒ½
</code></pre>
<p><strong>ç»ƒä¹  3ï¼šCephFS æ–‡ä»¶ç³»ç»Ÿå®æˆ˜ï¼ˆ2-3 å°æ—¶ï¼‰</strong></p>
<pre><code>ç›®æ ‡ï¼šéƒ¨ç½²å’Œä½¿ç”¨ CephFS
æ­¥éª¤ï¼š
1. åˆ›å»ºå…ƒæ•°æ®æ± å’Œæ•°æ®æ± 
2. éƒ¨ç½² 2 ä¸ª MDSï¼ˆHAï¼‰
3. å¤šå®¢æˆ·ç«¯æŒ‚è½½æµ‹è¯•
4. é…ç½®ç›®å½•é…é¢å’Œå¿«ç…§
</code></pre>
<p><strong>ç»ƒä¹  4ï¼šæ•…éšœæ¨¡æ‹Ÿä¸æ¢å¤ï¼ˆ3-4 å°æ—¶ï¼‰</strong></p>
<pre><code>ç›®æ ‡ï¼šæŒæ¡æ•…éšœå¤„ç†æµç¨‹
æ­¥éª¤ï¼š
1. æ¨¡æ‹Ÿ OSD æ•…éšœï¼ˆåœæ­¢ OSD æœåŠ¡ï¼‰
2. è§‚å¯Ÿæ•°æ®æ¢å¤è¿‡ç¨‹
3. æ¨¡æ‹Ÿç£ç›˜æ•…éšœï¼ˆæ–­å¼€ç£ç›˜ï¼‰
4. æ›¿æ¢æ•…éšœç£ç›˜å¹¶é‡æ–°å¹³è¡¡
</code></pre>
<p><strong>ç»ƒä¹  5ï¼šæ€§èƒ½æµ‹è¯•ä¸ä¼˜åŒ–ï¼ˆ3-4 å°æ—¶ï¼‰</strong></p>
<pre><code>ç›®æ ‡ï¼šæ€§èƒ½æµ‹è¯•å’Œè°ƒä¼˜
æ­¥éª¤ï¼š
1. ä½¿ç”¨ rados bench æµ‹è¯•é›†ç¾¤æ€§èƒ½
2. ä½¿ç”¨ fio æµ‹è¯• RBD æ€§èƒ½
3. è°ƒæ•´ BlueStore å‚æ•°
4. å¯¹æ¯”ä¼˜åŒ–å‰åæ€§èƒ½å·®å¼‚
</code></pre>
<hr />
<h2 id="æ‰©å±•èµ„æºä¸è¿›é˜¶å»ºè®®"><a class="header" href="#æ‰©å±•èµ„æºä¸è¿›é˜¶å»ºè®®">æ‰©å±•èµ„æºä¸è¿›é˜¶å»ºè®®</a></h2>
<h3 id="-å®˜æ–¹æ–‡æ¡£"><a class="header" href="#-å®˜æ–¹æ–‡æ¡£">ğŸ“š å®˜æ–¹æ–‡æ¡£</a></h3>
<ol>
<li>
<p><strong>Ceph å®˜æ–¹æ–‡æ¡£</strong>ï¼šhttps://docs.ceph.com</p>
<ul>
<li>Architecture: https://docs.ceph.com/en/latest/architecture/</li>
<li>Operations: https://docs.ceph.com/en/latest/rados/operations/</li>
<li>Cephadm: https://docs.ceph.com/en/latest/cephadm/</li>
</ul>
</li>
<li>
<p><strong>Red Hat Ceph Storage</strong>ï¼šhttps://access.redhat.com/documentation/en-us/red_hat_ceph_storage</p>
</li>
</ol>
<h3 id="-è¿›é˜¶å­¦ä¹ è·¯å¾„"><a class="header" href="#-è¿›é˜¶å­¦ä¹ è·¯å¾„">ğŸ“ è¿›é˜¶å­¦ä¹ è·¯å¾„</a></h3>
<p><strong>é˜¶æ®µ 1ï¼šåŸºç¡€æŒæ¡ï¼ˆ1-2 å‘¨ï¼‰</strong></p>
<ul>
<li>ç†è§£ Ceph æ¶æ„å’Œæ ¸å¿ƒæ¦‚å¿µ</li>
<li>æ­å»ºæµ‹è¯•é›†ç¾¤</li>
<li>æŒæ¡åŸºæœ¬è¿ç»´æ“ä½œ</li>
</ul>
<p><strong>é˜¶æ®µ 2ï¼šæ·±å…¥ç†è§£ï¼ˆ2-4 å‘¨ï¼‰</strong></p>
<ul>
<li>æ·±å…¥å­¦ä¹  RADOS å’Œ CRUSH</li>
<li>æŒæ¡ä¸‰ç§å­˜å‚¨æ¥å£</li>
<li>å­¦ä¹ æ€§èƒ½ä¼˜åŒ–æŠ€å·§</li>
</ul>
<p><strong>é˜¶æ®µ 3ï¼šç”Ÿäº§å®è·µï¼ˆ1-3 ä¸ªæœˆï¼‰</strong></p>
<ul>
<li>è§„åˆ’å’Œéƒ¨ç½²ç”Ÿäº§ç¯å¢ƒ</li>
<li>å®æ–½ç›‘æ§å’Œå‘Šè­¦ä½“ç³»</li>
<li>ç§¯ç´¯æ•…éšœå¤„ç†ç»éªŒ</li>
</ul>
<p><strong>é˜¶æ®µ 4ï¼šé«˜çº§ç‰¹æ€§ï¼ˆæŒç»­ï¼‰</strong></p>
<ul>
<li>RBD é•œåƒï¼ˆè·¨é›†ç¾¤å¤åˆ¶ï¼‰</li>
<li>CephFS å¤šæ–‡ä»¶ç³»ç»Ÿ</li>
<li>RGW å¤šç«™ç‚¹åŒæ­¥</li>
<li>BlueStore å‹ç¼©å’ŒåŠ å¯†</li>
</ul>
<h3 id="-æ¨èå·¥å…·"><a class="header" href="#-æ¨èå·¥å…·">ğŸ› ï¸ æ¨èå·¥å…·</a></h3>
<ol>
<li>
<p><strong>æ€§èƒ½æµ‹è¯•</strong>ï¼š</p>
<ul>
<li>rados benchï¼šé›†ç¾¤æ€§èƒ½æµ‹è¯•</li>
<li>rbd benchï¼šRBD æ€§èƒ½æµ‹è¯•</li>
<li>fioï¼šé€šç”¨ I/O æµ‹è¯•å·¥å…·</li>
</ul>
</li>
<li>
<p><strong>ç›‘æ§å‘Šè­¦</strong>ï¼š</p>
<ul>
<li>Prometheus + Grafana</li>
<li>Ceph Dashboard</li>
<li>Nagios/Zabbix</li>
</ul>
</li>
<li>
<p><strong>ç®¡ç†å·¥å…·</strong>ï¼š</p>
<ul>
<li>ceph-ansibleï¼šAnsible éƒ¨ç½²å·¥å…·</li>
<li>Rookï¼šKubernetes ç¼–æ’</li>
<li>Ceph Dashboardï¼šWeb ç®¡ç†ç•Œé¢</li>
</ul>
</li>
</ol>
<h3 id="-æœ€ä½³å®è·µæ€»ç»“"><a class="header" href="#-æœ€ä½³å®è·µæ€»ç»“">ğŸ’¡ æœ€ä½³å®è·µæ€»ç»“</a></h3>
<ol>
<li>
<p><strong>è§„åˆ’é˜¶æ®µ</strong>ï¼š</p>
<ul>
<li>å……åˆ†è¯„ä¼°ä¸šåŠ¡éœ€æ±‚</li>
<li>é¢„ç•™ 20-30% å®¹é‡ä½™é‡</li>
<li>é€‰æ‹©åˆé€‚çš„ç¡¬ä»¶é…ç½®</li>
<li>è§„åˆ’ç½‘ç»œæ‹“æ‰‘</li>
</ul>
</li>
<li>
<p><strong>éƒ¨ç½²é˜¶æ®µ</strong>ï¼š</p>
<ul>
<li>ä½¿ç”¨ cephadm/ceph-ansible</li>
<li>é…ç½®åŒç½‘ç»œ</li>
<li>ä½¿ç”¨ SSD ä½œä¸º BlueStore DB</li>
<li>éƒ¨ç½²å¥‡æ•°ä¸ª Monitor</li>
</ul>
</li>
<li>
<p><strong>è¿ç»´é˜¶æ®µ</strong>ï¼š</p>
<ul>
<li>å®šæœŸæ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€</li>
<li>ç›‘æ§ç£ç›˜ SMART ä¿¡æ¯</li>
<li>å®šæœŸå¤‡ä»½é…ç½®æ–‡ä»¶</li>
<li>åˆ¶å®šåº”æ€¥é¢„æ¡ˆ</li>
</ul>
</li>
<li>
<p><strong>ä¼˜åŒ–é˜¶æ®µ</strong>ï¼š</p>
<ul>
<li>æ ¹æ®å·¥ä½œè´Ÿè½½è°ƒæ•´å‚æ•°</li>
<li>ä½¿ç”¨ Balancer æ¨¡å—å¹³è¡¡æ•°æ®</li>
<li>ä¼˜åŒ– PG æ•°é‡</li>
<li>å¯ç”¨å‹ç¼©ï¼ˆé€‚å½“åœºæ™¯ï¼‰</li>
</ul>
</li>
</ol>
<hr />
<h2 id="å¸¸è§é—®é¢˜faq"><a class="header" href="#å¸¸è§é—®é¢˜faq">å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰</a></h2>
<h3 id="q1ceph-é€‚åˆä»€ä¹ˆæ ·çš„åœºæ™¯"><a class="header" href="#q1ceph-é€‚åˆä»€ä¹ˆæ ·çš„åœºæ™¯">Q1ï¼šCeph é€‚åˆä»€ä¹ˆæ ·çš„åœºæ™¯ï¼Ÿ</a></h3>
<p><strong>é€‚åˆ</strong>ï¼š</p>
<ul>
<li>ç§æœ‰äº‘å­˜å‚¨å¹³å°</li>
<li>è™šæ‹ŸåŒ–å­˜å‚¨åç«¯ï¼ˆOpenStackã€VMwareï¼‰</li>
<li>å®¹å™¨æŒä¹…åŒ–å­˜å‚¨ï¼ˆKubernetesï¼‰</li>
<li>å¤§æ•°æ®å­˜å‚¨ï¼ˆHadoopã€Sparkï¼‰</li>
<li>åª’ä½“å­˜å‚¨å’Œåˆ†å‘</li>
<li>å¤‡ä»½å’Œå½’æ¡£</li>
</ul>
<p><strong>ä¸é€‚åˆ</strong>ï¼š</p>
<ul>
<li>ä½å»¶è¿Ÿäº¤æ˜“ç³»ç»Ÿï¼ˆ&lt; 1msï¼‰</li>
<li>å°æ–‡ä»¶å¯†é›†å‹åº”ç”¨ï¼ˆå¯¹è±¡å­˜å‚¨æ¨¡å¼ä¸‹ï¼‰</li>
<li>èµ„æºå—é™ç¯å¢ƒï¼ˆ&lt; 3 èŠ‚ç‚¹ï¼‰</li>
</ul>
<h3 id="q2ceph-å’Œå…¶ä»–å­˜å‚¨ç³»ç»Ÿå¯¹æ¯”"><a class="header" href="#q2ceph-å’Œå…¶ä»–å­˜å‚¨ç³»ç»Ÿå¯¹æ¯”">Q2ï¼šCeph å’Œå…¶ä»–å­˜å‚¨ç³»ç»Ÿå¯¹æ¯”ï¼Ÿ</a></h3>
<div class="table-wrapper"><table><thead><tr><th>ç‰¹æ€§</th><th>Ceph</th><th>GlusterFS</th><th>MinIO</th><th>HDFS</th></tr></thead><tbody>
<tr><td>ç»Ÿä¸€å­˜å‚¨</td><td>âœ…</td><td>âœ…</td><td>âŒ</td><td>âŒ</td></tr>
<tr><td>å—å­˜å‚¨</td><td>âœ…</td><td>âœ…</td><td>âŒ</td><td>âŒ</td></tr>
<tr><td>å¯¹è±¡å­˜å‚¨</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td>âŒ</td></tr>
<tr><td>æ–‡ä»¶å­˜å‚¨</td><td>âœ…</td><td>âœ…</td><td>âŒ</td><td>âœ…</td></tr>
<tr><td>æ‰©å±•æ€§</td><td>ä¼˜ç§€</td><td>è‰¯å¥½</td><td>ä¼˜ç§€</td><td>ä¼˜ç§€</td></tr>
<tr><td>æ€§èƒ½</td><td>è‰¯å¥½</td><td>ä¸€èˆ¬</td><td>ä¼˜ç§€</td><td>è‰¯å¥½</td></tr>
<tr><td>è¿ç»´å¤æ‚åº¦</td><td>è¾ƒé«˜</td><td>è¾ƒä½</td><td>ä½</td><td>ä¸­ç­‰</td></tr>
</tbody></table>
</div>
<h3 id="q3ç”Ÿäº§ç¯å¢ƒæœ€å°‘éœ€è¦å¤šå°‘èŠ‚ç‚¹"><a class="header" href="#q3ç”Ÿäº§ç¯å¢ƒæœ€å°‘éœ€è¦å¤šå°‘èŠ‚ç‚¹">Q3ï¼šç”Ÿäº§ç¯å¢ƒæœ€å°‘éœ€è¦å¤šå°‘èŠ‚ç‚¹ï¼Ÿ</a></h3>
<p><strong>æœ€å°é…ç½®</strong>ï¼š3 ä¸ªèŠ‚ç‚¹</p>
<ul>
<li>æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œ Mon + OSD</li>
<li>3 å‰¯æœ¬é…ç½®</li>
<li>å¯å®¹å¿ 1 ä¸ªèŠ‚ç‚¹æ•…éšœ</li>
</ul>
<p><strong>æ¨èé…ç½®</strong>ï¼š5+ ä¸ªèŠ‚ç‚¹</p>
<ul>
<li>3-5 ä¸ª Mon èŠ‚ç‚¹ï¼ˆä¸“ç”¨æˆ–å¤ç”¨ï¼‰</li>
<li>3+ ä¸ª OSD èŠ‚ç‚¹ï¼ˆä¸“ç”¨ï¼‰</li>
<li>æ›´å¥½çš„æ•…éšœéš”ç¦»</li>
<li>æ›´çµæ´»çš„æ‰©å±•</li>
</ul>
<h3 id="q4å¦‚ä½•é€‰æ‹©å‰¯æœ¬æ•°è¿˜æ˜¯çº åˆ ç "><a class="header" href="#q4å¦‚ä½•é€‰æ‹©å‰¯æœ¬æ•°è¿˜æ˜¯çº åˆ ç ">Q4ï¼šå¦‚ä½•é€‰æ‹©å‰¯æœ¬æ•°è¿˜æ˜¯çº åˆ ç ï¼Ÿ</a></h3>
<p><strong>é€‰æ‹©å‰¯æœ¬ï¼ˆ3 å‰¯æœ¬ï¼‰</strong>ï¼š</p>
<ul>
<li>å°è§„æ¨¡é›†ç¾¤ï¼ˆ&lt; 50TBï¼‰</li>
<li>é«˜æ€§èƒ½éœ€æ±‚</li>
<li>éšæœº I/O å¯†é›†</li>
<li>ç¤ºä¾‹ï¼šè™šæ‹Ÿæœºå­˜å‚¨ã€æ•°æ®åº“</li>
</ul>
<p><strong>é€‰æ‹©çº åˆ ç ï¼ˆå¦‚ 8+3ï¼‰</strong>ï¼š</p>
<ul>
<li>å¤§è§„æ¨¡é›†ç¾¤ï¼ˆ&gt; 100TBï¼‰</li>
<li>æˆæœ¬æ•æ„Ÿ</li>
<li>é¡ºåº I/O ä¸ºä¸»</li>
<li>ç¤ºä¾‹ï¼šå¤‡ä»½ã€å½’æ¡£ã€å†·æ•°æ®</li>
</ul>
<h3 id="q5å¦‚ä½•è§„åˆ’-pg-æ•°é‡"><a class="header" href="#q5å¦‚ä½•è§„åˆ’-pg-æ•°é‡">Q5ï¼šå¦‚ä½•è§„åˆ’ PG æ•°é‡ï¼Ÿ</a></h3>
<p><strong>è®¡ç®—å…¬å¼</strong>ï¼š</p>
<pre><code>Total PGs = (Target PGs per OSD Ã— OSDæ•°é‡ Ã— å‰¯æœ¬æ•°) / Poolæ•°é‡
Target PGs per OSD = 50-200ï¼ˆæ¨è 100ï¼‰
ç»“æœå‘ä¸Šå–æœ€æ¥è¿‘çš„ 2 çš„å¹‚æ¬¡
</code></pre>
<p><strong>ç¤ºä¾‹</strong>ï¼š</p>
<pre><code>30 OSDï¼Œ3 å‰¯æœ¬ï¼Œ3 ä¸ª Pool
Total PGs = (100 Ã— 30 Ã— 3) / 3 = 3000
é€‰æ‹© 4096ï¼ˆæœ€æ¥è¿‘çš„ 2 çš„å¹‚æ¬¡ï¼‰
æ¯ä¸ª Pool: 4096 / 3 â‰ˆ 1024-2048
</code></pre>
<h3 id="q6å¦‚ä½•å¤‡ä»½-ceph-æ•°æ®"><a class="header" href="#q6å¦‚ä½•å¤‡ä»½-ceph-æ•°æ®">Q6ï¼šå¦‚ä½•å¤‡ä»½ Ceph æ•°æ®ï¼Ÿ</a></h3>
<p><strong>RBD å¤‡ä»½</strong>ï¼š</p>
<pre><code class="language-bash"># å¢é‡å¤‡ä»½
rbd export-diff pool/image@snap /backup/image-snap.diff

# å®Œæ•´å¤‡ä»½
rbd export pool/image /backup/image.img
</code></pre>
<p><strong>CephFS å¤‡ä»½</strong>ï¼š</p>
<pre><code class="language-bash"># ä½¿ç”¨ rsync
rsync -avz /mnt/cephfs/ /backup/cephfs/

# ä½¿ç”¨å¿«ç…§
mkdir /mnt/cephfs/.snap/backup-$(date +%Y%m%d)
</code></pre>
<p><strong>RGW å¤‡ä»½</strong>ï¼š</p>
<pre><code class="language-bash"># ä½¿ç”¨ s3cmd åŒæ­¥
s3cmd sync s3://mybucket/ /backup/s3/
</code></pre>
<hr />
<h2 id="æ€»ç»“"><a class="header" href="#æ€»ç»“">æ€»ç»“</a></h2>
<p>Ceph æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç»Ÿä¸€å­˜å‚¨å¹³å°ï¼Œé€šè¿‡æœ¬ç¬”è®°çš„å­¦ä¹ ï¼Œä½ åº”è¯¥å·²ç»æŒæ¡äº†ï¼š</p>
<ol>
<li><strong>æ ¸å¿ƒåŸç†</strong>ï¼šRADOSã€CRUSHã€PG æœºåˆ¶</li>
<li><strong>æ¶æ„è®¾è®¡</strong>ï¼šMonã€OSDã€MGRã€MDS å„ç»„ä»¶çš„ä½œç”¨</li>
<li><strong>å­˜å‚¨æ¥å£</strong>ï¼šRBDã€CephFSã€RGW çš„ä½¿ç”¨</li>
<li><strong>éƒ¨ç½²è¿ç»´</strong>ï¼šé›†ç¾¤è§„åˆ’ã€éƒ¨ç½²ã€æ—¥å¸¸ç®¡ç†</li>
<li><strong>æ€§èƒ½ä¼˜åŒ–</strong>ï¼šå‚æ•°è°ƒä¼˜ã€ç›‘æ§å‘Šè­¦</li>
<li><strong>æ•…éšœå¤„ç†</strong>ï¼šå¸¸è§é—®é¢˜çš„è¯Šæ–­å’Œè§£å†³</li>
</ol>
<p>Ceph çš„å­¦ä¹ æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œå»ºè®®ï¼š</p>
<ul>
<li>åŠ¨æ‰‹å®è·µï¼Œæ­å»ºæµ‹è¯•ç¯å¢ƒ</li>
<li>å…³æ³¨ç¤¾åŒºåŠ¨æ€å’Œæ–°ç‰ˆæœ¬ç‰¹æ€§</li>
<li>ç§¯ç´¯ç”Ÿäº§ç¯å¢ƒç»éªŒ</li>
<li>æ·±å…¥æºç ç†è§£å®ç°åŸç†</li>
</ul>
<p>ç¥ä½ åœ¨ Ceph çš„å­¦ä¹ å’Œä½¿ç”¨ä¸­å–å¾—æˆåŠŸï¼</p>
<hr />
<h2 id="ç‰ˆæœ¬å†å²"><a class="header" href="#ç‰ˆæœ¬å†å²">ç‰ˆæœ¬å†å²</a></h2>
<ul>
<li>v1.0 (2024-01): åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºäº Ceph Reef ç‰ˆæœ¬</li>
<li>æ¶µç›–æ ¸å¿ƒæ¶æ„ã€ä¸‰ç§å­˜å‚¨æ¥å£ã€éƒ¨ç½²è¿ç»´ã€æ€§èƒ½ä¼˜åŒ–</li>
<li>ç›®æ ‡è¯»è€…ï¼š0-5 å¹´ç»éªŒçš„æŠ€æœ¯ä»ä¸šè€…</li>
</ul>
<hr />
<p><strong>ç›¸å…³ç¬”è®°æ¨è</strong>ï¼š</p>
<ul>
<li>åˆ†å¸ƒå¼å­˜å‚¨åŸç†</li>
<li>Kubernetes å­˜å‚¨æ¶æ„</li>
<li>å¯¹è±¡å­˜å‚¨æŠ€æœ¯å¯¹æ¯”</li>
<li>Linux å­˜å‚¨å­ç³»ç»Ÿä¼˜åŒ–</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../ç¼–ç¨‹/network/ä¸‰å±‚äº¤æ¢æœº.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../../ç¼–ç¨‹/paas/docker.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../ç¼–ç¨‹/network/ä¸‰å±‚äº¤æ¢æœº.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../../ç¼–ç¨‹/paas/docker.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js"></script>
        <script src="../../theme/segmentit.umd.js"></script>
        <script src="../../mark.min.js"></script>
        <script src="../../theme/searcher.js"></script>

        <script src="../../clipboard.min.js"></script>
        <script src="../../highlight.js"></script>
        <script src="../../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../../theme/pagetoc.js"></script>



    </div>
    </body>
</html>

