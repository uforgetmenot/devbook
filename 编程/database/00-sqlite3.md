# SQLite3 å®Œæ•´å­¦ä¹ æŒ‡å—

> ğŸ“– **å­¦ä¹ ç›®æ ‡**: æŒæ¡SQLite3ä»åŸºç¡€æ¦‚å¿µåˆ°ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²çš„å®Œæ•´æŠ€èƒ½ä½“ç³»ï¼Œå…·å¤‡ç‹¬ç«‹å¼€å‘å’Œç»´æŠ¤SQLiteåº”ç”¨çš„èƒ½åŠ›

## ç›®å½•

1. [åŸºç¡€æ¦‚å¿µä¸æ¶æ„](#1-åŸºç¡€æ¦‚å¿µä¸æ¶æ„)
2. [ç¯å¢ƒæ­å»ºä¸é…ç½®](#2-ç¯å¢ƒæ­å»ºä¸é…ç½®)
3. [æ•°æ®ç±»å‹ç³»ç»Ÿ](#3-æ•°æ®ç±»å‹ç³»ç»Ÿ)
4. [æ ¸å¿ƒSQLæ“ä½œ](#4-æ ¸å¿ƒsqlæ“ä½œ)
5. [é«˜çº§ç‰¹æ€§ä¸åº”ç”¨](#5-é«˜çº§ç‰¹æ€§ä¸åº”ç”¨)
6. [æ€§èƒ½ä¼˜åŒ–å®æˆ˜](#6-æ€§èƒ½ä¼˜åŒ–å®æˆ˜)
7. [Pythonç¼–ç¨‹é›†æˆ](#7-pythonç¼–ç¨‹é›†æˆ)
8. [ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#8-ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)
9. [é—®é¢˜è¯Šæ–­ä¸è§£å†³](#9-é—®é¢˜è¯Šæ–­ä¸è§£å†³)
10. [å®æˆ˜é¡¹ç›®ä¸éªŒè¯](#10-å®æˆ˜é¡¹ç›®ä¸éªŒè¯)

## 1. åŸºç¡€æ¦‚å¿µä¸æ¶æ„

### 1.1 å­¦ä¹ ç›®æ ‡
- ç†è§£SQLite3çš„æ ¸å¿ƒç‰¹æ€§å’Œé€‚ç”¨åœºæ™¯
- æŒæ¡SQLiteæ¶æ„åŸç†å’Œå·¥ä½œæœºåˆ¶
- äº†è§£ä¸ä¼ ç»Ÿæ•°æ®åº“çš„åŒºåˆ«å’Œä¼˜åŠ¿

### 1.2 SQLite3 æ ¸å¿ƒç‰¹æ€§

SQLite3æ˜¯ä¸–ç•Œä¸Šéƒ¨ç½²æœ€å¹¿æ³›çš„æ•°æ®åº“å¼•æ“ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹æ€§ï¼š

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
- âš¡ **é›¶é…ç½®**ï¼šæ— éœ€å®‰è£…æœåŠ¡å™¨ï¼Œåº”ç”¨ç¨‹åºç›´æ¥è®¿é—®æ•°æ®åº“æ–‡ä»¶
- ğŸ“ **æ–‡ä»¶å‹æ•°æ®åº“**ï¼šæ•´ä¸ªæ•°æ®åº“å­˜å‚¨åœ¨å•ä¸ªç£ç›˜æ–‡ä»¶ä¸­
- ğŸŒ **è·¨å¹³å°**ï¼šæ”¯æŒWindowsã€Linuxã€macOSã€Androidã€iOSç­‰
- ğŸ›¡ï¸ **ACIDå…¼å®¹**ï¼šå®Œå…¨æ”¯æŒåŸå­æ€§ã€ä¸€è‡´æ€§ã€éš”ç¦»æ€§ã€æŒä¹…æ€§
- ğŸª¶ **è½»é‡çº§**ï¼šæ ¸å¿ƒåº“å°äº700KBï¼Œå†…å­˜å ç”¨æä½
- ğŸ“‹ **æ ‡å‡†SQL**ï¼šæ”¯æŒSQL-92æ ‡å‡†çš„ç»å¤§éƒ¨åˆ†åŠŸèƒ½
- ğŸ”’ **å¯é æ€§**ï¼šç»è¿‡å¤§é‡æµ‹è¯•ï¼Œæ•…éšœç‡æä½

**é€‚ç”¨åœºæ™¯ï¼š**
- ç§»åŠ¨åº”ç”¨å’Œæ¡Œé¢è½¯ä»¶çš„æœ¬åœ°å­˜å‚¨
- IoTè®¾å¤‡å’ŒåµŒå…¥å¼ç³»ç»Ÿ
- åŸå‹å¼€å‘å’Œæµ‹è¯•ç¯å¢ƒ
- å°å‹åˆ°ä¸­å‹Webåº”ç”¨
- æ•°æ®åˆ†æå’ŒæŠ¥å‘Šå·¥å…·
- é…ç½®æ–‡ä»¶å’Œç¼“å­˜å­˜å‚¨

### 1.3 æ¶æ„æ·±åº¦è§£æ

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨ç¨‹åºå±‚                              â”‚
â”‚  (Python, C/C++, Java, JavaScript, Go, Rustç­‰)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ SQLè¯­å¥å’ŒAPIè°ƒç”¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SQLæ¥å£å±‚                               â”‚
â”‚  sqlite3_exec(), sqlite3_prepare(), sqlite3_step()     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ è§£æçš„SQLè¯­å¥
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç¼–è¯‘å™¨                                â”‚
â”‚  SQLè§£æå™¨ â†’ æŸ¥è¯¢è§„åˆ’å™¨ â†’ ä»£ç ç”Ÿæˆå™¨                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ å­—èŠ‚ç æŒ‡ä»¤
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 è™šæ‹Ÿæ•°æ®åº“å¼•æ“                            â”‚
â”‚  æ‰§è¡Œå­—èŠ‚ç  â†’ æ¸¸æ ‡ç®¡ç† â†’ ç»“æœé›†å¤„ç†                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ é¡µé¢æ“ä½œè¯·æ±‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 å­˜å‚¨å¼•æ“å±‚                               â”‚
â”‚  B-treeç®¡ç†å™¨ â†’ R-treeç´¢å¼• â†’ é¡µé¢ç¼“å­˜ç®¡ç†                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ æ–‡ä»¶I/Oæ“ä½œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                æ“ä½œç³»ç»Ÿæ¥å£å±‚                             â”‚
â”‚  VFS (è™šæ‹Ÿæ–‡ä»¶ç³»ç»Ÿ) â†’ é”ç®¡ç† â†’ å†…å­˜æ˜ å°„                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ ç³»ç»Ÿè°ƒç”¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ–‡ä»¶ç³»ç»Ÿ                               â”‚
â”‚         æ•°æ®åº“æ–‡ä»¶ (.db) + WALæ—¥å¿— + å…±äº«å†…å­˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®ç»„ä»¶è¯´æ˜ï¼š**

1. **SQLæ¥å£å±‚**: æä¾›C APIå’Œå„ç§è¯­è¨€ç»‘å®š
2. **ç¼–è¯‘å™¨**: å°†SQLè½¬æ¢ä¸ºè™šæ‹Ÿæœºå­—èŠ‚ç 
3. **è™šæ‹Ÿæœº**: æ‰§è¡Œå­—èŠ‚ç ï¼Œå¤„ç†æŸ¥è¯¢é€»è¾‘
4. **B-treeå¼•æ“**: ç®¡ç†è¡¨å’Œç´¢å¼•çš„å­˜å‚¨ç»“æ„
5. **é¡µç¼“å­˜**: å†…å­˜ä¸­çš„é¡µé¢ç¼“å­˜ç³»ç»Ÿ
6. **VFSå±‚**: æŠ½è±¡çš„æ–‡ä»¶ç³»ç»Ÿæ¥å£

## 2. ç¯å¢ƒæ­å»ºä¸é…ç½®

### 2.1 å­¦ä¹ ç›®æ ‡
- æŒæ¡å„å¹³å°SQLite3çš„å®‰è£…å’Œé…ç½®æ–¹æ³•
- å­¦ä¼šéªŒè¯å®‰è£…å’Œç¯å¢ƒæµ‹è¯•
- äº†è§£ç¼–ç¨‹è¯­è¨€é›†æˆçš„é…ç½®è¦æ±‚
- æŒæ¡å¼€å‘ç¯å¢ƒçš„æœ€ä½³å®è·µ

### 2.2 å¤šå¹³å°å®‰è£…æŒ‡å—

#### ğŸ§ Linux (Ubuntu/Debian) å®‰è£…
```bash
#!/bin/bash
# SQLite3 å®Œæ•´å®‰è£…è„šæœ¬

# æ›´æ–°åŒ…ç®¡ç†å™¨
sudo apt update

# å®‰è£… SQLite3 æ ¸å¿ƒç»„ä»¶
sudo apt install -y sqlite3 libsqlite3-dev sqlite3-tools

# å®‰è£…å¯é€‰çš„æ‰©å±•å·¥å…·
sudo apt install -y sqlite3-pcre libsqlite3-mod-spatialite

# éªŒè¯å®‰è£…
echo "éªŒè¯SQLite3å®‰è£…..."
sqlite3 --version

# æ£€æŸ¥åº“æ–‡ä»¶
pkg-config --exists sqlite3 && echo "âœ… å¼€å‘åº“å·²å®‰è£…" || echo "âŒ å¼€å‘åº“å®‰è£…å¤±è´¥"

# æµ‹è¯•åŸºæœ¬åŠŸèƒ½
echo "æµ‹è¯•æ•°æ®åº“åˆ›å»º..."
sqlite3 test.db "CREATE TABLE test(id INTEGER PRIMARY KEY); INSERT INTO test VALUES(1); SELECT * FROM test;"
rm -f test.db

echo "ğŸ‰ SQLite3 å®‰è£…å®Œæˆ!"
```

#### ğŸ”´ CentOS/RHEL å®‰è£…
```bash
#!/bin/bash
# CentOS/RHEL SQLite3 å®‰è£…è„šæœ¬

# æ£€æµ‹ç³»ç»Ÿç‰ˆæœ¬
if command -v dnf > /dev/null; then
    PKG_MANAGER="dnf"
else
    PKG_MANAGER="yum"
fi

echo "ä½¿ç”¨åŒ…ç®¡ç†å™¨: $PKG_MANAGER"

# å®‰è£… SQLite3
sudo $PKG_MANAGER install -y sqlite sqlite-devel

# ç¼–è¯‘æœ€æ–°ç‰ˆæœ¬ (å¯é€‰)
echo "æ˜¯å¦ç¼–è¯‘å®‰è£…æœ€æ–°ç‰ˆæœ¬? (y/N)"
read -r compile_latest

if [[ $compile_latest =~ ^[Yy]$ ]]; then
    # å®‰è£…ç¼–è¯‘ä¾èµ–
    sudo $PKG_MANAGER groupinstall -y "Development Tools"
    sudo $PKG_MANAGER install -y wget

    # ä¸‹è½½å’Œç¼–è¯‘æœ€æ–°ç‰ˆæœ¬
    SQLITE_VERSION="3450300"  # 3.45.3
    wget https://sqlite.org/2024/sqlite-autoconf-${SQLITE_VERSION}.tar.gz
    tar xzf sqlite-autoconf-${SQLITE_VERSION}.tar.gz
    cd sqlite-autoconf-${SQLITE_VERSION}
    
    ./configure --prefix=/usr/local
    make -j$(nproc)
    sudo make install
    
    # æ›´æ–°åº“è·¯å¾„
    echo "/usr/local/lib" | sudo tee /etc/ld.so.conf.d/sqlite3.conf
    sudo ldconfig
    
    cd .. && rm -rf sqlite-autoconf-${SQLITE_VERSION}*
fi

# éªŒè¯å®‰è£…
sqlite3 --version
echo "âœ… SQLite3 å®‰è£…å®Œæˆ"
```

#### ğŸªŸ Windows å®‰è£…
```powershell
# PowerShell å®‰è£…è„šæœ¬

# æ–¹æ³•1: ä½¿ç”¨ Chocolatey (æ¨è)
if (Get-Command choco -ErrorAction SilentlyContinue) {
    Write-Host "ä½¿ç”¨ Chocolatey å®‰è£… SQLite3..."
    choco install sqlite -y
} else {
    Write-Host "Chocolatey æœªå®‰è£…ï¼Œä½¿ç”¨æ‰‹åŠ¨å®‰è£…..."
    
    # æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½å®‰è£…
    $downloadPath = "$env:TEMP\sqlite-tools.zip"
    $installPath = "C:\sqlite"
    
    # ä¸‹è½½é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶
    Invoke-WebRequest -Uri "https://sqlite.org/2024/sqlite-tools-win32-x86-3450300.zip" -OutFile $downloadPath
    
    # è§£å‹åˆ°å®‰è£…ç›®å½•
    Expand-Archive -Path $downloadPath -DestinationPath $installPath -Force
    
    # æ·»åŠ åˆ° PATH ç¯å¢ƒå˜é‡
    $currentPath = [Environment]::GetEnvironmentVariable("Path", "User")
    if ($currentPath -notlike "*$installPath*") {
        [Environment]::SetEnvironmentVariable("Path", "$currentPath;$installPath", "User")
        Write-Host "å·²å°† SQLite3 æ·»åŠ åˆ° PATH ç¯å¢ƒå˜é‡"
    }
    
    # æ¸…ç†ä¸‹è½½æ–‡ä»¶
    Remove-Item $downloadPath -Force
}

# éªŒè¯å®‰è£…
Write-Host "éªŒè¯ SQLite3 å®‰è£…..."
try {
    $version = sqlite3 --version
    Write-Host "âœ… SQLite3 ç‰ˆæœ¬: $version" -ForegroundColor Green
} catch {
    Write-Host "âŒ SQLite3 å®‰è£…å¤±è´¥æˆ–æœªæ·»åŠ åˆ° PATH" -ForegroundColor Red
}

# åˆ›å»ºæµ‹è¯•æ•°æ®åº“
Write-Host "åˆ›å»ºæµ‹è¯•æ•°æ®åº“..."
sqlite3 test.db "CREATE TABLE users(id INTEGER PRIMARY KEY, name TEXT); INSERT INTO users(name) VALUES('Test User'); SELECT * FROM users;"
Remove-Item test.db -Force
Write-Host "ğŸ‰ SQLite3 å®‰è£…å’Œæµ‹è¯•å®Œæˆ!"
```

#### ğŸ macOS å®‰è£…
```bash
#!/bin/bash
# macOS SQLite3 å®‰è£…è„šæœ¬

# æ£€æŸ¥ Homebrew æ˜¯å¦å·²å®‰è£…
if ! command -v brew &> /dev/null; then
    echo "å®‰è£… Homebrew..."
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
fi

# å®‰è£… SQLite3
echo "å®‰è£… SQLite3..."
brew install sqlite

# å®‰è£…æ‰©å±•å·¥å…·
brew install spatialite-tools

# æ›´æ–° shell é…ç½® (å¦‚æœéœ€è¦)
if [[ $SHELL == */zsh ]]; then
    SHELL_CONFIG="$HOME/.zshrc"
else
    SHELL_CONFIG="$HOME/.bash_profile"
fi

# æ·»åŠ  brew sqlite åˆ° PATH (å¦‚æœç³»ç»Ÿç‰ˆæœ¬è¾ƒè€)
if ! grep -q "brew.*sqlite" "$SHELL_CONFIG" 2>/dev/null; then
    echo 'export PATH="/usr/local/opt/sqlite/bin:$PATH"' >> "$SHELL_CONFIG"
    echo "å·²æ›´æ–° $SHELL_CONFIG"
fi

# é‡è½½é…ç½®
source "$SHELL_CONFIG"

# éªŒè¯å®‰è£…
echo "éªŒè¯å®‰è£…ç»“æœ..."
sqlite3 --version

# æ£€æŸ¥ç¼–è¯‘é€‰é¡¹
sqlite3 -version
echo ""
echo "ç¼–è¯‘é€‰é¡¹:"
sqlite3 :memory: "PRAGMA compile_options;" | head -10

echo "ğŸ‰ macOS SQLite3 å®‰è£…å®Œæˆ!"
```

### 2.3 ç¼–ç¨‹è¯­è¨€é›†æˆé…ç½®

#### ğŸ Python é›†æˆä¸æµ‹è¯•
```python
#!/usr/bin/env python3
"""
SQLite3 Python é›†æˆæµ‹è¯•å’Œé…ç½®è„šæœ¬
æ”¯æŒåŠŸèƒ½éªŒè¯ã€æ€§èƒ½æµ‹è¯•ã€æ‰©å±•æ£€æŸ¥
"""

import sqlite3
import sys
import time
import tempfile
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple

class SQLiteTester:
    """SQLite Python é›†æˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results: Dict[str, bool] = {}
        
    def check_basic_info(self) -> Dict[str, str]:
        """æ£€æŸ¥åŸºæœ¬ä¿¡æ¯å’Œç‰ˆæœ¬"""
        info = {}
        
        # Python sqlite3 æ¨¡å—ç‰ˆæœ¬
        info['python_sqlite3_version'] = sqlite3.version
        info['sqlite_library_version'] = sqlite3.sqlite_version
        info['python_version'] = sys.version
        
        # è¿æ¥æµ‹è¯•
        try:
            with sqlite3.connect(':memory:') as conn:
                cursor = conn.cursor()
                cursor.execute('SELECT SQLITE_VERSION()')
                info['runtime_sqlite_version'] = cursor.fetchone()[0]
                
                # æ£€æŸ¥ç¼–è¯‘é€‰é¡¹
                cursor.execute('PRAGMA compile_options')
                compile_options = [row[0] for row in cursor.fetchall()]
                info['compile_options'] = ', '.join(compile_options[:5]) + '...'
                
                self.results['basic_connection'] = True
        except Exception as e:
            info['connection_error'] = str(e)
            self.results['basic_connection'] = False
            
        return info
    
    def test_features(self) -> Dict[str, bool]:
        """æµ‹è¯•SQLiteç‰¹æ€§æ”¯æŒ"""
        features = {}
        
        with sqlite3.connect(':memory:') as conn:
            cursor = conn.cursor()
            
            # æµ‹è¯•JSONæ”¯æŒ (SQLite 3.38+)
            try:
                cursor.execute("SELECT json('{}') IS NOT NULL")
                features['json_support'] = bool(cursor.fetchone()[0])
            except:
                features['json_support'] = False
            
            # æµ‹è¯•çª—å£å‡½æ•°æ”¯æŒ (SQLite 3.25+)
            try:
                cursor.execute("""
                    WITH test AS (SELECT 1 as val UNION SELECT 2)
                    SELECT val, ROW_NUMBER() OVER() as rn FROM test
                """)
                features['window_functions'] = True
            except:
                features['window_functions'] = False
            
            # æµ‹è¯•CTEæ”¯æŒ
            try:
                cursor.execute("""
                    WITH recursive cnt(x) AS (
                        SELECT 1 UNION SELECT x+1 FROM cnt WHERE x<3
                    ) SELECT x FROM cnt
                """)
                features['cte_support'] = True
            except:
                features['cte_support'] = False
            
            # æµ‹è¯•FTSæ”¯æŒ
            try:
                cursor.execute("CREATE VIRTUAL TABLE ft USING fts5(content)")
                cursor.execute("DROP TABLE ft")
                features['fts5_support'] = True
            except:
                features['fts5_support'] = False
            
            # æµ‹è¯•R-Treeæ”¯æŒ
            try:
                cursor.execute("CREATE VIRTUAL TABLE rt USING rtree(id, x1, x2)")
                cursor.execute("DROP TABLE rt")
                features['rtree_support'] = True
            except:
                features['rtree_support'] = False
                
        return features
    
    def performance_test(self) -> Dict[str, float]:
        """ç®€å•çš„æ€§èƒ½æµ‹è¯•"""
        perf_results = {}
        
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp:
            db_path = tmp.name
        
        try:
            # æ’å…¥æ€§èƒ½æµ‹è¯•
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    CREATE TABLE perf_test (
                        id INTEGER PRIMARY KEY,
                        data TEXT,
                        timestamp REAL
                    )
                """)
                
                # æ‰¹é‡æ’å…¥æµ‹è¯•
                start_time = time.time()
                test_data = [(i, f'test_data_{i}', time.time()) for i in range(1000)]
                cursor.executemany(
                    'INSERT INTO perf_test (id, data, timestamp) VALUES (?, ?, ?)',
                    test_data
                )
                conn.commit()
                insert_time = time.time() - start_time
                perf_results['insert_1000_records'] = round(insert_time, 4)
                
                # æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
                start_time = time.time()
                cursor.execute('SELECT COUNT(*) FROM perf_test WHERE id < 500')
                cursor.fetchone()
                query_time = time.time() - start_time
                perf_results['query_with_condition'] = round(query_time, 4)
                
                # ç´¢å¼•åˆ›å»ºæµ‹è¯•
                start_time = time.time()
                cursor.execute('CREATE INDEX idx_data ON perf_test(data)')
                index_time = time.time() - start_time
                perf_results['create_index'] = round(index_time, 4)
                
        finally:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            try:
                os.unlink(db_path)
            except:
                pass
                
        return perf_results
    
    def run_comprehensive_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶"""
        print("ğŸ” SQLite3 Python é›†æˆç»¼åˆæµ‹è¯•")
        print("=" * 50)
        
        # åŸºæœ¬ä¿¡æ¯æ£€æŸ¥
        print("\nğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
        basic_info = self.check_basic_info()
        for key, value in basic_info.items():
            print(f"  {key}: {value}")
        
        # åŠŸèƒ½ç‰¹æ€§æµ‹è¯•
        print("\nğŸ§ª åŠŸèƒ½ç‰¹æ€§æµ‹è¯•:")
        features = self.test_features()
        for feature, supported in features.items():
            status = "âœ…" if supported else "âŒ"
            print(f"  {feature}: {status}")
        
        # æ€§èƒ½æµ‹è¯•
        print("\nâš¡ æ€§èƒ½æµ‹è¯•:")
        perf_results = self.performance_test()
        for test, duration in perf_results.items():
            print(f"  {test}: {duration}s")
        
        # æ€»ç»“
        print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        total_features = len(features)
        supported_features = sum(features.values())
        print(f"  æ”¯æŒçš„åŠŸèƒ½ç‰¹æ€§: {supported_features}/{total_features}")
        
        if self.results.get('basic_connection', False):
            print("  âœ… SQLite3 Python é›†æˆæ­£å¸¸å·¥ä½œ")
        else:
            print("  âŒ SQLite3 Python é›†æˆå­˜åœ¨é—®é¢˜")

def install_python_dependencies():
    """å®‰è£…Pythonç›¸å…³ä¾èµ–"""
    import subprocess
    
    packages = [
        'sqlite3',  # å†…ç½®æ¨¡å—ï¼Œæ— éœ€å®‰è£…
        # å¯é€‰æ‰©å±•åŒ…
        # 'pysqlite3',  # å¦‚æœéœ€è¦æœ€æ–°ç‰ˆæœ¬
        # 'sqlalchemy',  # ORMæ”¯æŒ
        # 'dataset',     # ç®€åŒ–çš„æ•°æ®åº“æ“ä½œ
    ]
    
    print("æ£€æŸ¥Python SQLite3ä¾èµ–...")
    try:
        import sqlite3
        print("âœ… sqlite3 æ¨¡å—å¯ç”¨")
    except ImportError:
        print("âŒ sqlite3 æ¨¡å—ä¸å¯ç”¨ (è¿™ä¸åº”è¯¥å‘ç”Ÿ)")

if __name__ == "__main__":
    install_python_dependencies()
    tester = SQLiteTester()
    tester.run_comprehensive_test()
```

#### ğŸŸ¨ Node.js é›†æˆä¸æµ‹è¯•
```javascript
#!/usr/bin/env node
/**
 * SQLite3 Node.js é›†æˆæµ‹è¯•å’Œé…ç½®è„šæœ¬
 * æ”¯æŒå¼‚æ­¥æ“ä½œã€è¿æ¥æ± ã€æ€§èƒ½æµ‹è¯•
 */

const sqlite3 = require('sqlite3').verbose();
const fs = require('fs');
const path = require('path');
const os = require('os');

class SQLiteNodeTester {
    constructor() {
        this.testResults = {};
    }

    async checkBasicInfo() {
        return new Promise((resolve, reject) => {
            const info = {};
            info.nodeVersion = process.version;
            info.platform = process.platform;
            info.arch = process.arch;
            
            const db = new sqlite3.Database(':memory:', (err) => {
                if (err) {
                    info.connectionError = err.message;
                    resolve(info);
                    return;
                }

                db.get('SELECT sqlite_version() AS version', (err, row) => {
                    if (err) {
                        info.queryError = err.message;
                    } else {
                        info.sqliteVersion = row.version;
                    }

                    // æ£€æŸ¥ç¼–è¯‘é€‰é¡¹
                    db.all('PRAGMA compile_options', (err, rows) => {
                        if (!err) {
                            info.compileOptions = rows.slice(0, 5).map(r => r['compile_options']).join(', ') + '...';
                        }

                        db.close((err) => {
                            if (!err) {
                                this.testResults.basicConnection = true;
                            }
                            resolve(info);
                        });
                    });
                });
            });
        });
    }

    async testFeatures() {
        return new Promise((resolve) => {
            const features = {};
            const db = new sqlite3.Database(':memory:');

            const testPromises = [];

            // æµ‹è¯•JSONæ”¯æŒ
            testPromises.push(new Promise((res) => {
                db.get("SELECT json('{}') IS NOT NULL as supported", (err, row) => {
                    features.jsonSupport = !err && row && row.supported;
                    res();
                });
            }));

            // æµ‹è¯•çª—å£å‡½æ•°
            testPromises.push(new Promise((res) => {
                db.get(`
                    WITH test AS (SELECT 1 as val UNION SELECT 2)
                    SELECT val, ROW_NUMBER() OVER() as rn FROM test LIMIT 1
                `, (err, row) => {
                    features.windowFunctions = !err;
                    res();
                });
            }));

            // æµ‹è¯•CTE
            testPromises.push(new Promise((res) => {
                db.get(`
                    WITH recursive cnt(x) AS (
                        SELECT 1 UNION SELECT x+1 FROM cnt WHERE x<3
                    ) SELECT x FROM cnt LIMIT 1
                `, (err, row) => {
                    features.cteSupport = !err;
                    res();
                });
            }));

            // æµ‹è¯•FTS5
            testPromises.push(new Promise((res) => {
                db.run("CREATE VIRTUAL TABLE ft USING fts5(content)", (err) => {
                    if (!err) {
                        db.run("DROP TABLE ft", () => {
                            features.fts5Support = true;
                            res();
                        });
                    } else {
                        features.fts5Support = false;
                        res();
                    }
                });
            }));

            Promise.all(testPromises).then(() => {
                db.close();
                resolve(features);
            });
        });
    }

    async performanceTest() {
        return new Promise((resolve) => {
            const perfResults = {};
            const tmpPath = path.join(os.tmpdir(), `sqlite_test_${Date.now()}.db`);
            const db = new sqlite3.Database(tmpPath);

            db.serialize(() => {
                // åˆ›å»ºæµ‹è¯•è¡¨
                db.run(`
                    CREATE TABLE perf_test (
                        id INTEGER PRIMARY KEY,
                        data TEXT,
                        timestamp REAL
                    )
                `);

                // æ‰¹é‡æ’å…¥æ€§èƒ½æµ‹è¯•
                const insertStart = Date.now();
                const stmt = db.prepare('INSERT INTO perf_test (data, timestamp) VALUES (?, ?)');
                
                for (let i = 0; i < 1000; i++) {
                    stmt.run(`test_data_${i}`, Date.now());
                }
                
                stmt.finalize(() => {
                    const insertTime = (Date.now() - insertStart) / 1000;
                    perfResults.insert1000Records = parseFloat(insertTime.toFixed(4));

                    // æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
                    const queryStart = Date.now();
                    db.get('SELECT COUNT(*) as count FROM perf_test WHERE id < 500', (err, row) => {
                        const queryTime = (Date.now() - queryStart) / 1000;
                        perfResults.queryWithCondition = parseFloat(queryTime.toFixed(4));

                        // ç´¢å¼•åˆ›å»ºæµ‹è¯•
                        const indexStart = Date.now();
                        db.run('CREATE INDEX idx_data ON perf_test(data)', (err) => {
                            const indexTime = (Date.now() - indexStart) / 1000;
                            perfResults.createIndex = parseFloat(indexTime.toFixed(4));

                            db.close(() => {
                                // æ¸…ç†æµ‹è¯•æ–‡ä»¶
                                try {
                                    fs.unlinkSync(tmpPath);
                                } catch (e) {
                                    // å¿½ç•¥æ¸…ç†é”™è¯¯
                                }
                                resolve(perfResults);
                            });
                        });
                    });
                });
            });
        });
    }

    async runComprehensiveTest() {
        console.log('ğŸ” SQLite3 Node.js é›†æˆç»¼åˆæµ‹è¯•');
        console.log('='.repeat(50));

        try {
            // åŸºæœ¬ä¿¡æ¯æ£€æŸ¥
            console.log('\nğŸ“‹ åŸºæœ¬ä¿¡æ¯:');
            const basicInfo = await this.checkBasicInfo();
            Object.entries(basicInfo).forEach(([key, value]) => {
                console.log(`  ${key}: ${value}`);
            });

            // åŠŸèƒ½ç‰¹æ€§æµ‹è¯•
            console.log('\nğŸ§ª åŠŸèƒ½ç‰¹æ€§æµ‹è¯•:');
            const features = await this.testFeatures();
            Object.entries(features).forEach(([feature, supported]) => {
                const status = supported ? 'âœ…' : 'âŒ';
                console.log(`  ${feature}: ${status}`);
            });

            // æ€§èƒ½æµ‹è¯•
            console.log('\nâš¡ æ€§èƒ½æµ‹è¯•:');
            const perfResults = await this.performanceTest();
            Object.entries(perfResults).forEach(([test, duration]) => {
                console.log(`  ${test}: ${duration}s`);
            });

            // æ€»ç»“
            console.log('\nğŸ“Š æµ‹è¯•æ€»ç»“:');
            const totalFeatures = Object.keys(features).length;
            const supportedFeatures = Object.values(features).filter(Boolean).length;
            console.log(`  æ”¯æŒçš„åŠŸèƒ½ç‰¹æ€§: ${supportedFeatures}/${totalFeatures}`);
            
            if (this.testResults.basicConnection) {
                console.log('  âœ… SQLite3 Node.js é›†æˆæ­£å¸¸å·¥ä½œ');
            } else {
                console.log('  âŒ SQLite3 Node.js é›†æˆå­˜åœ¨é—®é¢˜');
            }

        } catch (error) {
            console.error('æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:', error);
        }
    }
}

// å®‰è£…ä¾èµ–æ£€æŸ¥
function checkDependencies() {
    console.log('æ£€æŸ¥ Node.js SQLite3 ä¾èµ–...');
    
    try {
        require('sqlite3');
        console.log('âœ… sqlite3 åŒ…å·²å®‰è£…');
        return true;
    } catch (error) {
        console.log('âŒ sqlite3 åŒ…æœªå®‰è£…');
        console.log('è¯·è¿è¡Œ: npm install sqlite3');
        return false;
    }
}

// ä¸»å‡½æ•°
async function main() {
    if (!checkDependencies()) {
        process.exit(1);
    }

    const tester = new SQLiteNodeTester();
    await tester.runComprehensiveTest();
}

if (require.main === module) {
    main().catch(console.error);
}

module.exports = SQLiteNodeTester;
```

### 2.4 å¼€å‘ç¯å¢ƒæœ€ä½³å®è·µ

#### ğŸ› ï¸ IDEå’Œå·¥å…·é…ç½®

**VS Code æ‰©å±•æ¨è:**
```json
{
    "recommendations": [
        "alexcvzz.vscode-sqlite",          // SQLiteæµè§ˆå™¨
        "qwtel.sqlite-viewer",             // SQLiteæŸ¥çœ‹å™¨  
        "ms-python.python",                // Pythonæ”¯æŒ
        "bradlc.vscode-tailwindcss",       // SQLè¯­æ³•é«˜äº®
        "formulahendry.code-runner"        // ä»£ç è¿è¡Œå™¨
    ]
}
```

**å¼€å‘ç¯å¢ƒé…ç½®è„šæœ¬:**
```bash
#!/bin/bash
# å¼€å‘ç¯å¢ƒå¿«é€Ÿé…ç½®è„šæœ¬

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
mkdir -p sqlite_project/{src,tests,docs,scripts,data}
cd sqlite_project

# åˆå§‹åŒ–Pythonç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip

# åˆ›å»ºrequirements.txt
cat > requirements.txt << EOF
# SQLiteç›¸å…³
# æ³¨æ„: sqlite3 æ˜¯Pythonå†…ç½®æ¨¡å—ï¼Œæ— éœ€å®‰è£…

# å¼€å‘å·¥å…·
pytest>=7.0.0
pytest-cov>=4.0.0
black>=22.0.0
flake8>=5.0.0
mypy>=1.0.0

# å¯é€‰çš„SQLiteæ‰©å±•
sqlalchemy>=2.0.0
dataset>=1.6.0
pandas>=2.0.0

# æ–‡æ¡£å·¥å…·
sphinx>=5.0.0
sphinx-rtd-theme>=1.0.0
EOF

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# åˆ›å»ºåŸºæœ¬çš„é¡¹ç›®é…ç½®
cat > pyproject.toml << EOF
[tool.black]
line-length = 88
target-version = ['py38']

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "--cov=src --cov-report=html --cov-report=term-missing"
EOF

echo "âœ… SQLiteå¼€å‘ç¯å¢ƒé…ç½®å®Œæˆ!"
echo "ğŸ“ é¡¹ç›®ç»“æ„å·²åˆ›å»ºåœ¨ $(pwd)"
echo "ğŸ è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»"
```

## 3. æ•°æ®ç±»å‹ç³»ç»Ÿ

### 3.1 å­¦ä¹ ç›®æ ‡
- æŒæ¡SQLite3çš„åŠ¨æ€ç±»å‹ç³»ç»Ÿå’Œå­˜å‚¨ç±»
- ç†è§£ç±»å‹äº²å’Œæ€§å’Œè½¬æ¢è§„åˆ™
- å­¦ä¼šå¤„ç†å„ç§æ•°æ®ç±»å‹çš„æœ€ä½³å®è·µ
- äº†è§£JSONå’Œå…¶ä»–æ‰©å±•ç±»å‹çš„ä½¿ç”¨

### 3.2 å­˜å‚¨ç±»è¯¦è§£

SQLite3ä½¿ç”¨åŠ¨æ€ç±»å‹ç³»ç»Ÿï¼Œå…·æœ‰5ç§åŸºæœ¬å­˜å‚¨ç±»ï¼š

| å­˜å‚¨ç±» | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|
| **NULL** | ç©ºå€¼ | `NULL` |
| **INTEGER** | æœ‰ç¬¦å·æ•´æ•°ï¼Œ1-8å­—èŠ‚ | `123`, `-456` |
| **REAL** | æµ®ç‚¹æ•°ï¼Œ8å­—èŠ‚IEEEæµ®ç‚¹ | `3.14159`, `1.0e10` |
| **TEXT** | UTF-8/UTF-16æ–‡æœ¬å­—ç¬¦ä¸² | `'Hello'`, `'ä¸­æ–‡'` |
| **BLOB** | äºŒè¿›åˆ¶æ•°æ® | `X'48656C6C6F'` |

```sql
-- å­˜å‚¨ç±»æ¼”ç¤ºè¡¨
CREATE TABLE type_comprehensive_demo (
    id INTEGER PRIMARY KEY,
    
    -- æ•°å€¼ç±»å‹ç¤ºä¾‹
    int_value INTEGER,
    real_value REAL,
    numeric_value NUMERIC,
    
    -- æ–‡æœ¬ç±»å‹ç¤ºä¾‹  
    text_value TEXT,
    varchar_value VARCHAR(100),
    char_value CHAR(10),
    
    -- æ—¥æœŸæ—¶é—´ç±»å‹ (å®é™…å­˜å‚¨ä¸ºTEXT/INTEGER/REAL)
    datetime_text DATETIME,
    date_integer INTEGER,  -- å­˜å‚¨Unixæ—¶é—´æˆ³
    time_real REAL,        -- å­˜å‚¨Julianæ—¥æœŸ
    
    -- äºŒè¿›åˆ¶æ•°æ®
    blob_data BLOB,
    
    -- å¸ƒå°”ç±»å‹ (å®é™…å­˜å‚¨ä¸ºINTEGER 0/1)
    boolean_flag BOOLEAN,
    
    -- JSONç±»å‹ (SQLite 3.38+, å®é™…å­˜å‚¨ä¸ºTEXT)
    json_data JSON
);

-- æ’å…¥å„ç§ç±»å‹çš„æ•°æ®
INSERT INTO type_comprehensive_demo VALUES (
    1,
    -- æ•°å€¼ç±»å‹
    42,                              -- INTEGER
    3.14159,                         -- REAL
    123.45,                          -- NUMERIC (å­˜å‚¨ä¸ºREAL)
    
    -- æ–‡æœ¬ç±»å‹
    'Hello SQLite',                  -- TEXT
    'Variable Length Text',          -- VARCHAR (å­˜å‚¨ä¸ºTEXT)
    'Fixed',                         -- CHAR (å­˜å‚¨ä¸ºTEXT)
    
    -- æ—¥æœŸæ—¶é—´
    '2024-01-15 10:30:00',          -- DATETIME as TEXT
    strftime('%s', 'now'),           -- Unix timestamp as INTEGER
    julianday('now'),                -- Julian date as REAL
    
    -- äºŒè¿›åˆ¶æ•°æ®
    randomblob(16),                  -- BLOB
    
    -- å¸ƒå°”å€¼
    1,                               -- BOOLEAN as INTEGER
    
    -- JSONæ•°æ®
    json_object('name', 'Alice', 'age', 30)  -- JSON as TEXT
);

-- ç±»å‹æ£€æŸ¥å’Œåˆ†ææŸ¥è¯¢
SELECT 
    'Type Analysis' as category,
    'Column' as name,
    'Value' as value,
    'Storage Class' as storage_class,
    'Length' as length
UNION ALL
SELECT 
    'INTEGER',
    'int_value',
    CAST(int_value AS TEXT),
    typeof(int_value),
    CAST(length(int_value) AS TEXT)
FROM type_comprehensive_demo
UNION ALL
SELECT 
    'REAL',
    'real_value', 
    CAST(real_value AS TEXT),
    typeof(real_value),
    CAST(length(real_value) AS TEXT)
FROM type_comprehensive_demo
UNION ALL
SELECT
    'TEXT',
    'text_value',
    text_value,
    typeof(text_value),
    CAST(length(text_value) AS TEXT)
FROM type_comprehensive_demo
UNION ALL
SELECT
    'BLOB',
    'blob_data',
    'BLOB(' || length(blob_data) || ' bytes)',
    typeof(blob_data),
    CAST(length(blob_data) AS TEXT)
FROM type_comprehensive_demo
UNION ALL
SELECT
    'JSON',
    'json_data',
    json_data,
    typeof(json_data),
    CAST(length(json_data) AS TEXT)
FROM type_comprehensive_demo;
```

### 3.3 ç±»å‹äº²å’Œæ€§è§„åˆ™

SQLiteä½¿ç”¨ç±»å‹äº²å’Œæ€§æ¥ç¡®å®šå¦‚ä½•å­˜å‚¨å’Œæ¯”è¾ƒæ•°æ®ï¼š

```sql
-- ç±»å‹äº²å’Œæ€§æ¼”ç¤º
CREATE TABLE affinity_demo (
    id INTEGER PRIMARY KEY,
    
    -- INTEGER affinity
    int_col INTEGER,
    bigint_col BIGINT,
    int2_col INT2,
    int8_col INT8,
    
    -- TEXT affinity  
    text_col TEXT,
    char_col CHAR(100),
    varchar_col VARCHAR(255),
    clob_col CLOB,
    
    -- BLOB affinity
    blob_col BLOB,
    
    -- REAL affinity
    real_col REAL,
    double_col DOUBLE,
    float_col FLOAT,
    
    -- NUMERIC affinity
    numeric_col NUMERIC,
    decimal_col DECIMAL(10,5),
    boolean_col BOOLEAN,
    date_col DATE,
    datetime_col DATETIME
);

-- æµ‹è¯•ç±»å‹äº²å’Œæ€§
INSERT INTO affinity_demo (
    int_col, text_col, blob_col, real_col, numeric_col,
    boolean_col, date_col, datetime_col
) VALUES 
    -- æ’å…¥ç›¸åŒçš„å€¼ï¼Œè§‚å¯Ÿä¸åŒåˆ—çš„å­˜å‚¨æ–¹å¼
    ('123', '123', '123', '123', '123', 'true', '2024-01-01', '2024-01-01 10:00:00'),
    (45.67, 45.67, 45.67, 45.67, 45.67, 1, 1704067200, datetime('now')),
    (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL);

-- æŸ¥çœ‹å®é™…å­˜å‚¨ç±»å‹
SELECT 
    'Value: 123 (text input)' as test_case,
    typeof(int_col) || ': ' || CAST(int_col AS TEXT) as integer_affinity,
    typeof(text_col) || ': ' || CAST(text_col AS TEXT) as text_affinity,
    typeof(real_col) || ': ' || CAST(real_col AS TEXT) as real_affinity,
    typeof(numeric_col) || ': ' || CAST(numeric_col AS TEXT) as numeric_affinity
FROM affinity_demo WHERE rowid = 1
UNION ALL
SELECT 
    'Value: 45.67 (numeric input)',
    typeof(int_col) || ': ' || CAST(int_col AS TEXT),
    typeof(text_col) || ': ' || CAST(text_col AS TEXT),
    typeof(real_col) || ': ' || CAST(real_col AS TEXT),
    typeof(numeric_col) || ': ' || CAST(numeric_col AS TEXT)
FROM affinity_demo WHERE rowid = 2;
```

### 3.4 ç±»å‹è½¬æ¢æ·±åº¦è§£æ

```sql
-- åˆ›å»ºç±»å‹è½¬æ¢æµ‹è¯•è¡¨
CREATE TABLE conversion_test (
    id INTEGER PRIMARY KEY,
    text_value TEXT,
    description TEXT
);

-- æ’å…¥å„ç§æµ‹è¯•æ•°æ®
INSERT INTO conversion_test (text_value, description) VALUES 
('123', 'çº¯æ•°å­—å­—ç¬¦ä¸²'),
('123.45', 'æµ®ç‚¹æ•°å­—ç¬¦ä¸²'),
('123.45.67', 'æ— æ•ˆæ•°å­—æ ¼å¼'),
(' 123 ', 'å¸¦ç©ºæ ¼çš„æ•°å­—'),
('123abc', 'æ•°å­—å¼€å¤´çš„æ··åˆå­—ç¬¦ä¸²'),
('abc123', 'å­—æ¯å¼€å¤´çš„æ··åˆå­—ç¬¦ä¸²'),
('', 'ç©ºå­—ç¬¦ä¸²'),
('0', 'é›¶å€¼å­—ç¬¦ä¸²'),
('true', 'å¸ƒå°”å€¼å­—ç¬¦ä¸²'),
('false', 'å¸ƒå°”å€¼å­—ç¬¦ä¸²'),
('1.23e4', 'ç§‘å­¦è®¡æ•°æ³•'),
('-456', 'è´Ÿæ•°'),
('0x1A', 'åå…­è¿›åˆ¶æ ¼å¼(ä¸æ”¯æŒ)');

-- ç»¼åˆç±»å‹è½¬æ¢æµ‹è¯•
SELECT 
    text_value,
    description,
    
    -- åŸå§‹ç±»å‹
    typeof(text_value) as original_type,
    
    -- æ•°å€¼è½¬æ¢
    CASE 
        WHEN text_value GLOB '*[!0-9.-]*' THEN 'Invalid'
        ELSE CAST(text_value AS INTEGER)
    END as to_integer,
    
    typeof(CAST(text_value AS INTEGER)) as integer_type,
    
    CASE 
        WHEN text_value GLOB '*[!0-9.-]*' AND text_value NOT GLOB '*[eE]*' THEN 'Invalid'
        ELSE CAST(text_value AS REAL)
    END as to_real,
    
    typeof(CAST(text_value AS REAL)) as real_type,
    
    -- æ•°å­¦è¿ç®—ä¸­çš„éšå¼è½¬æ¢
    CASE 
        WHEN typeof(text_value + 0) = 'null' THEN 'No conversion'
        ELSE CAST(text_value + 0 AS TEXT)
    END as arithmetic_conversion,
    
    typeof(text_value + 0) as arithmetic_type,
    
    -- æ¯”è¾ƒè¿ç®—ä¸­çš„è½¬æ¢
    CASE 
        WHEN text_value = 0 THEN 'Equal to 0'
        WHEN text_value > 0 THEN 'Greater than 0'
        WHEN text_value < 0 THEN 'Less than 0'
        ELSE 'Not comparable'
    END as comparison_result
    
FROM conversion_test
ORDER BY id;

-- ç±»å‹è½¬æ¢å‡½æ•°è¯¦è§£
SELECT 
    'Type Conversion Functions' as category,
    'Function' as func_name,
    'Input' as input_val,
    'Output' as output_val,
    'Type' as output_type
UNION ALL
SELECT
    'CAST Examples',
    'CAST(''123'' AS INTEGER)',
    '''123''',
    CAST(CAST('123' AS INTEGER) AS TEXT),
    typeof(CAST('123' AS INTEGER))
UNION ALL
SELECT
    '',
    'CAST(''123.45'' AS REAL)', 
    '''123.45''',
    CAST(CAST('123.45' AS REAL) AS TEXT),
    typeof(CAST('123.45' AS REAL))
UNION ALL
SELECT
    '',
    'CAST(123 AS TEXT)',
    '123',
    CAST(123 AS TEXT),
    typeof(CAST(123 AS TEXT))
UNION ALL
SELECT
    'Implicit Conversion',
    '''123'' + 0',
    '''123''',
    CAST('123' + 0 AS TEXT),
    typeof('123' + 0)
UNION ALL
SELECT
    '',
    '''123.45'' * 1',
    '''123.45''',
    CAST('123.45' * 1 AS TEXT),
    typeof('123.45' * 1);
```

## 4. æ ¸å¿ƒSQLæ“ä½œ

### 4.1 å­¦ä¹ ç›®æ ‡
- æŒæ¡æ•°æ®åº“å’Œè¡¨çš„åˆ›å»ºã€ä¿®æ”¹ã€åˆ é™¤æ“ä½œ
- å­¦ä¼šè®¾è®¡é«˜æ•ˆçš„ç´¢å¼•ç­–ç•¥
- æŒæ¡å¤æ‚æŸ¥è¯¢å’Œè¿æ¥æ“ä½œ
- äº†è§£äº‹åŠ¡å¤„ç†å’Œå¹¶å‘æ§åˆ¶

### 4.2 æ•°æ®åº“å’Œè¡¨çš„ç³»ç»Ÿæ€§æ“ä½œ

#### æ•°æ®åº“åˆ›å»ºå’Œç®¡ç†
```sql
-- å‘½ä»¤è¡Œæ“ä½œ (ä½¿ç”¨ sqlite3 å‘½ä»¤)
.open example.db          -- æ‰“å¼€æˆ–åˆ›å»ºæ•°æ®åº“
.databases                -- æŸ¥çœ‹å·²é™„åŠ çš„æ•°æ®åº“
.tables                   -- åˆ—å‡ºæ‰€æœ‰è¡¨
.schema table_name        -- æŸ¥çœ‹è¡¨ç»“æ„
.backup backup.db         -- å¤‡ä»½æ•°æ®åº“
.restore backup.db        -- è¿˜åŸæ•°æ®åº“
.dump                     -- å¯¼å‡ºæ•°æ®åº“SQL
.read script.sql          -- æ‰§è¡ŒSQLè„šæœ¬
.mode csv                 -- è®¾ç½®è¾“å‡ºæ ¼å¼
.headers on               -- æ˜¾ç¤ºåˆ—å¤´
.width 20 10 15           -- è®¾ç½®åˆ—å®½åº¦
.timer on                 -- æ˜¾ç¤ºæ‰§è¡Œæ—¶é—´

-- é™„åŠ å’Œåˆ†ç¦»æ•°æ®åº“
ATTACH DATABASE 'backup.db' AS backup;
ATTACH DATABASE ':memory:' AS temp_db;
DETACH DATABASE backup;

-- æ•°æ®åº“å…ƒæ•°æ®æŸ¥è¯¢
SELECT name FROM sqlite_master WHERE type='table';
SELECT sql FROM sqlite_master WHERE name='users';
SELECT * FROM pragma_table_info('users');
```

#### ä¼ä¸šçº§è¡¨ç»“æ„è®¾è®¡
```sql
-- ç”¨æˆ·ç³»ç»Ÿè¡¨è®¾è®¡
CREATE TABLE IF NOT EXISTS users (
    user_id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT NOT NULL UNIQUE COLLATE NOCASE,
    email TEXT NOT NULL UNIQUE COLLATE NOCASE,
    password_hash TEXT NOT NULL,
    salt TEXT NOT NULL,
    
    -- ä¸ªäººä¿¡æ¯
    first_name TEXT,
    last_name TEXT,
    phone TEXT,
    avatar_url TEXT,
    
    -- çŠ¶æ€ç®¡ç†
    status TEXT DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'suspended', 'deleted')),
    email_verified BOOLEAN DEFAULT 0,
    phone_verified BOOLEAN DEFAULT 0,
    
    -- æ—¶é—´æˆ³
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    updated_at DATETIME DEFAULT (datetime('now', 'localtime')),
    last_login_at DATETIME,
    
    -- JSONæ•°æ® (éœ€è¦ SQLite 3.38+)
    preferences JSON DEFAULT '{}',
    metadata JSON DEFAULT '{}',
    
    -- çº¦æŸè®¾è®¡
    CONSTRAINT chk_email_format CHECK (email LIKE '%_@_%.__%'),
    CONSTRAINT chk_username_length CHECK (length(username) >= 3 AND length(username) <= 50),
    CONSTRAINT chk_phone_format CHECK (phone IS NULL OR length(phone) >= 10)
);

-- äº§å“ç®¡ç†ç³»ç»Ÿè¡¨
CREATE TABLE categories (
    category_id INTEGER PRIMARY KEY AUTOINCREMENT,
    category_name TEXT NOT NULL UNIQUE,
    parent_id INTEGER,
    description TEXT,
    is_active BOOLEAN DEFAULT 1,
    sort_order INTEGER DEFAULT 0,
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    updated_at DATETIME DEFAULT (datetime('now', 'localtime')),
    FOREIGN KEY (parent_id) REFERENCES categories(category_id)
);

CREATE TABLE products (
    product_id INTEGER PRIMARY KEY AUTOINCREMENT,
    sku TEXT NOT NULL UNIQUE,
    product_name TEXT NOT NULL,
    category_id INTEGER NOT NULL,
    
    -- ä»·æ ¼ä¿¡æ¯
    price DECIMAL(12,4) CHECK (price >= 0),
    cost_price DECIMAL(12,4) CHECK (cost_price >= 0),
    sale_price DECIMAL(12,4),
    
    -- åº“å­˜ç®¡ç†
    stock_quantity INTEGER DEFAULT 0 CHECK (stock_quantity >= 0),
    min_stock_level INTEGER DEFAULT 0,
    max_stock_level INTEGER,
    
    -- äº§å“ä¿¡æ¯
    description TEXT,
    short_description TEXT,
    specifications JSON DEFAULT '{}',
    
    -- ç‰©ç†ä¿¡æ¯
    weight DECIMAL(8,3),
    dimensions JSON,  -- {"length": 10, "width": 20, "height": 5}
    
    -- çŠ¶æ€ç®¡ç†
    status TEXT DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'discontinued')),
    is_featured BOOLEAN DEFAULT 0,
    
    -- æ—¶é—´æˆ³
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    updated_at DATETIME DEFAULT (datetime('now', 'localtime')),
    
    FOREIGN KEY (category_id) REFERENCES categories(category_id),
    CONSTRAINT chk_price_logic CHECK (sale_price IS NULL OR sale_price <= price),
    CONSTRAINT chk_stock_logic CHECK (max_stock_level IS NULL OR max_stock_level >= min_stock_level)
);

-- è®¢å•ç³»ç»Ÿè¡¨
CREATE TABLE orders (
    order_id INTEGER PRIMARY KEY AUTOINCREMENT,
    order_number TEXT NOT NULL UNIQUE,
    user_id INTEGER NOT NULL,
    
    -- è®¢å•é‡‘é¢
    subtotal DECIMAL(12,4) DEFAULT 0 CHECK (subtotal >= 0),
    tax_amount DECIMAL(12,4) DEFAULT 0 CHECK (tax_amount >= 0),
    shipping_amount DECIMAL(12,4) DEFAULT 0 CHECK (shipping_amount >= 0),
    discount_amount DECIMAL(12,4) DEFAULT 0 CHECK (discount_amount >= 0),
    total_amount DECIMAL(12,4) GENERATED ALWAYS AS (subtotal + tax_amount + shipping_amount - discount_amount) VIRTUAL,
    
    -- è®¢å•çŠ¶æ€
    status TEXT DEFAULT 'pending' CHECK (status IN (
        'pending', 'confirmed', 'processing', 'shipped', 
        'delivered', 'cancelled', 'refunded', 'returned'
    )),
    payment_status TEXT DEFAULT 'pending' CHECK (payment_status IN (
        'pending', 'paid', 'failed', 'refunded', 'partial'
    )),
    
    -- åœ°å€ä¿¡æ¯
    shipping_address JSON NOT NULL,
    billing_address JSON,
    
    -- æ—¶é—´æˆ³
    order_date DATETIME DEFAULT (datetime('now', 'localtime')),
    shipped_at DATETIME,
    delivered_at DATETIME,
    cancelled_at DATETIME,
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    updated_at DATETIME DEFAULT (datetime('now', 'localtime')),
    
    -- å¤‡æ³¨ä¿¡æ¯
    notes TEXT,
    internal_notes TEXT,
    
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- è®¢å•æ˜ç»†è¡¨
CREATE TABLE order_items (
    order_item_id INTEGER PRIMARY KEY AUTOINCREMENT,
    order_id INTEGER NOT NULL,
    product_id INTEGER NOT NULL,
    
    quantity INTEGER NOT NULL CHECK (quantity > 0),
    unit_price DECIMAL(12,4) NOT NULL CHECK (unit_price >= 0),
    total_price DECIMAL(12,4) GENERATED ALWAYS AS (quantity * unit_price) VIRTUAL,
    
    -- äº§å“å¿«ç…§ (é˜²æ­¢äº§å“ä¿¡æ¯å˜æ›´)
    product_name TEXT NOT NULL,
    product_sku TEXT NOT NULL,
    
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    
    FOREIGN KEY (order_id) REFERENCES orders(order_id) ON DELETE CASCADE,
    FOREIGN KEY (product_id) REFERENCES products(product_id)
);
```

### 4.3 é«˜æ•ˆç´¢å¼•è®¾è®¡ç­–ç•¥

```sql
-- ä¸€ã€åŸºæœ¬ç´¢å¼•è®¾è®¡åŸåˆ™
-- 1. å•åˆ—ç´¢å¼• - ç”¨äºé«˜é¢‘æŸ¥è¯¢å’Œå¤–é”®
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at);
CREATE INDEX idx_users_status ON users(status);

CREATE INDEX idx_products_category_id ON products(category_id);
CREATE INDEX idx_products_sku ON products(sku);
CREATE INDEX idx_products_status ON products(status);
CREATE INDEX idx_products_price ON products(price);

CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_orders_order_date ON orders(order_date);

-- 2. å¤åˆç´¢å¼• - æŒ‰æŸ¥è¯¢é¢‘ç‡å’Œé€‰æ‹©æ€§æ’åº
-- åŸåˆ™ï¼šé€‰æ‹©æ€§é«˜çš„åˆ—åœ¨å‰ï¼ŒæŸ¥è¯¢é¢‘ç‡é«˜çš„åˆ—åœ¨å‰
CREATE INDEX idx_products_category_status_price ON products(category_id, status, price);
CREATE INDEX idx_orders_user_status_date ON orders(user_id, status, order_date DESC);
CREATE INDEX idx_users_status_created ON users(status, created_at DESC);

-- 3. è¦†ç›–ç´¢å¼• - åŒ…å«æŸ¥è¯¢æ‰€éœ€çš„æ‰€æœ‰åˆ—
-- é¿å…å›è¡¨æŸ¥è¯¢ï¼Œæé«˜æŸ¥è¯¢æ€§èƒ½
CREATE INDEX idx_products_covering ON products(category_id, status, price, product_name, stock_quantity);
CREATE INDEX idx_orders_covering ON orders(user_id, status, order_date, total_amount);

-- 4. éƒ¨åˆ†ç´¢å¼• (æ¡ä»¶ç´¢å¼•) - é’ˆå¯¹ç‰¹å®šæ¡ä»¶ä¼˜åŒ–
CREATE INDEX idx_active_users_username ON users(username) WHERE status = 'active';
CREATE INDEX idx_active_products_category ON products(category_id, price) WHERE status = 'active';
CREATE INDEX idx_recent_orders ON orders(user_id, total_amount) WHERE order_date > date('now', '-1 year');
CREATE INDEX idx_expensive_products ON products(product_name, category_id) WHERE price > 1000;
CREATE INDEX idx_low_stock_products ON products(product_id, product_name, stock_quantity) WHERE stock_quantity <= min_stock_level;

-- 5. è¡¨è¾¾å¼ç´¢å¼• - å¯¹è®¡ç®—ç»“æœå»ºç«‹ç´¢å¼•
CREATE INDEX idx_users_email_lower ON users(lower(email));
CREATE INDEX idx_users_full_name ON users(first_name || ' ' || last_name) WHERE first_name IS NOT NULL AND last_name IS NOT NULL;
CREATE INDEX idx_products_profit_margin ON products((price - cost_price) / NULLIF(cost_price, 0)) WHERE cost_price > 0;

-- 6. JSONç´¢å¼• (SQLite 3.38+)
-- ä¸ºJSONå­—æ®µä¸­çš„ç‰¹å®šå±æ€§åˆ›å»ºç´¢å¼•
CREATE INDEX idx_user_preferences_theme ON users(json_extract(preferences, '$.theme'));
CREATE INDEX idx_user_metadata_source ON users(json_extract(metadata, '$.source'));
CREATE INDEX idx_product_specs_brand ON products(json_extract(specifications, '$.brand'));

-- äºŒã€ç´¢å¼•æ•ˆæœéªŒè¯å’Œç›‘æ§

-- æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’åˆ†æ
EXPLAIN QUERY PLAN 
SELECT p.product_name, p.price, c.category_name
FROM products p
JOIN categories c ON p.category_id = c.category_id
WHERE p.status = 'active' 
AND p.price BETWEEN 100 AND 1000
ORDER BY p.price DESC
LIMIT 10;

-- ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
SELECT 
    name as index_name,
    tbl as table_name,
    sql as index_definition
FROM sqlite_master 
WHERE type = 'index' 
AND tbl IN ('users', 'products', 'orders')
ORDER BY tbl, name;

-- ç´¢å¼•å¤§å°åˆ†æ
SELECT 
    name,
    pageno,
    pagetype,
    ncell,
    payload,
    unused
FROM dbstat 
WHERE name LIKE 'idx_%'
ORDER BY unused DESC;
```

### 4.4 é«˜æ•ˆæ•°æ®æ“ä½œ(CRUD)

#### æ•°æ®æ’å…¥æœ€ä½³å®è·µ

```sql
-- 1. åŸºæœ¬æ’å…¥æ“ä½œ
-- å•è¡Œæ’å…¥
INSERT INTO users (
    username, email, password_hash, salt,
    first_name, last_name, preferences
) VALUES (
    'alice_smith', 'alice@example.com', '$2b$12$hash...', 'random_salt',
    'Alice', 'Smith', json_object('theme', 'dark', 'language', 'en')
);

-- æ‰¹é‡æ’å…¥ - æ€§èƒ½ä¼˜åŒ–
INSERT INTO products (
    sku, product_name, category_id, price, cost_price, stock_quantity, specifications
) VALUES 
    ('SKU001', 'Gaming Laptop Pro', 1, 1299.99, 899.99, 50, json_object('brand', 'TechCorp', 'ram', '16GB')),
    ('SKU002', 'Office Mouse Wireless', 2, 29.99, 15.99, 200, json_object('brand', 'TechCorp', 'type', 'wireless')),
    ('SKU003', 'Mechanical Keyboard', 2, 89.99, 45.99, 75, json_object('brand', 'KeyMaster', 'switches', 'blue'));

-- 2. é«˜çº§æ’å…¥æ¨¡å¼

-- UPSERT æ“ä½œ - INSERT OR REPLACE
INSERT OR REPLACE INTO users (
    user_id, username, email, password_hash, salt, updated_at
) VALUES (
    1, 'alice_smith_updated', 'alice.smith@example.com', '$2b$12$newhash...', 'new_salt', datetime('now', 'localtime')
);

-- IGNORE é‡å¤æ’å…¥
INSERT OR IGNORE INTO categories (category_name, parent_id) VALUES 
    ('Electronics', NULL),
    ('Computers', 1),
    ('Accessories', 1);

-- ç°ä»£ UPSERT è¯­æ³• (SQLite 3.24+)
INSERT INTO users (username, email, password_hash, salt)
VALUES ('john_doe', 'john@example.com', '$2b$12$hash...', 'salt123')
ON CONFLICT(email) DO UPDATE SET 
    username = excluded.username,
    password_hash = excluded.password_hash,
    salt = excluded.salt,
    updated_at = datetime('now', 'localtime')
WHERE users.updated_at < excluded.updated_at;  -- åªåœ¨æ•°æ®æ›´æ–°æ—¶æ‰æ›´æ–°

-- 3. æ¡ä»¶æ’å…¥
INSERT INTO order_items (order_id, product_id, quantity, unit_price, product_name, product_sku)
SELECT 
    ? as order_id,
    p.product_id,
    ? as quantity,
    p.price as unit_price,
    p.product_name,
    p.sku
FROM products p
WHERE p.product_id = ? 
AND p.status = 'active' 
AND p.stock_quantity >= ?;

-- 4. æ‰¹é‡æ’å…¥ä¼˜åŒ– (Python ç¤ºä¾‹ä»£ç )
/*
Python ä¸­çš„é«˜æ•ˆæ‰¹é‡æ’å…¥:

# ä½¿ç”¨ executemany è¿›è¡Œæ‰¹é‡æ’å…¥
data = [
    ('user1', 'user1@example.com', 'hash1', 'salt1'),
    ('user2', 'user2@example.com', 'hash2', 'salt2'),
    # ... æ›´å¤šæ•°æ®
]

cursor.executemany(
    'INSERT INTO users (username, email, password_hash, salt) VALUES (?, ?, ?, ?)',
    data
)
*/

-- 5. JSON æ•°æ®æ’å…¥
INSERT INTO users (username, email, password_hash, salt, preferences, metadata)
VALUES (
    'power_user',
    'power@example.com', 
    '$2b$12$hash...', 
    'salt456',
    json_object(
        'theme', 'dark',
        'notifications', json_object(
            'email', true,
            'push', false,
            'frequency', 'daily'
        ),
        'dashboard', json_array('orders', 'analytics', 'inventory')
    ),
    json_object(
        'source', 'web_registration',
        'campaign', 'spring_2024',
        'referrer', 'google_ads'
    )
);
```

#### æ•°æ®æ›´æ–°é«˜çº§æŠ€å·§

```sql
-- 1. åŸºæœ¬æ›´æ–°æ“ä½œ
UPDATE users 
SET 
    email = 'alice.smith.new@example.com',
    phone = '+1-555-0123',
    updated_at = datetime('now', 'localtime')
WHERE user_id = 1;

-- 2. æ¡ä»¶æ›´æ–°å’Œæ•°å­¦è¿ç®—
-- äº§å“ä»·æ ¼è°ƒæ•´
UPDATE products 
SET 
    price = ROUND(price * 1.1, 2),  -- æ¶ˆè´¹ä»·ä¸Šæ¶¨10%
    cost_price = ROUND(cost_price * 1.05, 2),  -- æˆæœ¬ä¸Šæ¶¨5%
    updated_at = datetime('now', 'localtime')
WHERE category_id = 1 
AND status = 'active'
AND created_at < date('now', '-3 months');

-- 3. å­æŸ¥è¯¢æ›´æ–°
-- æ›´æ–°ç”¨æˆ·çš„æœ€åç™»å½•æ—¶é—´
UPDATE users 
SET last_login_at = datetime('now', 'localtime')
WHERE user_id IN (
    SELECT DISTINCT user_id 
    FROM orders 
    WHERE order_date >= date('now', '-7 days')
);

-- 4. JOIN æ›´æ–° (ä½¿ç”¨å­æŸ¥è¯¢å®ç°)
-- æ ¹æ®è®¢å•æƒ…å†µæ›´æ–°äº§å“åº“å­˜
UPDATE products 
SET stock_quantity = stock_quantity - (
    SELECT COALESCE(SUM(oi.quantity), 0)
    FROM order_items oi
    JOIN orders o ON oi.order_id = o.order_id
    WHERE oi.product_id = products.product_id
    AND o.status = 'confirmed'
    AND o.order_date >= date('now', '-1 day')
)
WHERE product_id IN (
    SELECT DISTINCT oi.product_id
    FROM order_items oi
    JOIN orders o ON oi.order_id = o.order_id
    WHERE o.status = 'confirmed'
    AND o.order_date >= date('now', '-1 day')
);

-- 5. JSON æ•°æ®æ›´æ–°
-- æ›´æ–°ç”¨æˆ·é¦–é€‰é¡¹
UPDATE users 
SET 
    preferences = json_set(
        preferences,
        '$.theme', 'light',
        '$.notifications.email', false,
        '$.dashboard', json_array('orders', 'profile')
    ),
    updated_at = datetime('now', 'localtime')
WHERE user_id = 1;

-- æ·»åŠ å…ƒæ•°æ®
UPDATE users
SET metadata = json_set(
    COALESCE(metadata, '{}'),
    '$.last_password_change', datetime('now', 'localtime'),
    '$.login_count', COALESCE(json_extract(metadata, '$.login_count'), 0) + 1
)
WHERE user_id = 1;

-- 6. æ‰¹é‡æ›´æ–°ä¼˜åŒ–
-- ä½¿ç”¨ CASE WHEN è¿›è¡Œæ¡ä»¶æ›´æ–°
UPDATE products
SET 
    status = CASE 
        WHEN stock_quantity = 0 THEN 'inactive'
        WHEN stock_quantity <= min_stock_level THEN 'low_stock'
        ELSE 'active'
    END,
    updated_at = datetime('now', 'localtime')
WHERE status != 'discontinued';

-- 7. å¸¦è¿”å›å€¼çš„æ›´æ–° (ä½¿ç”¨ RETURNING, SQLite 3.35+)
-- æ³¨æ„: SQLite ç›®å‰ä¸æ”¯æŒ RETURNING å­å¥ï¼Œå¯ä»¥ä½¿ç”¨äº‹åŠ¡å’ŒæŸ¥è¯¢ç»„åˆ

BEGIN TRANSACTION;

UPDATE products 
SET 
    stock_quantity = stock_quantity - 5,
    updated_at = datetime('now', 'localtime')
WHERE product_id = 1;

-- è¿”å›æ›´æ–°åçš„æ•°æ®
SELECT 
    product_id,
    product_name,
    stock_quantity,
    CASE 
        WHEN stock_quantity <= min_stock_level THEN 'LOW_STOCK'
        WHEN stock_quantity = 0 THEN 'OUT_OF_STOCK'
        ELSE 'IN_STOCK'
    END as stock_status
FROM products 
WHERE product_id = 1;

COMMIT;
```

### 4.5 å¤æ‚æŸ¥è¯¢å’Œåˆ†æ

#### é«˜æ•ˆè¿æ¥æŸ¥è¯¢

```sql
-- 1. å†…è¿æ¥ - è·å–å®Œæ•´è®¢å•ä¿¡æ¯
SELECT 
    o.order_number,
    o.order_date,
    u.username,
    u.email,
    o.subtotal,
    o.tax_amount,
    o.shipping_amount,
    o.total_amount,
    o.status as order_status,
    o.payment_status,
    -- è®¢å•é¡¹ç›®ç»Ÿè®¡
    COUNT(oi.order_item_id) as item_count,
    SUM(oi.quantity) as total_quantity
FROM orders o
INNER JOIN users u ON o.user_id = u.user_id
INNER JOIN order_items oi ON o.order_id = oi.order_id
WHERE o.order_date >= date('now', '-30 days')
AND o.status != 'cancelled'
GROUP BY o.order_id, o.order_number, o.order_date, u.username, u.email, 
         o.subtotal, o.tax_amount, o.shipping_amount, o.total_amount, 
         o.status, o.payment_status
ORDER BY o.order_date DESC;

-- 2. å·¦è¿æ¥ - ç”¨æˆ·è´­ä¹°ç»Ÿè®¡(åŒ…æ‹¬æ— è´­ä¹°çš„ç”¨æˆ·)
SELECT 
    u.user_id,
    u.username,
    u.email,
    u.created_at as registration_date,
    u.last_login_at,
    
    -- è®¢å•ç»Ÿè®¡
    COUNT(o.order_id) as total_orders,
    COALESCE(SUM(o.total_amount), 0) as total_spent,
    COALESCE(AVG(o.total_amount), 0) as avg_order_value,
    MAX(o.order_date) as last_order_date,
    
    -- ç”¨æˆ·åˆ†ç±»
    CASE 
        WHEN COUNT(o.order_id) = 0 THEN 'New Customer'
        WHEN COUNT(o.order_id) = 1 THEN 'One-time Buyer'
        WHEN COUNT(o.order_id) BETWEEN 2 AND 5 THEN 'Regular Customer'
        ELSE 'VIP Customer'
    END as customer_segment,
    
    -- æ´»è·ƒåº¦åˆ†æ
    julianday('now') - julianday(COALESCE(MAX(o.order_date), u.created_at)) as days_since_last_activity
    
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id AND o.status != 'cancelled'
WHERE u.status = 'active'
GROUP BY u.user_id, u.username, u.email, u.created_at, u.last_login_at
ORDER BY total_spent DESC, total_orders DESC;

-- 3. å¤æ‚å­æŸ¥è¯¢ - äº§å“é”€å”®åˆ†æ
SELECT 
    p.product_id,
    p.sku,
    p.product_name,
    p.price,
    p.cost_price,
    p.stock_quantity,
    c.category_name,
    
    -- é”€å”®ç»Ÿè®¡
    COALESCE(sales.total_sold, 0) as total_sold,
    COALESCE(sales.total_revenue, 0) as total_revenue,
    COALESCE(sales.total_profit, 0) as total_profit,
    COALESCE(ROUND(sales.profit_margin * 100, 2), 0) as profit_margin_percent,
    
    -- æ’ååˆ†æ
    (SELECT COUNT(*) + 1 
     FROM (
         SELECT p2.product_id
         FROM products p2
         LEFT JOIN (
             SELECT 
                 oi.product_id,
                 SUM(oi.quantity) as sold
             FROM order_items oi
             JOIN orders o ON oi.order_id = o.order_id
             WHERE o.status = 'delivered'
             AND o.order_date >= date('now', '-3 months')
             GROUP BY oi.product_id
         ) s ON p2.product_id = s.product_id
         WHERE p2.category_id = p.category_id
         AND COALESCE(s.sold, 0) > COALESCE(sales.total_sold, 0)
     )
    ) as sales_rank_in_category,
    
    -- å¹³å‡å¯¹æ¯”
    (SELECT AVG(p3.price) FROM products p3 WHERE p3.category_id = p.category_id) as category_avg_price,
    p.price - (SELECT AVG(p3.price) FROM products p3 WHERE p3.category_id = p.category_id) as price_vs_category_avg
    
FROM products p
INNER JOIN categories c ON p.category_id = c.category_id
LEFT JOIN (
    SELECT 
        oi.product_id,
        SUM(oi.quantity) as total_sold,
        SUM(oi.total_price) as total_revenue,
        SUM(oi.quantity * (oi.unit_price - p.cost_price)) as total_profit,
        AVG((oi.unit_price - p.cost_price) / NULLIF(oi.unit_price, 0)) as profit_margin
    FROM order_items oi
    JOIN orders o ON oi.order_id = o.order_id
    JOIN products p ON oi.product_id = p.product_id
    WHERE o.status = 'delivered'
    AND o.order_date >= date('now', '-3 months')
    GROUP BY oi.product_id
) sales ON p.product_id = sales.product_id
WHERE p.status = 'active'
ORDER BY COALESCE(sales.total_revenue, 0) DESC, p.product_name;
```

#### çª—å£å‡½æ•°æ·±åº¦åº”ç”¨

```sql
-- 4. çª—å£å‡½æ•°é«˜çº§åº”ç”¨ (SQLite 3.25+)
-- é”€å”®è¶‹åŠ¿åˆ†æ
WITH daily_sales AS (
    SELECT 
        date(order_date) as sale_date,
        SUM(total_amount) as daily_revenue,
        COUNT(*) as daily_orders,
        AVG(total_amount) as daily_avg_order_value
    FROM orders
    WHERE status = 'delivered'
    AND order_date >= date('now', '-90 days')
    GROUP BY date(order_date)
)
SELECT 
    sale_date,
    daily_revenue,
    daily_orders,
    daily_avg_order_value,
    
    -- ç§»åŠ¨å¹³å‡ (7å¤©)
    AVG(daily_revenue) OVER (
        ORDER BY sale_date 
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) as revenue_7day_ma,
    
    AVG(daily_orders) OVER (
        ORDER BY sale_date
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) as orders_7day_ma,
    
    -- åŒæ¯”å¢é•¿
    LAG(daily_revenue, 7) OVER (ORDER BY sale_date) as revenue_7days_ago,
    
    ROUND(
        (daily_revenue - LAG(daily_revenue, 7) OVER (ORDER BY sale_date)) * 100.0 / 
        NULLIF(LAG(daily_revenue, 7) OVER (ORDER BY sale_date), 0),
        2
    ) as revenue_wow_growth_percent,
    
    -- æ’ååˆ†æ
    RANK() OVER (ORDER BY daily_revenue DESC) as revenue_rank,
    PERCENT_RANK() OVER (ORDER BY daily_revenue) as revenue_percentile,
    
    -- ç´¯è®¡å€¼
    SUM(daily_revenue) OVER (ORDER BY sale_date) as cumulative_revenue,
    SUM(daily_orders) OVER (ORDER BY sale_date) as cumulative_orders
    
FROM daily_sales
ORDER BY sale_date;

-- 5. äº§å“ç±»åˆ«åˆ†æ - çª—å£å‡½æ•°
SELECT 
    c.category_name,
    p.product_name,
    p.price,
    COALESCE(sales.total_sold, 0) as units_sold,
    COALESCE(sales.revenue, 0) as revenue,
    
    -- åœ¨ç±»åˆ«å†…æ’å
    ROW_NUMBER() OVER (
        PARTITION BY c.category_id 
        ORDER BY COALESCE(sales.revenue, 0) DESC
    ) as revenue_rank_in_category,
    
    RANK() OVER (
        PARTITION BY c.category_id 
        ORDER BY COALESCE(sales.total_sold, 0) DESC
    ) as units_rank_in_category,
    
    -- ç±»åˆ«å†…ç™¾åˆ†æ¯”
    ROUND(
        PERCENT_RANK() OVER (
            PARTITION BY c.category_id 
            ORDER BY COALESCE(sales.revenue, 0)
        ) * 100, 2
    ) as revenue_percentile_in_category,
    
    -- ä¸ç±»åˆ«å¹³å‡æ¯”è¾ƒ
    COALESCE(sales.revenue, 0) - AVG(COALESCE(sales.revenue, 0)) OVER (
        PARTITION BY c.category_id
    ) as revenue_vs_category_avg,
    
    -- ç´¯è®¡è´¡çŒ®ç‡
    ROUND(
        SUM(COALESCE(sales.revenue, 0)) OVER (
            PARTITION BY c.category_id 
            ORDER BY COALESCE(sales.revenue, 0) DESC
            ROWS UNBOUNDED PRECEDING
        ) * 100.0 / SUM(COALESCE(sales.revenue, 0)) OVER (PARTITION BY c.category_id),
        2
    ) as cumulative_revenue_contribution_percent
    
FROM categories c
INNER JOIN products p ON c.category_id = p.category_id
LEFT JOIN (
    SELECT 
        oi.product_id,
        SUM(oi.quantity) as total_sold,
        SUM(oi.total_price) as revenue
    FROM order_items oi
    JOIN orders o ON oi.order_id = o.order_id
    WHERE o.status = 'delivered'
    AND o.order_date >= date('now', '-6 months')
    GROUP BY oi.product_id
) sales ON p.product_id = sales.product_id
WHERE p.status = 'active'
ORDER BY c.category_name, revenue_rank_in_category;
```

#### å…¬å…±è¡¨è¡¨è¾¾å¼ (CTE) é«˜çº§åº”ç”¨

```sql
-- 6. é€’å½’ CTE - åˆ†å±‚æ•°æ®å¤„ç†
-- ç±»åˆ«å±‚æ¬¡ç»“æ„åˆ†æ
WITH RECURSIVE category_hierarchy AS (
    -- é¡¶çº§ç±»åˆ«
    SELECT 
        category_id,
        category_name,
        parent_id,
        category_name as full_path,
        0 as level
    FROM categories
    WHERE parent_id IS NULL
    
    UNION ALL
    
    -- å­ç±»åˆ«
    SELECT 
        c.category_id,
        c.category_name,
        c.parent_id,
        ch.full_path || ' > ' || c.category_name as full_path,
        ch.level + 1 as level
    FROM categories c
    INNER JOIN category_hierarchy ch ON c.parent_id = ch.category_id
),
category_sales AS (
    SELECT 
        ch.category_id,
        ch.category_name,
        ch.full_path,
        ch.level,
        COUNT(p.product_id) as product_count,
        COALESCE(SUM(sales.revenue), 0) as total_revenue,
        COALESCE(SUM(sales.units_sold), 0) as total_units_sold
    FROM category_hierarchy ch
    LEFT JOIN products p ON ch.category_id = p.category_id AND p.status = 'active'
    LEFT JOIN (
        SELECT 
            oi.product_id,
            SUM(oi.total_price) as revenue,
            SUM(oi.quantity) as units_sold
        FROM order_items oi
        JOIN orders o ON oi.order_id = o.order_id
        WHERE o.status = 'delivered'
        AND o.order_date >= date('now', '-6 months')
        GROUP BY oi.product_id
    ) sales ON p.product_id = sales.product_id
    GROUP BY ch.category_id, ch.category_name, ch.full_path, ch.level
)
SELECT 
    PRINTF('%*s%s', level * 2, '', category_name) as category_display,
    full_path,
    level,
    product_count,
    PRINTF('$%,.2f', total_revenue) as total_revenue,
    total_units_sold,
    CASE 
        WHEN total_revenue > 0 THEN ROUND(total_revenue / NULLIF(total_units_sold, 0), 2)
        ELSE 0
    END as avg_unit_price
FROM category_sales
ORDER BY full_path;

-- 7. å¤æ‚åˆ†æ CTE - å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æ
WITH customer_orders AS (
    -- å®¢æˆ·è®¢å•åŸºç¡€æ•°æ®
    SELECT 
        u.user_id,
        u.username,
        u.created_at as registration_date,
        o.order_id,
        o.order_date,
        o.total_amount,
        ROW_NUMBER() OVER (
            PARTITION BY u.user_id 
            ORDER BY o.order_date
        ) as order_sequence
    FROM users u
    INNER JOIN orders o ON u.user_id = o.user_id
    WHERE o.status = 'delivered'
    AND u.status = 'active'
),
first_orders AS (
    -- é¦–æ¬¡è®¢å•åˆ†æ
    SELECT 
        user_id,
        username,
        registration_date,
        order_date as first_order_date,
        total_amount as first_order_value,
        julianday(order_date) - julianday(registration_date) as days_to_first_order
    FROM customer_orders
    WHERE order_sequence = 1
),
customer_metrics AS (
    -- å®¢æˆ·æŒ‡æ ‡è®¡ç®—
    SELECT 
        co.user_id,
        fo.username,
        fo.registration_date,
        fo.first_order_date,
        fo.first_order_value,
        fo.days_to_first_order,
        
        COUNT(co.order_id) as total_orders,
        SUM(co.total_amount) as total_spent,
        AVG(co.total_amount) as avg_order_value,
        MAX(co.order_date) as last_order_date,
        MIN(co.order_date) as first_purchase_date,
        
        -- è´­ä¹°é¢‘ç‡åˆ†æ
        CASE 
            WHEN COUNT(co.order_id) > 1 THEN
                (julianday(MAX(co.order_date)) - julianday(MIN(co.order_date))) / 
                NULLIF(COUNT(co.order_id) - 1, 0)
            ELSE NULL
        END as avg_days_between_orders,
        
        -- æ´»è·ƒåº¦
        julianday('now') - julianday(MAX(co.order_date)) as days_since_last_order,
        
        -- RFM åˆ†æ
        julianday('now') - julianday(MAX(co.order_date)) as recency,
        COUNT(co.order_id) as frequency,
        SUM(co.total_amount) as monetary
        
    FROM customer_orders co
    INNER JOIN first_orders fo ON co.user_id = fo.user_id
    GROUP BY co.user_id, fo.username, fo.registration_date, 
             fo.first_order_date, fo.first_order_value, fo.days_to_first_order
),
rfm_scores AS (
    -- RFM è¯„åˆ†
    SELECT 
        *,
        NTILE(5) OVER (ORDER BY recency DESC) as recency_score,
        NTILE(5) OVER (ORDER BY frequency) as frequency_score,
        NTILE(5) OVER (ORDER BY monetary) as monetary_score
    FROM customer_metrics
)
SELECT 
    username,
    ROUND(total_spent, 2) as lifetime_value,
    total_orders,
    ROUND(avg_order_value, 2) as avg_order_value,
    ROUND(days_to_first_order, 1) as days_to_first_order,
    ROUND(avg_days_between_orders, 1) as avg_days_between_orders,
    ROUND(days_since_last_order, 1) as days_since_last_order,
    
    -- RFM ç»„åˆè¯„åˆ†
    CAST(recency_score AS TEXT) || CAST(frequency_score AS TEXT) || CAST(monetary_score AS TEXT) as rfm_score,
    
    -- å®¢æˆ·ç±»å‹åˆ†ç±»
    CASE 
        WHEN recency_score >= 4 AND frequency_score >= 4 AND monetary_score >= 4 THEN 'VIP Champions'
        WHEN recency_score >= 3 AND frequency_score >= 3 AND monetary_score >= 3 THEN 'Loyal Customers'
        WHEN recency_score >= 4 AND frequency_score <= 2 THEN 'New Customers'
        WHEN recency_score <= 2 AND frequency_score >= 3 THEN 'At Risk'
        WHEN recency_score <= 2 AND frequency_score <= 2 AND monetary_score >= 3 THEN 'Lost VIPs'
        WHEN recency_score <= 2 AND frequency_score <= 2 THEN 'Lost Customers'
        ELSE 'Regular Customers'
    END as customer_segment,
    
    registration_date,
    first_order_date,
    last_order_date
    
FROM rfm_scores
ORDER BY lifetime_value DESC, total_orders DESC;
```

## 5. é«˜çº§ç‰¹æ€§ä¸åº”ç”¨

### 5.1 å­¦ä¹ ç›®æ ‡
- æŒæ¡è§¦å‘å™¨ã€è§†å›¾ã€å­˜å‚¨è¿‡ç¨‹çš„è®¾è®¡å’Œå®ç°
- å­¦ä¼šäº‹åŠ¡å¤„ç†å’Œå¹¶å‘æ§åˆ¶
- äº†è§£JSONæ”¯æŒå’Œå…¨æ–‡æœç´¢(FTS)
- æŒæ¡æ•°æ®åº“å®‰å…¨å’Œæƒé™ç®¡ç†

### 5.2 æ™ºèƒ½è§¦å‘å™¨ç³»ç»Ÿ

```sql
-- 1. å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
-- åˆ›å»ºç»Ÿä¸€çš„å®¡è®¡æ—¥å¿—è¡¨
CREATE TABLE audit_log (
    audit_id INTEGER PRIMARY KEY AUTOINCREMENT,
    table_name TEXT NOT NULL,
    record_id INTEGER NOT NULL,
    action TEXT NOT NULL CHECK (action IN ('INSERT', 'UPDATE', 'DELETE')),
    
    -- å˜æ›´è®°å½•
    old_values JSON,
    new_values JSON,
    changed_fields JSON,  -- åªè®°å½•å˜æ›´çš„å­—æ®µ
    
    -- æ“ä½œä¿¡æ¯
    operation_timestamp DATETIME DEFAULT (datetime('now', 'localtime')),
    user_id INTEGER,  -- æ“ä½œç”¨æˆ·ID
    session_id TEXT,  -- ä¼šè¯æ ‡è¯†
    ip_address TEXT,  -- IPåœ°å€
    user_agent TEXT,  -- ç”¨æˆ·ä»£ç†
    
    -- ç´¢å¼•ä¼˜åŒ–
    INDEX(table_name, record_id),
    INDEX(operation_timestamp),
    INDEX(user_id, operation_timestamp)
);

-- ç”¨æˆ·è¡¨è§¦å‘å™¨ - æ›´æ–°æ“ä½œ
CREATE TRIGGER users_audit_update
AFTER UPDATE ON users
FOR EACH ROW WHEN (
    NEW.username != OLD.username OR
    NEW.email != OLD.email OR 
    NEW.status != OLD.status OR
    NEW.phone != OLD.phone OR
    NEW.first_name != OLD.first_name OR
    NEW.last_name != OLD.last_name
)
BEGIN
    INSERT INTO audit_log (
        table_name, record_id, action, old_values, new_values, changed_fields,
        user_id
    ) VALUES (
        'users',
        NEW.user_id,
        'UPDATE',
        json_object(
            'username', OLD.username,
            'email', OLD.email,
            'status', OLD.status,
            'phone', OLD.phone,
            'first_name', OLD.first_name,
            'last_name', OLD.last_name
        ),
        json_object(
            'username', NEW.username,
            'email', NEW.email,
            'status', NEW.status,
            'phone', NEW.phone,
            'first_name', NEW.first_name,
            'last_name', NEW.last_name
        ),
        json_array(
            CASE WHEN NEW.username != OLD.username THEN 'username' END,
            CASE WHEN NEW.email != OLD.email THEN 'email' END,
            CASE WHEN NEW.status != OLD.status THEN 'status' END,
            CASE WHEN NEW.phone != OLD.phone THEN 'phone' END,
            CASE WHEN NEW.first_name != OLD.first_name THEN 'first_name' END,
            CASE WHEN NEW.last_name != OLD.last_name THEN 'last_name' END
        ),
        NEW.user_id  -- å‡è®¾æ“ä½œç”¨æˆ·æ˜¯ç”¨æˆ·æœ¬äºº
    );
END;

-- ç”¨æˆ·è¡¨è§¦å‘å™¨ - æ’å…¥æ“ä½œ
CREATE TRIGGER users_audit_insert
AFTER INSERT ON users
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        table_name, record_id, action, new_values
    ) VALUES (
        'users',
        NEW.user_id,
        'INSERT',
        json_object(
            'username', NEW.username,
            'email', NEW.email,
            'status', NEW.status,
            'created_at', NEW.created_at
        )
    );
END;

-- ç”¨æˆ·è¡¨è§¦å‘å™¨ - åˆ é™¤æ“ä½œ(è½¯åˆ é™¤)
CREATE TRIGGER users_soft_delete
INSTEAD OF DELETE ON users
FOR EACH ROW WHEN OLD.status != 'deleted'
BEGIN
    -- è½¯åˆ é™¤ï¼šä¿®æ”¹çŠ¶æ€è€Œä¸æ˜¯ç‰©ç†åˆ é™¤
    UPDATE users 
    SET status = 'deleted',
        updated_at = datetime('now', 'localtime')
    WHERE user_id = OLD.user_id;
    
    -- è®°å½•åˆ é™¤æ“ä½œ
    INSERT INTO audit_log (
        table_name, record_id, action, old_values
    ) VALUES (
        'users',
        OLD.user_id,
        'DELETE',
        json_object(
            'username', OLD.username,
            'email', OLD.email,
            'status', OLD.status
        )
    );
END;

-- 2. æ™ºèƒ½æ—¶é—´æˆ³ç®¡ç†
-- è‡ªåŠ¨æ›´æ–°updated_atå­—æ®µ
CREATE TRIGGER users_update_timestamp
BEFORE UPDATE ON users
FOR EACH ROW
WHEN NEW.updated_at = OLD.updated_at OR NEW.updated_at IS NULL
BEGIN
    UPDATE users 
    SET updated_at = datetime('now', 'localtime')
    WHERE user_id = NEW.user_id;
END;

CREATE TRIGGER products_update_timestamp  
BEFORE UPDATE ON products
FOR EACH ROW
WHEN NEW.updated_at = OLD.updated_at OR NEW.updated_at IS NULL
BEGIN
    UPDATE products
    SET updated_at = datetime('now', 'localtime')
    WHERE product_id = NEW.product_id;
END;

-- 3. ä¸šåŠ¡é€»è¾‘è§¦å‘å™¨
-- åº“å­˜ç®¡ç†è§¦å‘å™¨
CREATE TRIGGER product_stock_check
BEFORE UPDATE ON products
FOR EACH ROW
WHEN NEW.stock_quantity != OLD.stock_quantity
BEGIN
    -- æ£€æŸ¥åº“å­˜ä¸èƒ½ä¸ºè´Ÿæ•°
    SELECT CASE
        WHEN NEW.stock_quantity < 0 THEN
            RAISE(ABORT, 'åº“å­˜æ•°é‡ä¸èƒ½ä¸ºè´Ÿæ•°')
    END;
    
    -- ä½åº“å­˜é¢„è­¦
    INSERT INTO system_alerts (alert_type, message, severity, created_at)
    SELECT 
        'LOW_STOCK',
        'Product ' || NEW.product_name || ' (SKU: ' || NEW.sku || ') stock is below minimum level',
        CASE 
            WHEN NEW.stock_quantity = 0 THEN 'CRITICAL'
            WHEN NEW.stock_quantity <= NEW.min_stock_level THEN 'WARNING'
            ELSE 'INFO'
        END,
        datetime('now', 'localtime')
    WHERE NEW.stock_quantity <= COALESCE(NEW.min_stock_level, 0)
    AND OLD.stock_quantity > COALESCE(NEW.min_stock_level, 0);
END;

-- è®¢å•çŠ¶æ€å¤‰æ›´è§¦å‘å™¨
CREATE TRIGGER order_status_change
AFTER UPDATE ON orders
FOR EACH ROW
WHEN NEW.status != OLD.status
BEGIN
    -- è®°å½•çŠ¶æ€å˜æ›´æ—¶é—´
    UPDATE orders 
    SET 
        shipped_at = CASE WHEN NEW.status = 'shipped' THEN datetime('now', 'localtime') ELSE shipped_at END,
        delivered_at = CASE WHEN NEW.status = 'delivered' THEN datetime('now', 'localtime') ELSE delivered_at END,
        cancelled_at = CASE WHEN NEW.status = 'cancelled' THEN datetime('now', 'localtime') ELSE cancelled_at END
    WHERE order_id = NEW.order_id;
    
    -- å½“è®¢å•å–æ¶ˆæ—¶ï¼Œæ¢å¤åº“å­˜
    UPDATE products 
    SET stock_quantity = stock_quantity + oi.quantity
    FROM order_items oi 
    WHERE products.product_id = oi.product_id 
    AND oi.order_id = NEW.order_id
    AND NEW.status = 'cancelled'
    AND OLD.status IN ('confirmed', 'processing');
END;

-- 4. æ•°æ®éªŒè¯è§¦å‘å™¨
CREATE TRIGGER order_items_validation
BEFORE INSERT ON order_items
FOR EACH ROW
BEGIN
    -- æ£€æŸ¥äº§å“æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    SELECT CASE
        WHEN NOT EXISTS (
            SELECT 1 FROM products 
            WHERE product_id = NEW.product_id 
            AND status = 'active'
        ) THEN
            RAISE(ABORT, 'äº§å“ä¸å­˜åœ¨æˆ–å·²åœç”¨')
    END;
    
    -- æ£€æŸ¥åº“å­˜æ˜¯å¦è¶³å¤Ÿ
    SELECT CASE
        WHEN (
            SELECT stock_quantity FROM products 
            WHERE product_id = NEW.product_id
        ) < NEW.quantity THEN
            RAISE(ABORT, 'åº“å­˜ä¸è¶³')
    END;
    
    -- è‡ªåŠ¨è®¾ç½®å•ä»·(å¦‚æœæœªæä¾›)
    UPDATE order_items 
    SET unit_price = COALESCE(NEW.unit_price, (
        SELECT price FROM products WHERE product_id = NEW.product_id
    ))
    WHERE rowid = NEW.rowid;
END;
```

### 5.3 é«˜çº§è§†å›¾è®¾è®¡

```sql
-- 1. ä¸šåŠ¡æ™ºèƒ½è§†å›¾è®¾è®¡

-- ç”¨æˆ·360åº¦è§†å›¾
CREATE VIEW user_360_view AS
SELECT 
    u.user_id,
    u.username,
    u.email,
    u.first_name || ' ' || u.last_name as full_name,
    u.phone,
    u.status,
    u.created_at as registration_date,
    u.last_login_at,
    
    -- è®¢å•ç»Ÿè®¡
    COUNT(DISTINCT o.order_id) as total_orders,
    COALESCE(SUM(o.total_amount), 0) as lifetime_value,
    COALESCE(AVG(o.total_amount), 0) as avg_order_value,
    MIN(o.order_date) as first_order_date,
    MAX(o.order_date) as last_order_date,
    
    -- è´­ä¹°è¡Œä¸ºåˆ†æ
    COUNT(DISTINCT oi.product_id) as unique_products_purchased,
    SUM(oi.quantity) as total_items_purchased,
    
    -- æ—¶é—´åˆ†æ  
    julianday('now') - julianday(COALESCE(MAX(o.order_date), u.created_at)) as days_since_last_activity,
    julianday('now') - julianday(u.created_at) as customer_age_days,
    
    -- å®¢æˆ·åˆ†ç±»
    CASE 
        WHEN COUNT(o.order_id) = 0 THEN 'Prospect'
        WHEN COUNT(o.order_id) = 1 THEN 'New Customer'
        WHEN COUNT(o.order_id) BETWEEN 2 AND 5 THEN 'Regular Customer' 
        WHEN COUNT(o.order_id) > 5 AND COALESCE(SUM(o.total_amount), 0) > 1000 THEN 'VIP Customer'
        ELSE 'Loyal Customer'
    END as customer_segment,
    
    -- æ´»è·ƒçŠ¶æ€
    CASE
        WHEN MAX(o.order_date) >= date('now', '-30 days') THEN 'Active'
        WHEN MAX(o.order_date) >= date('now', '-90 days') THEN 'At Risk'
        WHEN MAX(o.order_date) >= date('now', '-180 days') THEN 'Dormant'
        WHEN MAX(o.order_date) IS NULL THEN 'Never Purchased'
        ELSE 'Lost'
    END as activity_status,
    
    -- é¦–é€‰é¡¹å’Œå…ƒæ•°æ®
    json_extract(u.preferences, '$.theme') as preferred_theme,
    json_extract(u.metadata, '$.source') as acquisition_source
    
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id AND o.status != 'cancelled'
LEFT JOIN order_items oi ON o.order_id = oi.order_id
WHERE u.status != 'deleted'
GROUP BY u.user_id, u.username, u.email, u.first_name, u.last_name, 
         u.phone, u.status, u.created_at, u.last_login_at, 
         u.preferences, u.metadata;

-- äº§å“ç»è¥åˆ†æè§†å›¾
CREATE VIEW product_performance_view AS
SELECT 
    p.product_id,
    p.sku,
    p.product_name,
    c.category_name,
    p.price,
    p.cost_price,
    p.stock_quantity,
    p.min_stock_level,
    p.status,
    
    -- é”€å”®æ•°æ® (30å¤©)
    COALESCE(recent.units_sold_30d, 0) as units_sold_30d,
    COALESCE(recent.revenue_30d, 0) as revenue_30d,
    COALESCE(recent.profit_30d, 0) as profit_30d,
    
    -- é”€å”®æ•°æ® (å…¨éƒ¨)
    COALESCE(total.total_units_sold, 0) as total_units_sold,
    COALESCE(total.total_revenue, 0) as total_revenue,
    COALESCE(total.total_profit, 0) as total_profit,
    
    -- æ”¶ç›Šç‡åˆ†æ
    CASE 
        WHEN p.cost_price > 0 THEN ROUND((p.price - p.cost_price) * 100.0 / p.cost_price, 2)
        ELSE 0
    END as markup_percentage,
    
    CASE 
        WHEN p.price > 0 THEN ROUND((p.price - p.cost_price) * 100.0 / p.price, 2)
        ELSE 0
    END as profit_margin_percentage,
    
    -- åº“å­˜åˆ†æ
    CASE 
        WHEN p.stock_quantity = 0 THEN 'Out of Stock'
        WHEN p.stock_quantity <= p.min_stock_level THEN 'Low Stock'
        WHEN p.stock_quantity > p.min_stock_level * 3 THEN 'Overstock'
        ELSE 'Normal'
    END as stock_status,
    
    -- é”€å”®æ’å (æŒ‰ç±»åˆ«)
    ROW_NUMBER() OVER (
        PARTITION BY p.category_id 
        ORDER BY COALESCE(recent.revenue_30d, 0) DESC
    ) as category_sales_rank,
    
    -- äº§å“ç”Ÿå‘½å‘¨æœŸåˆ†æ
    julianday('now') - julianday(p.created_at) as product_age_days,
    
    CASE
        WHEN julianday('now') - julianday(p.created_at) < 30 THEN 'New Product'
        WHEN COALESCE(recent.units_sold_30d, 0) = 0 AND julianday('now') - julianday(p.created_at) > 90 THEN 'Declining'
        WHEN COALESCE(recent.units_sold_30d, 0) > 0 THEN 'Active'
        ELSE 'Stable'
    END as product_lifecycle_stage
    
FROM products p
INNER JOIN categories c ON p.category_id = c.category_id
LEFT JOIN (
    -- 30å¤©é”€å”®æ•°æ®
    SELECT 
        oi.product_id,
        SUM(oi.quantity) as units_sold_30d,
        SUM(oi.total_price) as revenue_30d,
        SUM(oi.quantity * (oi.unit_price - p.cost_price)) as profit_30d
    FROM order_items oi
    JOIN orders o ON oi.order_id = o.order_id
    JOIN products p ON oi.product_id = p.product_id
    WHERE o.status = 'delivered'
    AND o.order_date >= date('now', '-30 days')
    GROUP BY oi.product_id
) recent ON p.product_id = recent.product_id
LEFT JOIN (
    -- æ€»é”€å”®æ•°æ®
    SELECT 
        oi.product_id,
        SUM(oi.quantity) as total_units_sold,
        SUM(oi.total_price) as total_revenue,
        SUM(oi.quantity * (oi.unit_price - p.cost_price)) as total_profit
    FROM order_items oi
    JOIN orders o ON oi.order_id = o.order_id  
    JOIN products p ON oi.product_id = p.product_id
    WHERE o.status = 'delivered'
    GROUP BY oi.product_id
) total ON p.product_id = total.product_id
WHERE p.status != 'discontinued';

-- è´¢åŠ¡æŠ¥è¡¨è§†å›¾
CREATE VIEW financial_summary_view AS
WITH monthly_data AS (
    SELECT 
        strftime('%Y-%m', o.order_date) as month,
        strftime('%Y', o.order_date) as year,
        SUM(o.subtotal) as gross_revenue,
        SUM(o.tax_amount) as total_tax,
        SUM(o.shipping_amount) as total_shipping,
        SUM(o.discount_amount) as total_discounts,
        SUM(o.total_amount) as net_revenue,
        COUNT(DISTINCT o.order_id) as order_count,
        COUNT(DISTINCT o.user_id) as unique_customers,
        
        -- æˆæœ¬è®¡ç®— (åŸºäºè®¢å•é¡¹ç›®)
        SUM(oi.quantity * p.cost_price) as total_cogs,
        
        -- æ¯›åˆ©æ¶¦
        SUM(o.subtotal) - SUM(oi.quantity * p.cost_price) as gross_profit
        
    FROM orders o
    INNER JOIN order_items oi ON o.order_id = oi.order_id
    INNER JOIN products p ON oi.product_id = p.product_id
    WHERE o.status = 'delivered'
    GROUP BY strftime('%Y-%m', o.order_date)
)
SELECT 
    month,
    year,
    PRINTF('$%,.2f', gross_revenue) as gross_revenue_formatted,
    PRINTF('$%,.2f', net_revenue) as net_revenue_formatted,
    PRINTF('$%,.2f', total_cogs) as cogs_formatted,
    PRINTF('$%,.2f', gross_profit) as gross_profit_formatted,
    
    -- å…³é”®æŒ‡æ ‡
    gross_revenue,
    net_revenue,
    total_cogs,
    gross_profit,
    order_count,
    unique_customers,
    
    -- è®¡ç®—çš„æŒ‡æ ‡
    ROUND(net_revenue / NULLIF(order_count, 0), 2) as avg_order_value,
    ROUND(gross_profit * 100.0 / NULLIF(gross_revenue, 0), 2) as gross_margin_percentage,
    ROUND(net_revenue / NULLIF(unique_customers, 0), 2) as revenue_per_customer,
    
    -- åŒæ¯”åˆ†æ (éœ€è¦è‡³å°‘æœ‰ä¸Šå¹´åŒæœŸæ•°æ®)
    LAG(net_revenue, 12) OVER (ORDER BY month) as same_month_last_year_revenue,
    
    ROUND(
        (net_revenue - LAG(net_revenue, 12) OVER (ORDER BY month)) * 100.0 /
        NULLIF(LAG(net_revenue, 12) OVER (ORDER BY month), 0), 
        2
    ) as yoy_revenue_growth_percentage,
    
    -- æœˆç¯æ¯”åˆ†æ
    LAG(net_revenue, 1) OVER (ORDER BY month) as prev_month_revenue,
    
    ROUND(
        (net_revenue - LAG(net_revenue, 1) OVER (ORDER BY month)) * 100.0 /
        NULLIF(LAG(net_revenue, 1) OVER (ORDER BY month), 0),
        2  
    ) as mom_revenue_growth_percentage
    
FROM monthly_data
ORDER BY month;

-- 2. å®‰å…¨è§†å›¾å’Œæ•°æ®è„±æ•
-- ç”¨æˆ·ä¿¡æ¯è„±æ•è§†å›¾(ç”¨äºæŠ¥è¡¨å’Œåˆ†æ)
CREATE VIEW user_profile_safe AS
SELECT 
    user_id,
    
    -- è„±æ•å¤„ç†
    CASE 
        WHEN LENGTH(username) > 3 THEN 
            SUBSTR(username, 1, 2) || '***' || SUBSTR(username, -1)
        ELSE '***'
    END as username_masked,
    
    CASE 
        WHEN email LIKE '%@%' THEN 
            SUBSTR(email, 1, 2) || '***@' || SUBSTR(email, INSTR(email, '@') + 1)
        ELSE '***@***.***'
    END as email_masked,
    
    CASE
        WHEN phone IS NOT NULL AND LENGTH(phone) >= 4 THEN
            '***-***-' || SUBSTR(phone, -4)
        ELSE '***-***-****'
    END as phone_masked,
    
    -- ä¿ç•™åˆ†ææ‰€éœ€çš„å­—æ®µ
    first_name,  -- æ ¹æ®éœ€è¦å¯ä»¥è¿›ä¸€æ­¥è„±æ•
    status,
    created_at,
    last_login_at,
    
    -- åœ°ç†åŒºåŸŸ(è€Œéå…·ä½“åœ°å€) 
    json_extract(metadata, '$.region') as region,
    json_extract(metadata, '$.country') as country,
    
    -- åå¥½è®¾ç½®
    preferences
    
FROM users 
WHERE status != 'deleted';

-- ç®¡ç†å‘˜æƒé™è§†å›¾(å®Œæ•´ä¿¡æ¯)
CREATE VIEW user_profile_admin AS
SELECT 
    user_id,
    username,
    email,
    phone,
    first_name,
    last_name,
    status,
    email_verified,
    phone_verified,
    created_at,
    updated_at,
    last_login_at,
    preferences,
    metadata
FROM users;

-- 3. åŠ¨æ€æŠ¥è¡¨è§†å›¾
-- å¯é…ç½®çš„æ—¶é—´èŒƒå›´é”€å”®è§†å›¾
CREATE VIEW sales_report_flexible AS
SELECT 
    'daily' as period_type,
    date(o.order_date) as period,
    SUM(o.total_amount) as revenue,
    COUNT(DISTINCT o.order_id) as orders,
    COUNT(DISTINCT o.user_id) as customers,
    AVG(o.total_amount) as avg_order_value
FROM orders o
WHERE o.status = 'delivered'
GROUP BY date(o.order_date)

UNION ALL

SELECT 
    'weekly' as period_type,
    strftime('%Y-W%W', o.order_date) as period,
    SUM(o.total_amount) as revenue,
    COUNT(DISTINCT o.order_id) as orders,
    COUNT(DISTINCT o.user_id) as customers,
    AVG(o.total_amount) as avg_order_value
FROM orders o  
WHERE o.status = 'delivered'
GROUP BY strftime('%Y-W%W', o.order_date)

UNION ALL

SELECT 
    'monthly' as period_type,
    strftime('%Y-%m', o.order_date) as period,
    SUM(o.total_amount) as revenue,
    COUNT(DISTINCT o.order_id) as orders,
    COUNT(DISTINCT o.user_id) as customers,
    AVG(o.total_amount) as avg_order_value
FROM orders o
WHERE o.status = 'delivered'  
GROUP BY strftime('%Y-%m', o.order_date);

-- å®æ—¶åº“å­˜ç›‘æ§è§†å›¾
CREATE VIEW inventory_alerts AS
SELECT 
    p.product_id,
    p.sku,
    p.product_name,
    c.category_name,
    p.stock_quantity,
    p.min_stock_level,
    p.max_stock_level,
    
    -- åº“å­˜çŠ¶æ€
    CASE 
        WHEN p.stock_quantity = 0 THEN 'CRITICAL'
        WHEN p.stock_quantity <= p.min_stock_level THEN 'WARNING' 
        WHEN p.max_stock_level IS NOT NULL AND p.stock_quantity >= p.max_stock_level THEN 'OVERSTOCK'
        ELSE 'NORMAL'
    END as alert_level,
    
    -- é¢„è®¡å”®ç½„å¤©æ•°(åŸºäº30å¤©å¹³å‡é”€é‡)
    CASE 
        WHEN COALESCE(sales.avg_daily_sales, 0) > 0 THEN
            CAST(p.stock_quantity / sales.avg_daily_sales AS INTEGER)
        ELSE 999
    END as days_until_stockout,
    
    -- å»ºè®®è¡¥è´§æ•°é‡
    CASE
        WHEN p.stock_quantity <= p.min_stock_level THEN
            COALESCE(p.max_stock_level, p.min_stock_level * 3) - p.stock_quantity
        ELSE 0
    END as suggested_reorder_quantity,
    
    p.updated_at as last_updated
    
FROM products p
INNER JOIN categories c ON p.category_id = c.category_id
LEFT JOIN (
    SELECT 
        oi.product_id,
        AVG(daily_sales.daily_quantity) as avg_daily_sales
    FROM (
        SELECT 
            oi.product_id,
            date(o.order_date) as sale_date,
            SUM(oi.quantity) as daily_quantity
        FROM order_items oi
        JOIN orders o ON oi.order_id = o.order_id
        WHERE o.status = 'delivered'
        AND o.order_date >= date('now', '-30 days')
        GROUP BY oi.product_id, date(o.order_date)
    ) daily_sales
    JOIN order_items oi ON daily_sales.product_id = oi.product_id
    GROUP BY oi.product_id
) sales ON p.product_id = sales.product_id
WHERE p.status = 'active'
AND (
    p.stock_quantity = 0 OR
    p.stock_quantity <= p.min_stock_level OR
    (p.max_stock_level IS NOT NULL AND p.stock_quantity >= p.max_stock_level)
)
ORDER BY 
    CASE alert_level
        WHEN 'CRITICAL' THEN 1
        WHEN 'WARNING' THEN 2  
        WHEN 'OVERSTOCK' THEN 3
        ELSE 4
    END,
    days_until_stockout;
``` 

### 5.4 ä¼ä¸šçº§äº‹åŠ¡å¤„ç†å’Œå¹¶å‘æ§åˆ¶

```sql
-- 1. å®Œæ•´çš„äº‹åŠ¡å¤„ç†æ¨¡å¼
-- åˆ›å»ºç¤ºä¾‹è´¦æˆ·è¡¨ç”¨äºæ¼”ç¤º
CREATE TABLE IF NOT EXISTS accounts (
    account_id INTEGER PRIMARY KEY,
    account_number TEXT UNIQUE NOT NULL,
    user_id INTEGER NOT NULL,
    balance DECIMAL(15,2) DEFAULT 0.00 CHECK (balance >= 0),
    account_type TEXT DEFAULT 'checking' CHECK (account_type IN ('checking', 'savings', 'credit')),
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    updated_at DATETIME DEFAULT (datetime('now', 'localtime')),
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- åˆ›å»ºäº¤æ˜“è®°å½•è¡¨
CREATE TABLE IF NOT EXISTS transactions (
    transaction_id INTEGER PRIMARY KEY AUTOINCREMENT,
    from_account_id INTEGER,
    to_account_id INTEGER,
    amount DECIMAL(15,2) NOT NULL CHECK (amount > 0),
    transaction_type TEXT NOT NULL CHECK (transaction_type IN ('transfer', 'deposit', 'withdrawal', 'payment')),
    reference_number TEXT UNIQUE,
    description TEXT,
    status TEXT DEFAULT 'pending' CHECK (status IN ('pending', 'completed', 'failed', 'reversed')),
    created_at DATETIME DEFAULT (datetime('now', 'localtime')),
    processed_at DATETIME,
    
    FOREIGN KEY (from_account_id) REFERENCES accounts(account_id),
    FOREIGN KEY (to_account_id) REFERENCES accounts(account_id),
    
    -- ç¡®ä¿è½¬è´¦æ“ä½œè‡³å°‘æœ‰ä¸€ä¸ªè´¦æˆ·
    CHECK (from_account_id IS NOT NULL OR to_account_id IS NOT NULL)
);

-- 2. å®‰å…¨çš„èµ„é‡‘è½¬è´¦äº‹åŠ¡
-- é«˜çº§è½¬è´¦å­˜å‚¨è¿‡ç¨‹æ¨¡æ‹Ÿ
BEGIN IMMEDIATE TRANSACTION;

-- è®¾ç½®å˜é‡ (SQLite ä¸æ”¯æŒå˜é‡ï¼Œä½¿ç”¨ä¸´æ—¶è¡¨æ¨¡æ‹Ÿ)
CREATE TEMP TABLE transfer_params (
    from_account INTEGER,
    to_account INTEGER,  
    transfer_amount DECIMAL(15,2),
    reference TEXT
);

INSERT INTO transfer_params VALUES (1, 2, 100.00, 'TXN-' || datetime('now'));

-- éªŒè¯æºè´¦æˆ·ä½™é¢
SELECT CASE
    WHEN (SELECT balance FROM accounts WHERE account_id = (SELECT from_account FROM transfer_params)) < 
         (SELECT transfer_amount FROM transfer_params) THEN
        RAISE(ABORT, 'ä½™é¢ä¸è¶³ï¼Œæ— æ³•å®Œæˆè½¬è´¦')
    WHEN NOT EXISTS (SELECT 1 FROM accounts WHERE account_id = (SELECT from_account FROM transfer_params) AND status = 'active') THEN
        RAISE(ABORT, 'æºè´¦æˆ·ä¸å­˜åœ¨æˆ–å·²åœç”¨')
    WHEN NOT EXISTS (SELECT 1 FROM accounts WHERE account_id = (SELECT to_account FROM transfer_params) AND status = 'active') THEN
        RAISE(ABORT, 'ç›®æ ‡è´¦æˆ·ä¸å­˜åœ¨æˆ–å·²åœç”¨')
END;

-- åˆ›å»ºäº¤æ˜“è®°å½•
INSERT INTO transactions (
    from_account_id, to_account_id, amount, transaction_type, 
    reference_number, description, status
)
SELECT 
    from_account, 
    to_account, 
    transfer_amount, 
    'transfer',
    reference,
    'Account to account transfer',
    'pending'
FROM transfer_params;

-- æ‰§è¡Œè½¬è´¦æ“ä½œ
UPDATE accounts 
SET balance = balance - (SELECT transfer_amount FROM transfer_params),
    updated_at = datetime('now', 'localtime')
WHERE account_id = (SELECT from_account FROM transfer_params);

UPDATE accounts 
SET balance = balance + (SELECT transfer_amount FROM transfer_params),
    updated_at = datetime('now', 'localtime')
WHERE account_id = (SELECT to_account FROM transfer_params);

-- æ›´æ–°äº¤æ˜“çŠ¶æ€
UPDATE transactions 
SET status = 'completed',
    processed_at = datetime('now', 'localtime')
WHERE reference_number = (SELECT reference FROM transfer_params);

-- æ¸…ç†ä¸´æ—¶è¡¨
DROP TABLE transfer_params;

COMMIT TRANSACTION;

-- 3. å¤æ‚ä¸šåŠ¡äº‹åŠ¡ - è®¢å•å¤„ç†
-- å®Œæ•´çš„è®¢å•åˆ›å»ºå’Œåº“å­˜æ‰£å‡äº‹åŠ¡
BEGIN IMMEDIATE TRANSACTION;

-- åˆ›å»ºä¸´æ—¶è¡¨å­˜å‚¨è®¢å•ä¿¡æ¯
CREATE TEMP TABLE order_processing (
    user_id INTEGER,
    product_id INTEGER,
    quantity INTEGER,
    unit_price DECIMAL(12,4)
);

-- æ’å…¥è®¢å•é¡¹ç›®
INSERT INTO order_processing VALUES 
(1, 101, 2, 29.99),
(1, 102, 1, 49.99);

-- éªŒè¯åº“å­˜å……è¶³
SELECT CASE
    WHEN EXISTS (
        SELECT 1 FROM order_processing op
        JOIN products p ON op.product_id = p.product_id
        WHERE p.stock_quantity < op.quantity
    ) THEN
        RAISE(ABORT, 'éƒ¨åˆ†å•†å“åº“å­˜ä¸è¶³')
END;

-- éªŒè¯äº§å“çŠ¶æ€
SELECT CASE
    WHEN EXISTS (
        SELECT 1 FROM order_processing op
        JOIN products p ON op.product_id = p.product_id  
        WHERE p.status != 'active'
    ) THEN
        RAISE(ABORT, 'è®¢å•ä¸­åŒ…å«å·²ä¸‹æ¶å•†å“')
END;

-- åˆ›å»ºè®¢å•
INSERT INTO orders (
    order_number, user_id, subtotal, tax_amount, shipping_amount, 
    total_amount, status, shipping_address, billing_address
)
SELECT 
    'ORD-' || strftime('%Y%m%d%H%M%S', 'now') || '-' || abs(random() % 10000),
    user_id,
    SUM(quantity * unit_price) as subtotal,
    SUM(quantity * unit_price) * 0.08 as tax_amount,
    CASE WHEN SUM(quantity * unit_price) > 50 THEN 0 ELSE 5.99 END as shipping_amount,
    SUM(quantity * unit_price) * 1.08 + CASE WHEN SUM(quantity * unit_price) > 50 THEN 0 ELSE 5.99 END as total_amount,
    'confirmed',
    json_object('address', '123 Main St', 'city', 'Anytown', 'zip', '12345'),
    json_object('address', '123 Main St', 'city', 'Anytown', 'zip', '12345')
FROM order_processing
GROUP BY user_id;

-- ä¿å­˜ç‚¹ - å¦‚æœè®¢å•é¡¹ç›®æ’å…¥å¤±è´¥ï¼Œå¯ä»¥å›æ»šåˆ°è¿™é‡Œ
SAVEPOINT order_items_start;

-- æ’å…¥è®¢å•é¡¹ç›®
INSERT INTO order_items (
    order_id, product_id, quantity, unit_price, 
    product_name, product_sku
)
SELECT 
    (SELECT MAX(order_id) FROM orders),
    op.product_id,
    op.quantity,
    op.unit_price,
    p.product_name,
    p.sku
FROM order_processing op
JOIN products p ON op.product_id = p.product_id;

-- æ‰£å‡åº“å­˜
UPDATE products 
SET stock_quantity = stock_quantity - (
    SELECT quantity FROM order_processing 
    WHERE product_id = products.product_id
),
updated_at = datetime('now', 'localtime')
WHERE product_id IN (SELECT product_id FROM order_processing);

-- éªŒè¯æ‰£å‡ååº“å­˜ä¸ä¸ºè´Ÿæ•° (åŒé‡æ£€æŸ¥)
SELECT CASE
    WHEN EXISTS (
        SELECT 1 FROM products 
        WHERE product_id IN (SELECT product_id FROM order_processing)
        AND stock_quantity < 0
    ) THEN
        RAISE(ABORT, 'åº“å­˜æ‰£å‡å¼‚å¸¸ï¼Œæ•°æ®ä¸ä¸€è‡´')
END;

-- æ¸…ç†ä¸´æ—¶è¡¨
DROP TABLE order_processing;

-- æäº¤äº‹åŠ¡
COMMIT TRANSACTION;

-- 4. é”™è¯¯å¤„ç†å’Œå›æ»šç¤ºä¾‹
-- æ¼”ç¤ºä¸åŒç±»å‹çš„å›æ»šæ“ä½œ
BEGIN TRANSACTION;

-- ç¬¬ä¸€æ­¥ï¼šæ’å…¥ç”¨æˆ·
INSERT INTO users (username, email, password_hash, salt)
VALUES ('demo_user', 'demo@example.com', 'hash123', 'salt123');

SAVEPOINT after_user_insert;

-- ç¬¬äºŒæ­¥ï¼šå°è¯•æ’å…¥åå¥½è®¾ç½®
BEGIN TRY  -- SQLite ä¸ç›´æ¥æ”¯æŒ TRY-CATCHï¼Œè¿™é‡Œç”¨ä½œç¤ºä¾‹æ¦‚å¿µ

    INSERT INTO user_preferences (user_id, theme, language)
    VALUES (last_insert_rowid(), 'invalid_theme', 'en');  -- å‡è®¾è¿™ä¼šå¤±è´¥
    
    SAVEPOINT after_preferences;

    -- ç¬¬ä¸‰æ­¥ï¼šå°è¯•åˆ›å»ºåˆå§‹è®¢å•  
    INSERT INTO orders (user_id, status, total_amount)
    VALUES (last_insert_rowid(), 'draft', 0.00);

EXCEPTION
    -- å¦‚æœåå¥½è®¾ç½®å¤±è´¥ï¼Œå›æ»šåˆ°ç”¨æˆ·æ’å…¥å
    WHEN constraint_violation THEN
        ROLLBACK TO SAVEPOINT after_user_insert;
        -- æ’å…¥é»˜è®¤åå¥½
        INSERT INTO user_preferences (user_id, theme, language)
        VALUES (last_insert_rowid(), 'light', 'en');
        
    -- å¦‚æœè®¢å•åˆ›å»ºå¤±è´¥ï¼Œåªå›æ»šè®¢å•æ“ä½œ
    WHEN order_creation_failed THEN
        ROLLBACK TO SAVEPOINT after_preferences;

END TRY;

COMMIT;

-- 5. å¹¶å‘æ§åˆ¶ç­–ç•¥
-- WAL æ¨¡å¼ä¸‹çš„è¯»å†™å¹¶å‘
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA busy_timeout = 30000;  -- 30ç§’è¶…æ—¶

-- ä¹è§‚é”ç‰ˆæœ¬æ§åˆ¶ç¤ºä¾‹
-- æ·»åŠ ç‰ˆæœ¬å­—æ®µåˆ°å…³é”®è¡¨
ALTER TABLE products ADD COLUMN version INTEGER DEFAULT 1;
ALTER TABLE orders ADD COLUMN version INTEGER DEFAULT 1;

-- ä¹è§‚é”æ›´æ–°æ¨¡å¼
-- æ›´æ–°äº§å“ä¿¡æ¯æ—¶æ£€æŸ¥ç‰ˆæœ¬
UPDATE products 
SET product_name = 'New Product Name',
    price = 199.99,
    version = version + 1,
    updated_at = datetime('now', 'localtime')
WHERE product_id = 1 
AND version = 1;  -- æ£€æŸ¥ç‰ˆæœ¬å·

-- æ£€æŸ¥æ˜¯å¦æœ‰è¡Œè¢«æ›´æ–° (åº”ç”¨ç¨‹åºé€»è¾‘)
-- SELECT changes();  -- å¦‚æœè¿”å› 0ï¼Œè¯´æ˜ç‰ˆæœ¬å†²çª

-- 6. æ€§èƒ½ä¼˜åŒ–çš„äº‹åŠ¡æ¨¡å¼
-- æ‰¹é‡æ“ä½œäº‹åŠ¡
BEGIN IMMEDIATE TRANSACTION;

-- å…³é—­è‡ªåŠ¨æäº¤ä»¥æé«˜æ‰¹é‡æ’å…¥æ€§èƒ½
PRAGMA synchronous = OFF;   -- ä¸´æ—¶å…³é—­åŒæ­¥
PRAGMA journal_mode = MEMORY;  -- ä½¿ç”¨å†…å­˜æ—¥å¿—

-- æ‰¹é‡æ’å…¥å¤§é‡æ•°æ®
WITH RECURSIVE bulk_data(n) AS (
    SELECT 1
    UNION ALL
    SELECT n + 1 FROM bulk_data WHERE n < 10000
)
INSERT INTO products (sku, product_name, category_id, price, cost_price, stock_quantity)
SELECT 
    'BULK-' || printf('%06d', n),
    'Bulk Product ' || n,
    (n % 5) + 1,  -- åˆ†é…åˆ°5ä¸ªç±»åˆ«
    ROUND(random() * 100 + 10, 2),  -- éšæœºä»·æ ¼ 10-110
    ROUND(random() * 50 + 5, 2),    -- éšæœºæˆæœ¬ 5-55
    abs(random() % 100) + 1         -- éšæœºåº“å­˜ 1-100
FROM bulk_data;

-- æ¢å¤æ­£å¸¸è®¾ç½®
PRAGMA synchronous = NORMAL;
PRAGMA journal_mode = WAL;

COMMIT TRANSACTION;

-- 7. æ­»é”é¢„é˜²ç­–ç•¥
-- æŒ‰å›ºå®šé¡ºåºè·å–é”ä»¥é˜²æ­¢æ­»é”
-- ç¤ºä¾‹ï¼šæ€»æ˜¯æŒ‰account_idå‡åºè·å–é”

CREATE VIEW account_transfer_safe AS
WITH ordered_accounts AS (
    SELECT 
        CASE WHEN from_account_id < to_account_id THEN from_account_id ELSE to_account_id END as first_account,
        CASE WHEN from_account_id < to_account_id THEN to_account_id ELSE from_account_id END as second_account,
        amount,
        reference_number
    FROM pending_transfers  -- å‡è®¾çš„å¾…å¤„ç†è½¬è´¦è¡¨
)
SELECT * FROM ordered_accounts;

-- ä½¿ç”¨è§†å›¾ç¡®ä¿æŒ‰é¡ºåºé”å®šè´¦æˆ·
-- è¿™æ ·å¯ä»¥é¿å…ä¸åŒäº‹åŠ¡ä»¥ä¸åŒé¡ºåºé”å®šç›¸åŒè´¦æˆ·å¯¼è‡´çš„æ­»é”
```

### 5.5 JSONæ•°æ®å¤„ç† (SQLite 3.38+)

```sql
-- 1. JSONæ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢
-- ç”¨æˆ·åå¥½è®¾ç½®çš„JSONå­˜å‚¨
INSERT INTO users (username, email, password_hash, salt, preferences, metadata)
VALUES (
    'json_user',
    'json@example.com',
    'hash123',
    'salt123',
    json_object(
        'theme', 'dark',
        'language', 'zh-CN',
        'notifications', json_object(
            'email', true,
            'push', false,
            'frequency', 'daily'
        ),
        'dashboard_widgets', json_array(
            'sales_chart',
            'inventory_alerts', 
            'recent_orders'
        )
    ),
    json_object(
        'source', 'web_registration',
        'campaign', json_object(
            'name', 'spring_sale_2024',
            'medium', 'email',
            'content', 'newsletter_march'
        ),
        'device_info', json_object(
            'os', 'Windows',
            'browser', 'Chrome',
            'version', '122.0.0.0'
        )
    )
);

-- 2. JSONæŸ¥è¯¢å’Œæå–
-- åŸºæœ¬JSONè·¯å¾„æŸ¥è¯¢
SELECT 
    user_id,
    username,
    json_extract(preferences, '$.theme') as user_theme,
    json_extract(preferences, '$.language') as user_language,
    json_extract(preferences, '$.notifications.email') as email_notifications,
    json_extract(metadata, '$.source') as acquisition_source,
    json_extract(metadata, '$.campaign.name') as campaign_name
FROM users 
WHERE preferences IS NOT NULL;

-- JSONæ•°ç»„æ“ä½œ
SELECT 
    user_id,
    username,
    json_extract(preferences, '$.dashboard_widgets') as widgets,
    json_array_length(json_extract(preferences, '$.dashboard_widgets')) as widget_count
FROM users 
WHERE json_extract(preferences, '$.dashboard_widgets') IS NOT NULL;

-- å¤æ‚JSONæŸ¥è¯¢
SELECT 
    user_id,
    username,
    -- æå–åµŒå¥—å¯¹è±¡
    json_extract(preferences, '$.notifications') as notification_settings,
    
    -- æ¡ä»¶æå–
    CASE 
        WHEN json_extract(preferences, '$.notifications.email') = true THEN 'Enabled'
        ELSE 'Disabled'
    END as email_notification_status,
    
    -- JSONå¯¹è±¡é”®æ£€æŸ¥
    CASE 
        WHEN json_type(preferences, '$.theme') IS NOT NULL THEN 'Has theme setting'
        ELSE 'No theme setting'
    END as theme_status
FROM users
WHERE json_valid(preferences) = 1;

-- 3. JSONæ•°æ®ä¿®æ”¹
-- æ›´æ–°JSONå­—æ®µä¸­çš„ç‰¹å®šå€¼
UPDATE users 
SET preferences = json_set(
    preferences,
    '$.theme', 'light',
    '$.language', 'en',
    '$.notifications.push', true
)
WHERE user_id = 1;

-- æ·»åŠ æ–°çš„JSONå±æ€§
UPDATE users
SET preferences = json_set(
    preferences,
    '$.timezone', 'America/New_York',
    '$.date_format', 'MM/DD/YYYY'
)
WHERE json_extract(preferences, '$.timezone') IS NULL;

-- åˆ é™¤JSONå±æ€§
UPDATE users
SET preferences = json_remove(
    preferences,
    '$.old_setting',
    '$.deprecated_feature'
)
WHERE user_id = 1;

-- 4. JSONèšåˆå’Œåˆ†æ
-- ç»Ÿè®¡ç”¨æˆ·åå¥½åˆ†å¸ƒ
SELECT 
    json_extract(preferences, '$.theme') as theme,
    COUNT(*) as user_count,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM users WHERE preferences IS NOT NULL), 2) as percentage
FROM users
WHERE json_extract(preferences, '$.theme') IS NOT NULL
GROUP BY json_extract(preferences, '$.theme')
ORDER BY user_count DESC;

-- åˆ†æé€šçŸ¥åå¥½
SELECT 
    json_extract(preferences, '$.notifications.email') as email_pref,
    json_extract(preferences, '$.notifications.push') as push_pref,
    COUNT(*) as user_count
FROM users
WHERE json_extract(preferences, '$.notifications') IS NOT NULL
GROUP BY 
    json_extract(preferences, '$.notifications.email'),
    json_extract(preferences, '$.notifications.push');

-- 5. JSONç´¢å¼•ä¼˜åŒ–
-- ä¸ºå¸¸ç”¨çš„JSONè·¯å¾„åˆ›å»ºç´¢å¼•
CREATE INDEX idx_users_theme ON users(json_extract(preferences, '$.theme'));
CREATE INDEX idx_users_language ON users(json_extract(preferences, '$.language'));
CREATE INDEX idx_users_source ON users(json_extract(metadata, '$.source'));
CREATE INDEX idx_users_campaign ON users(json_extract(metadata, '$.campaign.name'));

-- 6. äº§å“è§„æ ¼çš„JSONå­˜å‚¨ç¤ºä¾‹
UPDATE products 
SET specifications = json_object(
    'brand', 'TechCorp',
    'model', 'Pro-X1',
    'dimensions', json_object(
        'length', 15.6,
        'width', 10.2, 
        'height', 0.8,
        'unit', 'inches'
    ),
    'weight', json_object(
        'value', 2.1,
        'unit', 'kg'
    ),
    'features', json_array(
        'Wireless charging',
        'Waterproof',
        'Fast charging',
        'Bluetooth 5.2'
    ),
    'technical_specs', json_object(
        'processor', 'Intel i7-12700K',
        'memory', '16GB DDR4',
        'storage', '512GB SSD',
        'graphics', 'NVIDIA RTX 3070'
    ),
    'certifications', json_array(
        'CE', 'FCC', 'RoHS'
    )
)
WHERE sku = 'TECH-PRO-X1';

-- åŸºäºJSONè§„æ ¼çš„äº§å“æœç´¢
SELECT 
    p.product_id,
    p.sku,
    p.product_name,
    p.price,
    json_extract(p.specifications, '$.brand') as brand,
    json_extract(p.specifications, '$.technical_specs.processor') as processor,
    json_extract(p.specifications, '$.technical_specs.memory') as memory
FROM products p
WHERE json_extract(p.specifications, '$.brand') = 'TechCorp'
AND json_extract(p.specifications, '$.technical_specs.memory') LIKE '%16GB%'
AND json_array_length(json_extract(p.specifications, '$.features')) >= 3;
```

## 6. æ€§èƒ½ä¼˜åŒ–å®æˆ˜

### 6.1 æŸ¥è¯¢ä¼˜åŒ–

```sql
-- æŸ¥çœ‹æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’
EXPLAIN QUERY PLAN 
SELECT u.username, o.total_amount
FROM users u 
JOIN orders o ON u.user_id = o.user_id
WHERE u.created_at > date('now', '-30 days')
ORDER BY o.total_amount DESC;

-- ä¼˜åŒ–å‰çš„æŸ¥è¯¢
SELECT * FROM products 
WHERE product_name LIKE '%search_term%'
ORDER BY price;

-- ä¼˜åŒ–åçš„æŸ¥è¯¢ï¼ˆä½¿ç”¨ FTS å…¨æ–‡æœç´¢ï¼‰
CREATE VIRTUAL TABLE products_fts USING fts5(product_name, description);
INSERT INTO products_fts SELECT product_name, description FROM products;

SELECT p.* 
FROM products p
JOIN products_fts fts ON p.product_id = fts.rowid
WHERE products_fts MATCH 'search_term'
ORDER BY p.price;

-- ä½¿ç”¨è¦†ç›–ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_products_category_price_stock 
ON products(category_id, price, stock_quantity);

-- è¿™ä¸ªæŸ¥è¯¢å°†ä½¿ç”¨è¦†ç›–ç´¢å¼•ï¼Œæ— éœ€è®¿é—®è¡¨æ•°æ®
SELECT price, stock_quantity 
FROM products 
WHERE category_id = 1 
ORDER BY price;
```

### 6.2 æ•°æ®åº“é…ç½®ä¼˜åŒ–

```sql
-- æŸ¥çœ‹å½“å‰ PRAGMA è®¾ç½®
PRAGMA compile_options;
PRAGMA database_list;
PRAGMA table_info(users);

-- æ€§èƒ½ä¼˜åŒ–è®¾ç½®
PRAGMA journal_mode = WAL;          -- ä½¿ç”¨ WAL æ¨¡å¼æé«˜å¹¶å‘æ€§
PRAGMA synchronous = NORMAL;        -- å¹³è¡¡æ€§èƒ½å’Œå®‰å…¨æ€§
PRAGMA cache_size = 10000;          -- è®¾ç½®ç¼“å­˜å¤§å° (é¡µæ•°)
PRAGMA temp_store = MEMORY;         -- ä¸´æ—¶è¡¨å­˜å‚¨åœ¨å†…å­˜ä¸­
PRAGMA mmap_size = 268435456;       -- 256MB å†…å­˜æ˜ å°„

-- æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
PRAGMA page_count;
PRAGMA page_size;
PRAGMA freelist_count;

-- åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE;
PRAGMA optimize;  -- SQLite 3.18+ è‡ªåŠ¨ä¼˜åŒ–
```

### 6.3 ç»´æŠ¤æ“ä½œ

```sql
-- æ•°æ®åº“æ¸…ç†å’Œä¼˜åŒ–
VACUUM;                    -- é‡æ„æ•°æ®åº“ï¼Œæ¸…ç†ç¢ç‰‡
PRAGMA incremental_vacuum; -- å¢é‡æ¸…ç†

-- é‡å»ºç´¢å¼•
REINDEX;                   -- é‡å»ºæ‰€æœ‰ç´¢å¼•
REINDEX idx_users_email;   -- é‡å»ºç‰¹å®šç´¢å¼•

-- æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
PRAGMA integrity_check;
PRAGMA foreign_key_check;
PRAGMA quick_check;
```

## 7. Python ç¼–ç¨‹å®æˆ˜

### 7.1 å®Œæ•´çš„ Python æ•°æ®è®¿é—®å±‚

```python
import sqlite3
import json
import logging
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from contextlib import contextmanager

class SQLiteManager:
    """SQLite æ•°æ®åº“ç®¡ç†ç±»"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.init_database()
    
    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row  # è¿”å›ç±»ä¼¼å­—å…¸çš„è¡Œå¯¹è±¡
        conn.execute("PRAGMA foreign_keys = ON")  # å¯ç”¨å¤–é”®çº¦æŸ
        try:
            yield conn
        except Exception as e:
            conn.rollback()
            logging.error(f"Database operation failed: {e}")
            raise
        finally:
            conn.close()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ç»“æ„"""
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # åˆ›å»ºç”¨æˆ·è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS users (
                    user_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT NOT NULL UNIQUE,
                    email TEXT NOT NULL,
                    password_hash TEXT NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    is_active BOOLEAN DEFAULT 1
                )
            ''')
            
            # åˆ›å»ºäº§å“è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS products (
                    product_id INTEGER PRIMARY KEY,
                    product_name TEXT NOT NULL,
                    price DECIMAL(10,2) CHECK (price > 0),
                    stock_quantity INTEGER DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_users_email ON users(email)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_products_name ON products(product_name)')
            
            conn.commit()
    
    def create_user(self, username: str, email: str, password_hash: str) -> int:
        """åˆ›å»ºæ–°ç”¨æˆ·"""
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                'INSERT INTO users (username, email, password_hash) VALUES (?, ?, ?)',
                (username, email, password_hash)
            )
            user_id = cursor.lastrowid
            conn.commit()
            return user_id
    
    def get_user(self, user_id: int) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT * FROM users WHERE user_id = ?', (user_id,))
            row = cursor.fetchone()
            return dict(row) if row else None
    
    def get_users_with_pagination(self, page: int = 1, page_size: int = 10) -> Tuple[List[Dict], int]:
        """åˆ†é¡µè·å–ç”¨æˆ·åˆ—è¡¨"""
        offset = (page - 1) * page_size
        
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # è·å–æ€»æ•°
            cursor.execute('SELECT COUNT(*) FROM users WHERE is_active = 1')
            total_count = cursor.fetchone()[0]
            
            # è·å–å½“å‰é¡µæ•°æ®
            cursor.execute(
                '''SELECT user_id, username, email, created_at 
                   FROM users 
                   WHERE is_active = 1 
                   ORDER BY created_at DESC 
                   LIMIT ? OFFSET ?''',
                (page_size, offset)
            )
            rows = cursor.fetchall()
            users = [dict(row) for row in rows]
            
            return users, total_count
    
    def update_user(self, user_id: int, **kwargs) -> bool:
        """æ›´æ–°ç”¨æˆ·ä¿¡æ¯"""
        if not kwargs:
            return False
        
        # æ„å»ºåŠ¨æ€ SQL
        fields = []
        values = []
        for key, value in kwargs.items():
            if key in ['username', 'email', 'is_active']:
                fields.append(f"{key} = ?")
                values.append(value)
        
        if not fields:
            return False
        
        fields.append("updated_at = CURRENT_TIMESTAMP")
        values.append(user_id)
        
        sql = f"UPDATE users SET {', '.join(fields)} WHERE user_id = ?"
        
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(sql, values)
            conn.commit()
            return cursor.rowcount > 0
    
    def search_products(self, keyword: str, min_price: float = None, max_price: float = None) -> List[Dict]:
        """æœç´¢äº§å“"""
        sql = "SELECT * FROM products WHERE product_name LIKE ?"
        params = [f"%{keyword}%"]
        
        if min_price is not None:
            sql += " AND price >= ?"
            params.append(min_price)
        
        if max_price is not None:
            sql += " AND price <= ?"
            params.append(max_price)
        
        sql += " ORDER BY product_name"
        
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(sql, params)
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def execute_transaction(self, operations: List[Tuple[str, Tuple]]) -> bool:
        """æ‰§è¡Œäº‹åŠ¡æ“ä½œ"""
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("BEGIN TRANSACTION")
            
            try:
                for sql, params in operations:
                    cursor.execute(sql, params)
                conn.commit()
                return True
            except Exception as e:
                conn.rollback()
                logging.error(f"Transaction failed: {e}")
                return False
    
    def get_database_stats(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            stats = {}
            
            # è¡¨ç»Ÿè®¡
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
            tables = [row[0] for row in cursor.fetchall()]
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                stats[f"{table}_count"] = count
            
            # æ•°æ®åº“å¤§å°ä¿¡æ¯
            cursor.execute("PRAGMA page_count")
            page_count = cursor.fetchone()[0]
            cursor.execute("PRAGMA page_size")
            page_size = cursor.fetchone()[0]
            
            stats['database_size_bytes'] = page_count * page_size
            stats['page_count'] = page_count
            stats['page_size'] = page_size
            
            return stats

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
    db = SQLiteManager('example.db')
    
    # åˆ›å»ºç”¨æˆ·
    try:
        user_id = db.create_user('alice', 'alice@example.com', 'hashed_password')
        print(f"Created user with ID: {user_id}")
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user = db.get_user(user_id)
        print(f"User info: {user}")
        
        # æ›´æ–°ç”¨æˆ·
        success = db.update_user(user_id, email='alice_new@example.com')
        print(f"Update success: {success}")
        
        # åˆ†é¡µè·å–ç”¨æˆ·
        users, total = db.get_users_with_pagination(page=1, page_size=5)
        print(f"Users page 1: {len(users)} of {total} total")
        
        # è·å–æ•°æ®åº“ç»Ÿè®¡
        stats = db.get_database_stats()
        print(f"Database stats: {stats}")
        
    except sqlite3.IntegrityError as e:
        print(f"Database integrity error: {e}")
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()
```

### 7.2 æ€§èƒ½ç›‘æ§å’Œåˆ†æå·¥å…·

```python
import sqlite3
import time
from functools import wraps
from typing import Callable, Any

class SQLiteProfiler:
    """SQLite æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.query_stats = {}
    
    def profile_query(self, description: str = None):
        """æŸ¥è¯¢æ€§èƒ½åˆ†æè£…é¥°å™¨"""
        def decorator(func: Callable) -> Callable:
            @wraps(func)
            def wrapper(*args, **kwargs) -> Any:
                start_time = time.time()
                result = func(*args, **kwargs)
                end_time = time.time()
                
                execution_time = end_time - start_time
                func_name = description or func.__name__
                
                if func_name not in self.query_stats:
                    self.query_stats[func_name] = {
                        'total_time': 0,
                        'call_count': 0,
                        'avg_time': 0,
                        'max_time': 0
                    }
                
                stats = self.query_stats[func_name]
                stats['call_count'] += 1
                stats['total_time'] += execution_time
                stats['avg_time'] = stats['total_time'] / stats['call_count']
                stats['max_time'] = max(stats['max_time'], execution_time)
                
                print(f"Query '{func_name}' executed in {execution_time:.4f}s")
                return result
            return wrapper
        return decorator
    
    def analyze_query_plan(self, sql: str, params: tuple = None):
        """åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # è·å–æŸ¥è¯¢è®¡åˆ’
            explain_sql = f"EXPLAIN QUERY PLAN {sql}"
            if params:
                cursor.execute(explain_sql, params)
            else:
                cursor.execute(explain_sql)
            
            plan = cursor.fetchall()
            
            print(f"Query: {sql}")
            print(f"Params: {params}")
            print("Execution Plan:")
            for row in plan:
                print(f"  {row}")
            print("-" * 50)
    
    def get_table_statistics(self):
        """è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            for table in tables:
                print(f"\nTable: {table}")
                
                # è¡Œæ•°ç»Ÿè®¡
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                row_count = cursor.fetchone()[0]
                print(f"  Row count: {row_count}")
                
                # åˆ—ä¿¡æ¯
                cursor.execute(f"PRAGMA table_info({table})")
                columns = cursor.fetchall()
                print(f"  Columns: {len(columns)}")
                for col in columns:
                    print(f"    {col[1]} ({col[2]}) {'PRIMARY KEY' if col[5] else ''}")
    
    def print_performance_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("SQLITE PERFORMANCE REPORT")
        print("="*60)
        
        if not self.query_stats:
            print("No queries executed yet.")
            return
        
        # æŒ‰å¹³å‡æ‰§è¡Œæ—¶é—´æ’åº
        sorted_stats = sorted(
            self.query_stats.items(), 
            key=lambda x: x[1]['avg_time'], 
            reverse=True
        )
        
        print(f"{'Query':<30} {'Calls':<8} {'Total(s)':<10} {'Avg(s)':<10} {'Max(s)':<10}")
        print("-" * 70)
        
        for query, stats in sorted_stats:
            print(f"{query[:30]:<30} "
                  f"{stats['call_count']:<8} "
                  f"{stats['total_time']:<10.4f} "
                  f"{stats['avg_time']:<10.4f} "
                  f"{stats['max_time']:<10.4f}")

# æ€§èƒ½æµ‹è¯•ç¤ºä¾‹
def performance_test():
    profiler = SQLiteProfiler('performance_test.db')
    db = SQLiteManager('performance_test.db')
    
    @profiler.profile_query("bulk_insert_users")
    def bulk_insert_users(count: int):
        operations = []
        for i in range(count):
            operations.append((
                'INSERT INTO users (username, email, password_hash) VALUES (?, ?, ?)',
                (f'user{i}', f'user{i}@example.com', f'hash{i}')
            ))
        return db.execute_transaction(operations)
    
    @profiler.profile_query("search_users_by_email")
    def search_users():
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT * FROM users WHERE email LIKE ?', ('%user1%',))
            return cursor.fetchall()
    
    # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    print("Starting performance test...")
    
    # æ‰¹é‡æ’å…¥æµ‹è¯•
    bulk_insert_users(1000)
    
    # æœç´¢æµ‹è¯•
    for _ in range(10):
        search_users()
    
    # åˆ†ææŸ¥è¯¢è®¡åˆ’
    profiler.analyze_query_plan(
        'SELECT * FROM users WHERE email LIKE ?',
        ('%user1%',)
    )
    
    # è·å–è¡¨ç»Ÿè®¡
    profiler.get_table_statistics()
    
    # æ‰“å°æ€§èƒ½æŠ¥å‘Š
    profiler.print_performance_report()

if __name__ == "__main__":
    performance_test()
```

## 8. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’Œæœ€ä½³å®è·µ

### 8.1 å¤‡ä»½å’Œæ¢å¤ç­–ç•¥

```bash
#!/bin/bash
# SQLite å¤‡ä»½è„šæœ¬

DB_PATH="/path/to/your/database.db"
BACKUP_DIR="/path/to/backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="$BACKUP_DIR/database_backup_$TIMESTAMP.db"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# çƒ­å¤‡ä»½ (åœ¨çº¿å¤‡ä»½)
sqlite3 "$DB_PATH" ".backup $BACKUP_FILE"

if [ $? -eq 0 ]; then
    echo "Backup successful: $BACKUP_FILE"
    
    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip "$BACKUP_FILE"
    echo "Backup compressed: $BACKUP_FILE.gz"
    
    # åˆ é™¤7å¤©å‰çš„å¤‡ä»½
    find "$BACKUP_DIR" -name "database_backup_*.db.gz" -mtime +7 -delete
    echo "Old backups cleaned up"
else
    echo "Backup failed!"
    exit 1
fi

# éªŒè¯å¤‡ä»½å®Œæ•´æ€§
echo "Verifying backup integrity..."
gunzip -c "$BACKUP_FILE.gz" > "/tmp/temp_backup.db"
sqlite3 "/tmp/temp_backup.db" "PRAGMA integrity_check;"
rm "/tmp/temp_backup.db"
```

### 8.2 ç›‘æ§å’Œæ—¥å¿—é…ç½®

```python
import logging
import sqlite3
import time
import threading
from datetime import datetime

class SQLiteMonitor:
    """SQLite æ•°æ®åº“ç›‘æ§å™¨"""
    
    def __init__(self, db_path: str, log_file: str = 'sqlite_monitor.log'):
        self.db_path = db_path
        self.monitoring = False
        self.stats = {
            'connections': 0,
            'queries': 0,
            'errors': 0,
            'last_query_time': None
        }
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            filename=log_file,
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        self.monitoring = True
        monitor_thread = threading.Thread(target=self._monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()
        self.logger.info("SQLite monitoring started")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        self.logger.info("SQLite monitoring stopped")
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                self._collect_stats()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                self.logger.error(f"Monitoring error: {e}")
    
    def _collect_stats(self):
        """æ”¶é›†æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
                cursor.execute("PRAGMA quick_check")
                check_result = cursor.fetchone()[0]
                if check_result != "ok":
                    self.logger.warning(f"Database integrity issue: {check_result}")
                
                # è·å–æ•°æ®åº“å¤§å°
                cursor.execute("PRAGMA page_count")
                page_count = cursor.fetchone()[0]
                cursor.execute("PRAGMA page_size")
                page_size = cursor.fetchone()[0]
                db_size = page_count * page_size
                
                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                self.logger.info(f"Database size: {db_size / (1024*1024):.2f} MB")
                
                # æ£€æŸ¥é”çŠ¶æ€
                cursor.execute("PRAGMA database_list")
                databases = cursor.fetchall()
                for db in databases:
                    db_name = db[1]
                    if db_name == 'main':
                        self.logger.debug(f"Main database: {db[2]}")
                
        except Exception as e:
            self.stats['errors'] += 1
            self.logger.error(f"Stats collection error: {e}")
    
    def log_query(self, query: str, params: tuple = None, execution_time: float = None):
        """è®°å½•æŸ¥è¯¢æ—¥å¿—"""
        self.stats['queries'] += 1
        self.stats['last_query_time'] = datetime.now()
        
        if execution_time and execution_time > 1.0:  # æ…¢æŸ¥è¯¢é˜ˆå€¼1ç§’
            self.logger.warning(f"Slow query ({execution_time:.3f}s): {query[:100]}...")
        else:
            self.logger.debug(f"Query executed ({execution_time:.3f}s): {query[:100]}...")
    
    def get_stats(self):
        """è·å–ç›‘æ§ç»Ÿè®¡"""
        return self.stats.copy()

# ä½¿ç”¨ç¤ºä¾‹
monitor = SQLiteMonitor('production.db')
monitor.start_monitoring()

# åœ¨ä½ çš„åº”ç”¨ä¸­è®°å½•æŸ¥è¯¢
# monitor.log_query("SELECT * FROM users WHERE id = ?", (1,), 0.001)
```

### 8.3 æ€§èƒ½è°ƒä¼˜é…ç½®

```sql
-- ç”Ÿäº§ç¯å¢ƒä¼˜åŒ– PRAGMA è®¾ç½®è„šæœ¬
-- å°†ä»¥ä¸‹è®¾ç½®æ·»åŠ åˆ°åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ

-- WAL æ¨¡å¼æé«˜å¹¶å‘æ€§èƒ½
PRAGMA journal_mode = WAL;

-- ä¼˜åŒ–åŒæ­¥æ¨¡å¼ (NORMAL å¹³è¡¡æ€§èƒ½å’Œå®‰å…¨)
PRAGMA synchronous = NORMAL;

-- å¢å¤§é¡µç¼“å­˜ (æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´)
PRAGMA cache_size = -64000;  -- 64MB ç¼“å­˜

-- å¯ç”¨å†…å­˜æ˜ å°„ (æ ¹æ®æ•°æ®åº“å¤§å°è°ƒæ•´)
PRAGMA mmap_size = 268435456;  -- 256MB

-- ä¸´æ—¶è¡¨å’Œæ’åºä½¿ç”¨å†…å­˜
PRAGMA temp_store = MEMORY;

-- è®¾ç½®é”è¶…æ—¶
PRAGMA busy_timeout = 30000;  -- 30ç§’

-- å¯ç”¨å¤–é”®çº¦æŸ
PRAGMA foreign_keys = ON;

-- ä¼˜åŒ–æŸ¥è¯¢è§„åˆ’å™¨
PRAGMA optimize;

-- æ£€æŸ¥è®¾ç½®æ˜¯å¦ç”Ÿæ•ˆ
SELECT 
    'journal_mode' as setting, 
    (SELECT * FROM pragma_journal_mode()) as value
UNION ALL
SELECT 
    'synchronous', 
    CAST((SELECT * FROM pragma_synchronous()) as TEXT)
UNION ALL
SELECT 
    'cache_size', 
    CAST((SELECT * FROM pragma_cache_size()) as TEXT)
UNION ALL
SELECT 
    'mmap_size', 
    CAST((SELECT * FROM pragma_mmap_size()) as TEXT);
```

## 9. å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

### 9.1 æ•°æ®åº“é”å®šé—®é¢˜

```python
import sqlite3
import time
import random
from contextlib import contextmanager

class SQLiteConnectionPool:
    """SQLite è¿æ¥æ± ï¼Œè§£å†³å¹¶å‘è®¿é—®é—®é¢˜"""
    
    def __init__(self, db_path: str, max_connections: int = 10):
        self.db_path = db_path
        self.max_connections = max_connections
        self.connections = []
        self.active_connections = 0
    
    @contextmanager
    def get_connection(self, timeout: int = 30):
        """è·å–è¿æ¥ï¼Œå¸¦è¶…æ—¶å’Œé‡è¯•æœºåˆ¶"""
        max_retries = 5
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                conn = sqlite3.connect(
                    self.db_path,
                    timeout=timeout,
                    check_same_thread=False
                )
                conn.execute("PRAGMA busy_timeout = 30000")
                conn.execute("PRAGMA journal_mode = WAL")
                
                yield conn
                return
                
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and retry_count < max_retries - 1:
                    retry_count += 1
                    wait_time = random.uniform(0.1, 1.0) * retry_count
                    time.sleep(wait_time)
                    continue
                else:
                    raise
            except Exception:
                raise
            finally:
                try:
                    conn.close()
                except:
                    pass

def handle_database_locked():
    """å¤„ç†æ•°æ®åº“é”å®šçš„ç¤ºä¾‹"""
    pool = SQLiteConnectionPool('concurrent_test.db')
    
    def worker_function(worker_id: int):
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        try:
            with pool.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
                cursor.execute("BEGIN IMMEDIATE TRANSACTION")
                cursor.execute(
                    "INSERT INTO test_table (worker_id, timestamp) VALUES (?, ?)",
                    (worker_id, time.time())
                )
                time.sleep(random.uniform(0.1, 0.5))  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                conn.commit()
                print(f"Worker {worker_id} completed successfully")
                
        except sqlite3.OperationalError as e:
            print(f"Worker {worker_id} failed: {e}")
    
    # åˆ›å»ºæµ‹è¯•è¡¨
    with pool.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS test_table (
                id INTEGER PRIMARY KEY,
                worker_id INTEGER,
                timestamp REAL
            )
        ''')
        conn.commit()
    
    # å¯åŠ¨å¤šä¸ªå·¥ä½œçº¿ç¨‹
    import threading
    threads = []
    for i in range(10):
        thread = threading.Thread(target=worker_function, args=(i,))
        threads.append(thread)
        thread.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()
```

### 9.2 æ•°æ®è¿ç§»å’Œç‰ˆæœ¬ç®¡ç†

```python
import sqlite3
import os
from typing import List, Tuple

class DatabaseMigrator:
    """æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†å’Œè¿ç§»å·¥å…·"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.migrations = []
        self.init_version_table()
    
    def init_version_table(self):
        """åˆå§‹åŒ–ç‰ˆæœ¬ç®¡ç†è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS schema_versions (
                    version INTEGER PRIMARY KEY,
                    applied_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    description TEXT
                )
            ''')
            conn.commit()
    
    def add_migration(self, version: int, description: str, up_sql: str, down_sql: str = None):
        """æ·»åŠ è¿ç§»è„šæœ¬"""
        self.migrations.append({
            'version': version,
            'description': description,
            'up_sql': up_sql,
            'down_sql': down_sql
        })
    
    def get_current_version(self) -> int:
        """è·å–å½“å‰æ•°æ®åº“ç‰ˆæœ¬"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT MAX(version) FROM schema_versions')
            result = cursor.fetchone()[0]
            return result if result is not None else 0
    
    def migrate_to_version(self, target_version: int):
        """è¿ç§»åˆ°æŒ‡å®šç‰ˆæœ¬"""
        current_version = self.get_current_version()
        
        if current_version == target_version:
            print(f"Database is already at version {target_version}")
            return
        
        # æ’åºè¿ç§»è„šæœ¬
        sorted_migrations = sorted(self.migrations, key=lambda x: x['version'])
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            if target_version > current_version:
                # å‘ä¸Šè¿ç§»
                for migration in sorted_migrations:
                    if current_version < migration['version'] <= target_version:
                        print(f"Applying migration {migration['version']}: {migration['description']}")
                        
                        try:
                            cursor.executescript(migration['up_sql'])
                            cursor.execute(
                                'INSERT INTO schema_versions (version, description) VALUES (?, ?)',
                                (migration['version'], migration['description'])
                            )
                            conn.commit()
                            print(f"Migration {migration['version']} applied successfully")
                            
                        except Exception as e:
                            conn.rollback()
                            print(f"Migration {migration['version']} failed: {e}")
                            raise
            else:
                # å‘ä¸‹è¿ç§» (éœ€è¦ down_sql)
                for migration in reversed(sorted_migrations):
                    if target_version < migration['version'] <= current_version:
                        if not migration['down_sql']:
                            raise ValueError(f"No down migration for version {migration['version']}")
                        
                        print(f"Reverting migration {migration['version']}: {migration['description']}")
                        
                        try:
                            cursor.executescript(migration['down_sql'])
                            cursor.execute(
                                'DELETE FROM schema_versions WHERE version = ?',
                                (migration['version'],)
                            )
                            conn.commit()
                            print(f"Migration {migration['version']} reverted successfully")
                            
                        except Exception as e:
                            conn.rollback()
                            print(f"Migration {migration['version']} revert failed: {e}")
                            raise

# ä½¿ç”¨ç¤ºä¾‹
def setup_migrations():
    migrator = DatabaseMigrator('app.db')
    
    # ç‰ˆæœ¬ 1: åˆ›å»ºç”¨æˆ·è¡¨
    migrator.add_migration(
        version=1,
        description="Create users table",
        up_sql='''
            CREATE TABLE users (
                user_id INTEGER PRIMARY KEY,
                username TEXT NOT NULL UNIQUE,
                email TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );
            CREATE INDEX idx_users_username ON users(username);
        ''',
        down_sql='''
            DROP INDEX IF EXISTS idx_users_username;
            DROP TABLE IF EXISTS users;
        '''
    )
    
    # ç‰ˆæœ¬ 2: æ·»åŠ ç”¨æˆ·çŠ¶æ€å­—æ®µ
    migrator.add_migration(
        version=2,
        description="Add is_active field to users",
        up_sql='''
            ALTER TABLE users ADD COLUMN is_active BOOLEAN DEFAULT 1;
            CREATE INDEX idx_users_active ON users(is_active);
        ''',
        down_sql='''
            DROP INDEX IF EXISTS idx_users_active;
            -- SQLite ä¸æ”¯æŒ DROP COLUMNï¼Œéœ€è¦é‡å»ºè¡¨
            CREATE TABLE users_backup AS SELECT user_id, username, email, created_at FROM users;
            DROP TABLE users;
            ALTER TABLE users_backup RENAME TO users;
            CREATE INDEX idx_users_username ON users(username);
        '''
    )
    
    # ç‰ˆæœ¬ 3: åˆ›å»ºäº§å“è¡¨
    migrator.add_migration(
        version=3,
        description="Create products table",
        up_sql='''
            CREATE TABLE products (
                product_id INTEGER PRIMARY KEY,
                product_name TEXT NOT NULL,
                price DECIMAL(10,2),
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );
        ''',
        down_sql='''
            DROP TABLE IF EXISTS products;
        '''
    )
    
    return migrator

# æ‰§è¡Œè¿ç§»
if __name__ == "__main__":
    migrator = setup_migrations()
    
    print(f"Current version: {migrator.get_current_version()}")
    
    # è¿ç§»åˆ°æœ€æ–°ç‰ˆæœ¬
    migrator.migrate_to_version(3)
    
    print(f"After migration: {migrator.get_current_version()}")
```

## 10. å­¦ä¹ éªŒè¯ä¸å®æˆ˜é¡¹ç›®

### 10.1 çŸ¥è¯†ç‚¹éªŒè¯æ¸…å•

å®Œæˆä»¥ä¸‹å®æˆ˜ç»ƒä¹ æ¥éªŒè¯ä½ çš„SQLite3æŒæ¡ç¨‹åº¦ï¼š

1. **åŸºç¡€æ“ä½œéªŒè¯** (å¿…é¡»100%å®Œæˆ)
   - [ ] åˆ›å»ºåŒ…å«çº¦æŸçš„å¤æ‚è¡¨ç»“æ„
   - [ ] å®ç°CRUDæ“ä½œçš„å®Œæ•´æµç¨‹
   - [ ] ä½¿ç”¨äº‹åŠ¡å¤„ç†å¹¶å‘æ“ä½œ
   - [ ] åˆ›å»ºå’Œä½¿ç”¨è§†å›¾ã€ç´¢å¼•ã€è§¦å‘å™¨

2. **æ€§èƒ½ä¼˜åŒ–éªŒè¯** (å¿…é¡»80%å®Œæˆ)
   - [ ] ä½¿ç”¨EXPLAINåˆ†ææŸ¥è¯¢è®¡åˆ’
   - [ ] å®ç°æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥
   - [ ] é…ç½®PRAGMAå‚æ•°ä¼˜åŒ–
   - [ ] å®ç°æ•°æ®åº“ç»´æŠ¤è„šæœ¬

3. **ç¼–ç¨‹é›†æˆéªŒè¯** (å¿…é¡»80%å®Œæˆ)
   - [ ] å®ç°Pythonæ•°æ®è®¿é—®å±‚
   - [ ] å¤„ç†å¹¶å‘è®¿é—®å’Œé”å®š
   - [ ] å®ç°è¿æ¥æ± ç®¡ç†
   - [ ] åˆ›å»ºæ€§èƒ½ç›‘æ§å·¥å…·

### 10.2 ç»¼åˆå®æˆ˜é¡¹ç›®ï¼šä¸ªäººä»»åŠ¡ç®¡ç†ç³»ç»Ÿ

æ„å»ºä¸€ä¸ªå®Œæ•´çš„ä¸ªäººä»»åŠ¡ç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

```sql
-- é¡¹ç›®æ•°æ®åº“ç»“æ„
CREATE TABLE projects (
    project_id INTEGER PRIMARY KEY,
    project_name TEXT NOT NULL,
    description TEXT,
    status TEXT DEFAULT 'active' CHECK (status IN ('active', 'completed', 'archived')),
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE tasks (
    task_id INTEGER PRIMARY KEY,
    project_id INTEGER,
    task_name TEXT NOT NULL,
    description TEXT,
    priority INTEGER DEFAULT 1 CHECK (priority BETWEEN 1 AND 5),
    status TEXT DEFAULT 'todo' CHECK (status IN ('todo', 'in_progress', 'completed')),
    due_date DATETIME,
    completed_at DATETIME,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (project_id) REFERENCES projects(project_id)
);

CREATE TABLE tags (
    tag_id INTEGER PRIMARY KEY,
    tag_name TEXT NOT NULL UNIQUE
);

CREATE TABLE task_tags (
    task_id INTEGER,
    tag_id INTEGER,
    PRIMARY KEY (task_id, tag_id),
    FOREIGN KEY (task_id) REFERENCES tasks(task_id),
    FOREIGN KEY (tag_id) REFERENCES tags(tag_id)
);

-- åˆ›å»ºå¿…è¦çš„ç´¢å¼•
CREATE INDEX idx_tasks_project ON tasks(project_id);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_due_date ON tasks(due_date);
CREATE INDEX idx_tasks_priority ON tasks(priority);

-- åˆ›å»ºè§†å›¾
CREATE VIEW task_overview AS
SELECT 
    t.task_id,
    t.task_name,
    p.project_name,
    t.priority,
    t.status,
    t.due_date,
    GROUP_CONCAT(tag.tag_name) as tags
FROM tasks t
LEFT JOIN projects p ON t.project_id = p.project_id
LEFT JOIN task_tags tt ON t.task_id = tt.task_id
LEFT JOIN tags tag ON tt.tag_id = tag.tag_id
GROUP BY t.task_id;
```

å®ç°è¦æ±‚ï¼š
1. å®Œæ•´çš„Python APIæ¥å£
2. æ•°æ®ç»Ÿè®¡å’ŒæŠ¥è¡¨åŠŸèƒ½
3. å¤‡ä»½æ¢å¤æœºåˆ¶
4. æ€§èƒ½ç›‘æ§
5. å•å…ƒæµ‹è¯•è¦†ç›–

å®Œæˆè¿™ä¸ªé¡¹ç›®åï¼Œä½ å°†å…·å¤‡åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨SQLite3çš„å®Œæ•´èƒ½åŠ›ã€‚

---

**å­¦ä¹ è·¯å¾„å»ºè®®ï¼š**
1. ç¬¬1-3å‘¨ï¼šæŒæ¡åŸºç¡€æ¦‚å¿µå’ŒSQLè¯­æ³•
2. ç¬¬4-6å‘¨ï¼šæ·±å…¥é«˜çº§ç‰¹æ€§å’Œæ€§èƒ½ä¼˜åŒ–
3. ç¬¬7-8å‘¨ï¼šç¼–ç¨‹é›†æˆå’Œå®æˆ˜é¡¹ç›®
4. æŒç»­å­¦ä¹ ï¼šå…³æ³¨SQLiteæ›´æ–°å’Œæœ€ä½³å®è·µ

SQLite3ä½œä¸ºè½»é‡çº§æ•°æ®åº“çš„é¦–é€‰ï¼ŒæŒæ¡å…¶æ ¸å¿ƒæŠ€èƒ½å°†ä¸ºä½ çš„æ•°æ®å¤„ç†èƒ½åŠ›æ‰“ä¸‹åšå®åŸºç¡€ã€‚è®°ä½ï¼Œç†è®ºå­¦ä¹ å¿…é¡»ç»“åˆå®é™…é¡¹ç›®ç»ƒä¹ æ‰èƒ½çœŸæ­£æŒæ¡ï¼