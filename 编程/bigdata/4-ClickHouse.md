# ClickHouse å­¦ä¹ ç¬”è®°

## ğŸ“‹ å­¦ä¹ ç›®æ ‡
- æ·±å…¥ç†è§£ClickHouseåˆ—å¼å­˜å‚¨åŸç†
- æŒæ¡ClickHouseè¡¨å¼•æ“å’Œç´¢å¼•æœºåˆ¶
- ç†Ÿç»ƒä½¿ç”¨ClickHouse SQLæŸ¥è¯¢
- ç†è§£ClickHouseåˆ†å¸ƒå¼æ¶æ„
- æŒæ¡ClickHouseæ€§èƒ½ä¼˜åŒ–æŠ€å·§
- å…·å¤‡ClickHouseè¿ç»´å’Œç›‘æ§èƒ½åŠ›

## 1. ClickHouse åŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯ ClickHouse

ClickHouseæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ—å¼æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆDBMSï¼‰ï¼Œä¸“ä¸ºåœ¨çº¿åˆ†æå¤„ç†ï¼ˆOLAPï¼‰è€Œè®¾è®¡ã€‚

**æ ¸å¿ƒç‰¹ç‚¹:**
- çœŸæ­£çš„åˆ—å¼å­˜å‚¨
- å‘é‡åŒ–æŸ¥è¯¢æ‰§è¡Œ
- æ•°æ®å‹ç¼©æ¯”é«˜ï¼ˆ10-100å€ï¼‰
- æ”¯æŒSQLæ ‡å‡†
- åˆ†å¸ƒå¼æŸ¥è¯¢
- å®æ—¶æ•°æ®æ›´æ–°

**åº”ç”¨åœºæ™¯:**
- å®æ—¶æ•°æ®åˆ†æ
- ç”¨æˆ·è¡Œä¸ºåˆ†æ
- æ—¥å¿—åˆ†æ
- å¹¿å‘Šç»Ÿè®¡
- ç›‘æ§ç³»ç»Ÿ
- å•†ä¸šæ™ºèƒ½ï¼ˆBIï¼‰

### 1.2 ClickHouse vs ä¼ ç»Ÿæ•°æ®åº“

| ç‰¹æ€§ | ClickHouse | MySQL | PostgreSQL |
|------|-----------|-------|-----------|
| å­˜å‚¨æ¨¡å‹ | åˆ—å¼å­˜å‚¨ | è¡Œå¼å­˜å‚¨ | è¡Œå¼å­˜å‚¨ |
| æŸ¥è¯¢æ€§èƒ½ | æå¿«(OLAP) | ä¸­ç­‰ | ä¸­ç­‰ |
| å†™å…¥æ€§èƒ½ | æ‰¹é‡å¿« | å•æ¡å¿« | å•æ¡å¿« |
| å‹ç¼©æ¯” | 10-100x | 2-5x | 2-5x |
| é€‚ç”¨åœºæ™¯ | OLAP | OLTP | OLTP |
| äº‹åŠ¡æ”¯æŒ | å¼± | å¼º | å¼º |

### 1.3 åˆ—å¼å­˜å‚¨ä¼˜åŠ¿

**è¡Œå¼å­˜å‚¨ vs åˆ—å¼å­˜å‚¨:**
```
è¡Œå¼å­˜å‚¨ (MySQL):
Row1: [id=1, name="Alice", age=25, city="Beijing"]
Row2: [id=2, name="Bob",   age=30, city="Shanghai"]
Row3: [id=3, name="Carol", age=28, city="Beijing"]

åˆ—å¼å­˜å‚¨ (ClickHouse):
Column[id]:   [1, 2, 3]
Column[name]: ["Alice", "Bob", "Carol"]
Column[age]:  [25, 30, 28]
Column[city]: ["Beijing", "Shanghai", "Beijing"]
```

**ä¼˜åŠ¿:**
- åªè¯»å–éœ€è¦çš„åˆ—
- æ›´é«˜çš„å‹ç¼©æ¯”
- å‘é‡åŒ–æ‰§è¡Œ
- CPUç¼“å­˜å‹å¥½

## 2. ClickHouse æ¶æ„

### 2.1 å•èŠ‚ç‚¹æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ClickHouse Server          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Query Processor                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Parser   â”‚  â”‚ Analyzer â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚Optimizer â”‚  â”‚ Executor â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage Engine                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ MergeTree Family         â”‚  â”‚
â”‚  â”‚ - MergeTree              â”‚  â”‚
â”‚  â”‚ - ReplacingMergeTree     â”‚  â”‚
â”‚  â”‚ - SummingMergeTree       â”‚  â”‚
â”‚  â”‚ - AggregatingMergeTree   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 åˆ†å¸ƒå¼æ¶æ„

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Client   â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”    â”Œâ”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚Shard1â”‚    â”‚Shard2â”‚    â”‚Shard3â”‚
â”‚Rep1  â”‚    â”‚Rep1  â”‚    â”‚Rep1  â”‚
â”‚Rep2  â”‚    â”‚Rep2  â”‚    â”‚Rep2  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒæ¦‚å¿µ:**
- **Shard**: æ•°æ®åˆ†ç‰‡
- **Replica**: æ•°æ®å‰¯æœ¬
- **Distributed Table**: åˆ†å¸ƒå¼è¡¨
- **Local Table**: æœ¬åœ°è¡¨
- **ZooKeeper**: åè°ƒæœåŠ¡

## 3. è¡¨å¼•æ“

### 3.1 MergeTree å¼•æ“æ—

**MergeTree (æœ€å¸¸ç”¨):**
```sql
CREATE TABLE events (
    date Date,
    user_id UInt32,
    event_type String,
    value Float64
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (user_id, date)
SETTINGS index_granularity = 8192;
```

**å…³é”®å‚æ•°:**
- `PARTITION BY`: åˆ†åŒºé”®ï¼ˆæŒ‰æœˆã€æŒ‰å¤©ç­‰ï¼‰
- `ORDER BY`: æ’åºé”®ï¼ˆä¸»é”®ï¼‰
- `index_granularity`: ç´¢å¼•ç²’åº¦ï¼ˆé»˜è®¤8192è¡Œï¼‰

**ReplacingMergeTree (æ•°æ®å»é‡):**
```sql
CREATE TABLE user_profile (
    user_id UInt32,
    name String,
    age UInt8,
    update_time DateTime
) ENGINE = ReplacingMergeTree(update_time)
PARTITION BY toYYYYMM(update_time)
ORDER BY user_id;
```

**SummingMergeTree (è‡ªåŠ¨æ±‚å’Œ):**
```sql
CREATE TABLE analytics (
    date Date,
    user_id UInt32,
    clicks UInt32,
    cost Float64
) ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (user_id, date);
```

**AggregatingMergeTree (é¢„èšåˆ):**
```sql
CREATE TABLE analytics_agg (
    date Date,
    user_id UInt32,
    clicks AggregateFunction(sum, UInt32),
    avg_value AggregateFunction(avg, Float64)
) ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (user_id, date);
```

### 3.2 å…¶ä»–å¸¸ç”¨å¼•æ“

**Memory (å†…å­˜è¡¨):**
```sql
CREATE TABLE temp_data (
    id UInt32,
    value String
) ENGINE = Memory;
```

**Distributed (åˆ†å¸ƒå¼è¡¨):**
```sql
CREATE TABLE events_dist AS events
ENGINE = Distributed(
    cluster_name,      -- é›†ç¾¤åç§°
    database_name,     -- æ•°æ®åº“å
    events,            -- æœ¬åœ°è¡¨å
    rand()             -- åˆ†ç‰‡é”®
);
```

**Dictionary (å­—å…¸):**
```sql
CREATE DICTIONARY user_dict (
    user_id UInt32,
    name String,
    age UInt8
) PRIMARY KEY user_id
SOURCE(CLICKHOUSE(
    HOST 'localhost'
    PORT 9000
    USER 'default'
    PASSWORD ''
    DB 'default'
    TABLE 'users'
))
LAYOUT(FLAT())
LIFETIME(300);
```

## 4. æ•°æ®ç±»å‹

### 4.1 åŸºç¡€æ•°æ®ç±»å‹

```sql
-- æ•´æ•°ç±»å‹
Int8, Int16, Int32, Int64
UInt8, UInt16, UInt32, UInt64

-- æµ®ç‚¹ç±»å‹
Float32, Float64
Decimal(P, S)  -- Decimal(18, 2)

-- å­—ç¬¦ä¸²ç±»å‹
String         -- ä»»æ„é•¿åº¦
FixedString(N) -- å›ºå®šé•¿åº¦

-- æ—¥æœŸæ—¶é—´ç±»å‹
Date           -- æ—¥æœŸ (YYYY-MM-DD)
DateTime       -- æ—¥æœŸæ—¶é—´
DateTime64(3)  -- æ¯«ç§’ç²¾åº¦

-- å¸ƒå°”ç±»å‹
UInt8          -- 0æˆ–1è¡¨ç¤ºå¸ƒå°”å€¼
```

### 4.2 å¤åˆæ•°æ®ç±»å‹

```sql
-- æ•°ç»„
Array(T)
-- ç¤ºä¾‹
column_name Array(String)
column_name Array(UInt32)

-- å…ƒç»„
Tuple(T1, T2, ...)
-- ç¤ºä¾‹
column_name Tuple(String, UInt32)

-- åµŒå¥—
Nested(
    name1 Type1,
    name2 Type2
)
-- ç¤ºä¾‹
user_events Nested(
    event_type String,
    timestamp DateTime
)
```

### 4.3 ç‰¹æ®Šæ•°æ®ç±»å‹

```sql
-- Nullable (å…è®¸NULL)
Nullable(String)
Nullable(UInt32)

-- Enum (æšä¸¾)
Enum8('active' = 1, 'inactive' = 2)
Enum16('status1' = 1, 'status2' = 2)

-- LowCardinality (ä½åŸºæ•°ä¼˜åŒ–)
LowCardinality(String)  -- é€‚åˆé‡å¤å€¼å¤šçš„åˆ—

-- UUID
UUID

-- IPv4/IPv6
IPv4
IPv6
```

## 5. SQL æŸ¥è¯¢

### 5.1 åŸºç¡€æŸ¥è¯¢

```sql
-- åŸºæœ¬æŸ¥è¯¢
SELECT user_id, count() as cnt
FROM events
WHERE date >= '2024-01-01'
GROUP BY user_id
ORDER BY cnt DESC
LIMIT 10;

-- å¤šè¡¨JOIN
SELECT
    e.user_id,
    u.name,
    count() as event_count
FROM events e
INNER JOIN users u ON e.user_id = u.user_id
WHERE e.date >= '2024-01-01'
GROUP BY e.user_id, u.name;

-- å­æŸ¥è¯¢
SELECT user_id, total
FROM (
    SELECT user_id, sum(value) as total
    FROM events
    GROUP BY user_id
)
WHERE total > 1000;
```

### 5.2 èšåˆå‡½æ•°

```sql
-- åŸºç¡€èšåˆ
SELECT
    count() as total,           -- è®¡æ•°
    sum(value) as total_value,  -- æ±‚å’Œ
    avg(value) as avg_value,    -- å¹³å‡å€¼
    min(value) as min_value,    -- æœ€å°å€¼
    max(value) as max_value     -- æœ€å¤§å€¼
FROM events;

-- å»é‡è®¡æ•°
SELECT
    uniq(user_id) as unique_users,           -- ç²¾ç¡®å»é‡
    uniqExact(user_id) as exact_unique,      -- ç²¾ç¡®å»é‡
    uniqCombined(user_id) as combined_unique -- HyperLogLogè¿‘ä¼¼
FROM events;

-- åˆ†ä½æ•°
SELECT
    quantile(0.5)(value) as median,      -- ä¸­ä½æ•°
    quantile(0.95)(value) as p95,        -- 95åˆ†ä½æ•°
    quantiles(0.5, 0.95, 0.99)(value)    -- å¤šä¸ªåˆ†ä½æ•°
FROM events;

-- TopK
SELECT
    topK(10)(user_id) as top_users,      -- Top 10ç”¨æˆ·
    topKWeighted(10)(user_id, value)     -- å¸¦æƒé‡çš„Top 10
FROM events;
```

### 5.3 çª—å£å‡½æ•°

```sql
-- ROW_NUMBER
SELECT
    user_id,
    date,
    value,
    ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY date) as rn
FROM events;

-- RANK/DENSE_RANK
SELECT
    user_id,
    value,
    RANK() OVER (ORDER BY value DESC) as rank,
    DENSE_RANK() OVER (ORDER BY value DESC) as dense_rank
FROM events;

-- LAG/LEAD
SELECT
    date,
    value,
    LAG(value, 1) OVER (ORDER BY date) as prev_value,
    LEAD(value, 1) OVER (ORDER BY date) as next_value
FROM events;

-- ç§»åŠ¨å¹³å‡
SELECT
    date,
    value,
    AVG(value) OVER (
        ORDER BY date
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) as moving_avg_3
FROM events;
```

### 5.4 æ•°ç»„å‡½æ•°

```sql
-- æ•°ç»„æ“ä½œ
SELECT
    arrayMap(x -> x * 2, [1,2,3]) as doubled,          -- [2,4,6]
    arrayFilter(x -> x > 2, [1,2,3,4]) as filtered,    -- [3,4]
    arrayReduce('sum', [1,2,3,4]) as sum_array,        -- 10
    arrayJoin([1,2,3]) as element;                     -- å±•å¼€æ•°ç»„

-- æ•°ç»„èšåˆ
SELECT
    groupArray(user_id) as user_list,      -- æ”¶é›†ä¸ºæ•°ç»„
    groupUniqArray(user_id) as unique_users -- å»é‡æ”¶é›†
FROM events
GROUP BY date;
```

## 6. æ•°æ®æ“ä½œ

### 6.1 æ’å…¥æ•°æ®

```sql
-- å•è¡Œæ’å…¥
INSERT INTO events VALUES
    ('2024-01-01', 100, 'click', 1.5);

-- æ‰¹é‡æ’å…¥
INSERT INTO events VALUES
    ('2024-01-01', 100, 'click', 1.5),
    ('2024-01-01', 101, 'view', 2.0),
    ('2024-01-01', 102, 'purchase', 50.0);

-- ä»æŸ¥è¯¢æ’å…¥
INSERT INTO events
SELECT * FROM temp_events WHERE date >= '2024-01-01';

-- ä»æ–‡ä»¶å¯¼å…¥
cat data.csv | clickhouse-client --query="INSERT INTO events FORMAT CSV"
```

### 6.2 æ›´æ–°å’Œåˆ é™¤

**è½»é‡çº§åˆ é™¤ (Lightweight Delete):**
```sql
-- ClickHouse 22.8+æ”¯æŒ
DELETE FROM events WHERE date < '2023-01-01';
```

**ä¼ ç»Ÿæ–¹å¼ (ALTER DELETE):**
```sql
-- å¼‚æ­¥åˆ é™¤ï¼Œç”Ÿæˆæ–°çš„æ•°æ®éƒ¨åˆ†
ALTER TABLE events DELETE WHERE date < '2023-01-01';
```

**è½»é‡çº§æ›´æ–°:**
```sql
-- ClickHouse 22.8+æ”¯æŒ
UPDATE events SET value = value * 2 WHERE user_id = 100;
```

**ä¼ ç»Ÿæ–¹å¼ (ALTER UPDATE):**
```sql
ALTER TABLE events UPDATE value = value * 2 WHERE user_id = 100;
```

### 6.3 æ•°æ®å¯¼å…¥å¯¼å‡º

**å¯¼å‡ºæ•°æ®:**
```bash
# å¯¼å‡ºä¸ºCSV
clickhouse-client --query="SELECT * FROM events FORMAT CSV" > events.csv

# å¯¼å‡ºä¸ºJSON
clickhouse-client --query="SELECT * FROM events FORMAT JSONEachRow" > events.json

# å¯¼å‡ºä¸ºParquet
clickhouse-client --query="SELECT * FROM events FORMAT Parquet" > events.parquet
```

**å¯¼å…¥æ•°æ®:**
```bash
# ä»CSVå¯¼å…¥
cat events.csv | clickhouse-client --query="INSERT INTO events FORMAT CSV"

# ä»JSONå¯¼å…¥
cat events.json | clickhouse-client --query="INSERT INTO events FORMAT JSONEachRow"
```

## 7. åˆ†å¸ƒå¼éƒ¨ç½²

### 7.1 é›†ç¾¤é…ç½®

**config.xmlé…ç½®:**
```xml
<clickhouse>
    <remote_servers>
        <my_cluster>
            <shard>
                <replica>
                    <host>node1</host>
                    <port>9000</port>
                </replica>
                <replica>
                    <host>node2</host>
                    <port>9000</port>
                </replica>
            </shard>
            <shard>
                <replica>
                    <host>node3</host>
                    <port>9000</port>
                </replica>
                <replica>
                    <host>node4</host>
                    <port>9000</port>
                </replica>
            </shard>
        </my_cluster>
    </remote_servers>

    <zookeeper>
        <node>
            <host>zk1</host>
            <port>2181</port>
        </node>
        <node>
            <host>zk2</host>
            <port>2181</port>
        </node>
        <node>
            <host>zk3</host>
            <port>2181</port>
        </node>
    </zookeeper>

    <macros>
        <shard>01</shard>
        <replica>replica1</replica>
    </macros>
</clickhouse>
```

### 7.2 åˆ›å»ºåˆ†å¸ƒå¼è¡¨

```sql
-- 1. åˆ›å»ºæœ¬åœ°è¡¨
CREATE TABLE events_local ON CLUSTER my_cluster (
    date Date,
    user_id UInt32,
    event_type String,
    value Float64
) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/events', '{replica}')
PARTITION BY toYYYYMM(date)
ORDER BY (user_id, date);

-- 2. åˆ›å»ºåˆ†å¸ƒå¼è¡¨
CREATE TABLE events_dist ON CLUSTER my_cluster AS events_local
ENGINE = Distributed(my_cluster, default, events_local, rand());

-- 3. å†™å…¥åˆ†å¸ƒå¼è¡¨
INSERT INTO events_dist VALUES ('2024-01-01', 100, 'click', 1.5);

-- 4. æŸ¥è¯¢åˆ†å¸ƒå¼è¡¨
SELECT count() FROM events_dist;
```

### 7.3 å‰¯æœ¬åŒæ­¥

**æ£€æŸ¥å‰¯æœ¬çŠ¶æ€:**
```sql
SELECT
    database,
    table,
    is_leader,
    total_replicas,
    active_replicas
FROM system.replicas;
```

**åŒæ­¥å‰¯æœ¬:**
```sql
-- åŒæ­¥æŒ‡å®šè¡¨
SYSTEM SYNC REPLICA events_local;

-- åŒæ­¥æ‰€æœ‰å‰¯æœ¬
SYSTEM SYNC REPLICA;
```

## 8. æ€§èƒ½ä¼˜åŒ–

### 8.1 è¡¨è®¾è®¡ä¼˜åŒ–

**é€‰æ‹©åˆé€‚çš„æ’åºé”®:**
```sql
-- å¥½çš„æ’åºé”®ï¼šé«˜åŸºæ•°åœ¨å‰
ORDER BY (user_id, date, event_type)

-- ä¸å¥½çš„æ’åºé”®ï¼šä½åŸºæ•°åœ¨å‰
ORDER BY (event_type, date, user_id)
```

**ä½¿ç”¨åˆ†åŒº:**
```sql
-- æŒ‰æœˆåˆ†åŒº
PARTITION BY toYYYYMM(date)

-- æŒ‰å¤©åˆ†åŒºï¼ˆæ•°æ®é‡å¤§æ—¶ï¼‰
PARTITION BY toYYYYMMDD(date)

-- å¤šçº§åˆ†åŒº
PARTITION BY (toYear(date), toMonth(date))
```

**ä½¿ç”¨ä½åŸºæ•°ç±»å‹:**
```sql
CREATE TABLE events (
    date Date,
    user_id UInt32,
    country LowCardinality(String),  -- å›½å®¶ä»£ç ï¼ˆé‡å¤å¤šï¼‰
    city LowCardinality(String),     -- åŸå¸‚ï¼ˆé‡å¤å¤šï¼‰
    event_type Enum8('click'=1, 'view'=2, 'purchase'=3)
) ENGINE = MergeTree()
ORDER BY (user_id, date);
```

### 8.2 æŸ¥è¯¢ä¼˜åŒ–

**ä½¿ç”¨PREWHERE:**
```sql
-- PREWHEREåœ¨WHEREä¹‹å‰è¿‡æ»¤ï¼Œå‡å°‘æ•°æ®è¯»å–
SELECT user_id, sum(value)
FROM events
PREWHERE date >= '2024-01-01'  -- å…ˆè¿‡æ»¤æ—¥æœŸ
WHERE event_type = 'purchase'   -- å†è¿‡æ»¤ç±»å‹
GROUP BY user_id;
```

**é¿å…SELECT *:**
```sql
-- ä¸å¥½
SELECT * FROM events WHERE date = '2024-01-01';

-- å¥½
SELECT user_id, event_type FROM events WHERE date = '2024-01-01';
```

**ä½¿ç”¨ç‰©åŒ–è§†å›¾:**
```sql
-- åˆ›å»ºç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW events_daily
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (date, user_id)
AS SELECT
    date,
    user_id,
    count() as event_count,
    sum(value) as total_value
FROM events
GROUP BY date, user_id;

-- æŸ¥è¯¢ç‰©åŒ–è§†å›¾ï¼ˆé€Ÿåº¦å¿«ï¼‰
SELECT * FROM events_daily WHERE date = '2024-01-01';
```

### 8.3 é…ç½®ä¼˜åŒ–

**config.xmlä¼˜åŒ–:**
```xml
<clickhouse>
    <!-- æœ€å¤§å†…å­˜ä½¿ç”¨ -->
    <max_memory_usage>10000000000</max_memory_usage>

    <!-- æœ€å¤§çº¿ç¨‹æ•° -->
    <max_threads>8</max_threads>

    <!-- åå°ä»»åŠ¡çº¿ç¨‹ -->
    <background_pool_size>16</background_pool_size>
    <background_schedule_pool_size>16</background_schedule_pool_size>

    <!-- åˆå¹¶è®¾ç½® -->
    <merge_tree>
        <max_bytes_to_merge_at_max_space_in_pool>161061273600</max_bytes_to_merge_at_max_space_in_pool>
        <parts_to_throw_insert>300</parts_to_throw_insert>
    </merge_tree>

    <!-- æŸ¥è¯¢ç¼“å­˜ -->
    <mark_cache_size>5368709120</mark_cache_size>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
</clickhouse>
```

## 9. ç›‘æ§ä¸è¿ç»´

### 9.1 ç³»ç»Ÿè¡¨

**æŸ¥è¯¢ç»Ÿè®¡:**
```sql
-- æŸ¥çœ‹å½“å‰æŸ¥è¯¢
SELECT query_id, user, query, elapsed
FROM system.processes;

-- æŸ¥çœ‹æ…¢æŸ¥è¯¢
SELECT
    query,
    query_duration_ms,
    read_rows,
    result_rows
FROM system.query_log
WHERE query_duration_ms > 1000
ORDER BY query_duration_ms DESC
LIMIT 10;

-- æŸ¥çœ‹è¡¨å¤§å°
SELECT
    database,
    table,
    formatReadableSize(sum(bytes)) as size,
    sum(rows) as rows
FROM system.parts
WHERE active
GROUP BY database, table
ORDER BY sum(bytes) DESC;
```

**é›†ç¾¤çŠ¶æ€:**
```sql
-- æŸ¥çœ‹å‰¯æœ¬çŠ¶æ€
SELECT * FROM system.replicas;

-- æŸ¥çœ‹åˆ†å¸ƒå¼è¡¨ä¿¡æ¯
SELECT * FROM system.clusters;

-- æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
SELECT
    name,
    path,
    formatReadableSize(free_space) as free,
    formatReadableSize(total_space) as total
FROM system.disks;
```

### 9.2 æ€§èƒ½æŒ‡æ ‡

```sql
-- æŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡
SELECT
    event_time,
    ProfileEvent_Query,
    ProfileEvent_SelectQuery,
    ProfileEvent_InsertQuery
FROM system.metric_log
WHERE event_time > now() - INTERVAL 1 HOUR
ORDER BY event_time;

-- èµ„æºä½¿ç”¨
SELECT
    metric,
    value
FROM system.metrics
WHERE metric IN (
    'MemoryTracking',
    'BackgroundPoolTask',
    'TCPConnection'
);
```

### 9.3 æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹ClickHouseæ—¥å¿—
tail -f /var/log/clickhouse-server/clickhouse-server.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f /var/log/clickhouse-server/clickhouse-server.err.log

# æŸ¥è¯¢æ—¥å¿—
tail -f /var/log/clickhouse-server/query_log.log
```

## 10. å®æˆ˜æ¡ˆä¾‹

### 10.1 ç”¨æˆ·è¡Œä¸ºåˆ†æ

```sql
-- åˆ›å»ºç”¨æˆ·è¡Œä¸ºè¡¨
CREATE TABLE user_behavior (
    user_id UInt32,
    item_id UInt32,
    category_id UInt16,
    behavior LowCardinality(String),
    timestamp DateTime
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(timestamp)
ORDER BY (user_id, timestamp);

-- ç»Ÿè®¡æ—¥æ´»ç”¨æˆ·
SELECT
    toDate(timestamp) as date,
    uniq(user_id) as dau
FROM user_behavior
WHERE timestamp >= today() - 7
GROUP BY date
ORDER BY date;

-- ç”¨æˆ·ç•™å­˜åˆ†æ
SELECT
    registration_date,
    day_diff,
    count(DISTINCT user_id) as retained_users,
    retained_users / first_value(retained_users) OVER (
        PARTITION BY registration_date ORDER BY day_diff
    ) as retention_rate
FROM (
    SELECT
        toDate(min(timestamp)) OVER (PARTITION BY user_id) as registration_date,
        user_id,
        dateDiff('day', registration_date, toDate(timestamp)) as day_diff
    FROM user_behavior
)
GROUP BY registration_date, day_diff
ORDER BY registration_date, day_diff;
```

### 10.2 å®æ—¶çœ‹æ¿

```sql
-- åˆ›å»ºå®æ—¶ç»Ÿè®¡ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW realtime_stats
ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMMDD(timestamp)
ORDER BY (minute, category_id)
AS SELECT
    toStartOfMinute(timestamp) as minute,
    category_id,
    uniqState(user_id) as unique_users,
    countState() as event_count,
    sumState(price) as total_revenue
FROM user_behavior
GROUP BY minute, category_id;

-- æŸ¥è¯¢æœ€è¿‘1å°æ—¶æ•°æ®
SELECT
    minute,
    category_id,
    uniqMerge(unique_users) as users,
    countMerge(event_count) as events,
    sumMerge(total_revenue) as revenue
FROM realtime_stats
WHERE minute >= now() - INTERVAL 1 HOUR
GROUP BY minute, category_id
ORDER BY minute DESC;
```

### 10.3 æ¼æ–—åˆ†æ

```sql
-- è½¬åŒ–æ¼æ–—
SELECT
    sum(step >= 1) as view,
    sum(step >= 2) as click,
    sum(step >= 3) as cart,
    sum(step >= 4) as purchase,
    click / view as view_to_click,
    cart / click as click_to_cart,
    purchase / cart as cart_to_purchase
FROM (
    SELECT
        user_id,
        max(multiIf(
            behavior = 'view', 1,
            behavior = 'click', 2,
            behavior = 'cart', 3,
            behavior = 'purchase', 4,
            0
        )) as step
    FROM user_behavior
    WHERE timestamp >= today()
    GROUP BY user_id
);
```

## 11. å­¦ä¹ éªŒè¯æ ‡å‡†

### âœ… åŸºç¡€èƒ½åŠ›éªŒè¯
- [ ] ç†è§£ClickHouseåˆ—å¼å­˜å‚¨åŸç†
- [ ] èƒ½å¤Ÿåˆ›å»ºå’Œä½¿ç”¨MergeTreeè¡¨
- [ ] æŒæ¡åŸºæœ¬SQLæŸ¥è¯¢å’Œèšåˆ
- [ ] ç†è§£åˆ†åŒºå’Œæ’åºé”®çš„ä½œç”¨

### âœ… è¿›é˜¶èƒ½åŠ›éªŒè¯
- [ ] èƒ½å¤Ÿè®¾è®¡é«˜æ•ˆçš„è¡¨ç»“æ„
- [ ] æŒæ¡å„ç§è¡¨å¼•æ“çš„ä½¿ç”¨åœºæ™¯
- [ ] èƒ½å¤Ÿä½¿ç”¨ç‰©åŒ–è§†å›¾ä¼˜åŒ–æŸ¥è¯¢
- [ ] ç†è§£åˆ†å¸ƒå¼è¡¨çš„å·¥ä½œåŸç†

### âœ… é«˜çº§èƒ½åŠ›éªŒè¯
- [ ] èƒ½å¤Ÿéƒ¨ç½²å’Œç®¡ç†ClickHouseé›†ç¾¤
- [ ] èƒ½å¤Ÿè¿›è¡Œæ€§èƒ½è°ƒä¼˜å’Œæ•…éšœæ’æŸ¥
- [ ] æŒæ¡å¤æ‚çš„åˆ†ææŸ¥è¯¢ç¼–å†™
- [ ] å…·å¤‡ç”Ÿäº§ç¯å¢ƒè¿ç»´èƒ½åŠ›

## 12. æ‰©å±•èµ„æº

### å®˜æ–¹èµ„æº
- å®˜ç½‘: https://clickhouse.com/
- æ–‡æ¡£: https://clickhouse.com/docs/
- GitHub: https://github.com/ClickHouse/ClickHouse

### å­¦ä¹ å»ºè®®
1. ä»å•æœºç¯å¢ƒå¼€å§‹å­¦ä¹ 
2. ç†è§£åˆ—å¼å­˜å‚¨å’ŒMergeTreeåŸç†
3. å®è·µå„ç§æŸ¥è¯¢å’Œèšåˆ
4. å­¦ä¹ è¡¨è®¾è®¡å’Œæ€§èƒ½ä¼˜åŒ–
5. æŒæ¡åˆ†å¸ƒå¼éƒ¨ç½²

### è¿›é˜¶æ–¹å‘
- ClickHouseå†…æ ¸åŸç†
- è‡ªå®šä¹‰å‡½æ•°å¼€å‘
- å®æ—¶æ•°æ®åˆ†ææ¶æ„
- ä¸å…¶ä»–ç³»ç»Ÿé›†æˆ
- å¤§è§„æ¨¡é›†ç¾¤è¿ç»´

### ç›¸å…³å·¥å…·
- ClickHouse Operator for Kubernetes
- Tabix - Webç•Œé¢
- DBeaver - æ•°æ®åº“å®¢æˆ·ç«¯
- Grafana - ç›‘æ§å¯è§†åŒ–
